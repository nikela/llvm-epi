; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=riscv64 -mattr=+v -verify-machineinstrs \
; RUN:    < %s -epi-pipeline | FileCheck %s

define <vscale x 8 x i8*> @test_llvm_vp_inttoptr_v8p0i8_v8i8(<vscale x 8 x i8> %a, <vscale x 8 x i1> %mask, i32 zeroext %evl) {
; CHECK-LABEL: test_llvm_vp_inttoptr_v8p0i8_v8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e64, m8, ta, ma
; CHECK-NEXT:    vzext.vf8 v16, v8, v0.t
; CHECK-NEXT:    vmv.v.v v8, v16
; CHECK-NEXT:    ret
  %ptrs = call <vscale x 8 x i8*> @llvm.vp.inttoptr.v8p0i8.v8i8(<vscale x 8 x i8> %a, <vscale x 8 x i1> %mask, i32 %evl)
  ret <vscale x 8 x i8*> %ptrs
}

define <vscale x 4 x i16*> @test_llvm_vp_inttoptr_v4p0i16_v4i16(<vscale x 4 x i16> %a, <vscale x 4 x i1> %mask, i32 zeroext %evl) {
; CHECK-LABEL: test_llvm_vp_inttoptr_v4p0i16_v4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e64, m4, ta, ma
; CHECK-NEXT:    vzext.vf4 v12, v8, v0.t
; CHECK-NEXT:    vmv.v.v v8, v12
; CHECK-NEXT:    ret
  %ptrs = call <vscale x 4 x i16*> @llvm.vp.inttoptr.v4p0i16.v4i16(<vscale x 4 x i16> %a, <vscale x 4 x i1> %mask, i32 %evl)
  ret <vscale x 4 x i16*> %ptrs
}

define <vscale x 2 x i32*> @test_llvm_vp_inttoptr_v2p0i32_v2i32(<vscale x 2 x i32> %a, <vscale x 2 x i1> %mask, i32 zeroext %evl) {
; CHECK-LABEL: test_llvm_vp_inttoptr_v2p0i32_v2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e64, m2, ta, ma
; CHECK-NEXT:    vzext.vf2 v10, v8, v0.t
; CHECK-NEXT:    vmv.v.v v8, v10
; CHECK-NEXT:    ret
  %ptrs = call <vscale x 2 x i32*> @llvm.vp.inttoptr.v2p0i32.v2i32(<vscale x 2 x i32> %a, <vscale x 2 x i1> %mask, i32 %evl)
  ret <vscale x 2 x i32*> %ptrs
}

define <vscale x 1 x i64*> @test_llvm_vp_inttoptr_v1p0i64_v1i64(<vscale x 1 x i64> %a, <vscale x 1 x i1> %mask, i32 zeroext %evl) {
; CHECK-LABEL: test_llvm_vp_inttoptr_v1p0i64_v1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
  %ptrs = call <vscale x 1 x i64*> @llvm.vp.inttoptr.v1p0i64.v1i64(<vscale x 1 x i64> %a, <vscale x 1 x i1> %mask, i32 %evl)
  ret <vscale x 1 x i64*> %ptrs
}

define <vscale x 2 x i32*> @test_llvm_vp_inttoptr_v2p0i32_v2i64(<vscale x 2 x i64> %a, <vscale x 2 x i1> %mask, i32 zeroext %evl) {
; CHECK-LABEL: test_llvm_vp_inttoptr_v2p0i32_v2i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
  %ptrs = call <vscale x 2 x i32*> @llvm.vp.inttoptr.v2p0i32.v2i64(<vscale x 2 x i64> %a, <vscale x 2 x i1> %mask, i32 %evl)
  ret <vscale x 2 x i32*> %ptrs
}

define <vscale x 4 x i16*> @test_llvm_vp_inttoptr_v4p0i16_v4i64(<vscale x 4 x i64> %a, <vscale x 4 x i1> %mask, i32 zeroext %evl) {
; CHECK-LABEL: test_llvm_vp_inttoptr_v4p0i16_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
  %ptrs = call <vscale x 4 x i16*> @llvm.vp.inttoptr.v4p0i16.v4i64(<vscale x 4 x i64> %a, <vscale x 4 x i1> %mask, i32 %evl)
  ret <vscale x 4 x i16*> %ptrs
}

define <vscale x 8 x i8*> @test_llvm_vp_inttoptr_v8p0i8_v8i64(<vscale x 8 x i64> %a, <vscale x 8 x i1> %mask, i32 zeroext %evl) {
; CHECK-LABEL: test_llvm_vp_inttoptr_v8p0i8_v8i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
  %ptrs = call <vscale x 8 x i8*> @llvm.vp.inttoptr.v8p0i8.v8i64(<vscale x 8 x i64> %a, <vscale x 8 x i1> %mask, i32 %evl)
  ret <vscale x 8 x i8*> %ptrs
}

declare <vscale x 8 x i8*> @llvm.vp.inttoptr.v8p0i8.v8i8(<vscale x 8 x i8>, <vscale x 8 x i1>, i32)
declare <vscale x 4 x i16*> @llvm.vp.inttoptr.v4p0i16.v4i16(<vscale x 4 x i16>, <vscale x 4 x i1>, i32)
declare <vscale x 2 x i32*> @llvm.vp.inttoptr.v2p0i32.v2i32(<vscale x 2 x i32>, <vscale x 2 x i1>, i32)
declare <vscale x 1 x i64*> @llvm.vp.inttoptr.v1p0i64.v1i64(<vscale x 1 x i64>, <vscale x 1 x i1>, i32)
declare <vscale x 2 x i32*> @llvm.vp.inttoptr.v2p0i32.v2i64(<vscale x 2 x i64>, <vscale x 2 x i1>, i32)
declare <vscale x 4 x i16*> @llvm.vp.inttoptr.v4p0i16.v4i64(<vscale x 4 x i64>, <vscale x 4 x i1>, i32)
declare <vscale x 8 x i8*> @llvm.vp.inttoptr.v8p0i8.v8i64(<vscale x 8 x i64>, <vscale x 8 x i1>, i32)
