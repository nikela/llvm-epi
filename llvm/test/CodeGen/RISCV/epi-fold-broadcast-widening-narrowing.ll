; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -S < %s | FileCheck --check-prefix=NOFOLD %s
; RUN: opt -S -epi-fold-broadcast < %s | FileCheck --check-prefix=FOLD %s

define dso_local <vscale x 2 x i32> @vnsrl_wx(<vscale x 2 x i64> %a, i32 signext %x, i64 %gvl) nounwind {
; NOFOLD-LABEL: @vnsrl_wx(
; NOFOLD-NEXT:  entry:
; NOFOLD-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 [[X:%.*]], i64 [[GVL:%.*]])
; NOFOLD-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnsrl.nxv2i32.nxv2i64.nxv2i32(<vscale x 2 x i64> [[A:%.*]], <vscale x 2 x i32> [[TMP0]], i64 [[GVL]])
; NOFOLD-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
;
; FOLD-LABEL: @vnsrl_wx(
; FOLD-NEXT:  entry:
; FOLD-NEXT:    [[TMP0:%.*]] = call <vscale x 2 x i32> @llvm.epi.vnsrl.nxv2i32.nxv2i64.i32(<vscale x 2 x i64> [[A:%.*]], i32 [[X:%.*]], i64 [[GVL:%.*]])
; FOLD-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
;
entry:
  %0 = tail call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 %x, i64 %gvl)
  %1 = tail call <vscale x 2 x i32> @llvm.epi.vnsrl.nxv2i32.nxv2i64.nxv2i32(<vscale x 2 x i64> %a, <vscale x 2 x i32> %0, i64 %gvl)
  ret <vscale x 2 x i32> %1
}

declare <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32, i64) #1

declare <vscale x 2 x i32> @llvm.epi.vnsrl.nxv2i32.nxv2i64.nxv2i32(<vscale x 2 x i64>, <vscale x 2 x i32>, i64) #1

define dso_local <vscale x 2 x i32> @vnsrl_wi(<vscale x 2 x i64> %a, i64 %gvl) nounwind {
; NOFOLD-LABEL: @vnsrl_wi(
; NOFOLD-NEXT:  entry:
; NOFOLD-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 5, i64 [[GVL:%.*]])
; NOFOLD-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnsrl.nxv2i32.nxv2i64.nxv2i32(<vscale x 2 x i64> [[A:%.*]], <vscale x 2 x i32> [[TMP0]], i64 [[GVL]])
; NOFOLD-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
;
; FOLD-LABEL: @vnsrl_wi(
; FOLD-NEXT:  entry:
; FOLD-NEXT:    [[TMP0:%.*]] = call <vscale x 2 x i32> @llvm.epi.vnsrl.nxv2i32.nxv2i64.i32(<vscale x 2 x i64> [[A:%.*]], i32 5, i64 [[GVL:%.*]])
; FOLD-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
;
entry:
  %0 = tail call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 5, i64 %gvl)
  %1 = tail call <vscale x 2 x i32> @llvm.epi.vnsrl.nxv2i32.nxv2i64.nxv2i32(<vscale x 2 x i64> %a, <vscale x 2 x i32> %0, i64 %gvl)
  ret <vscale x 2 x i32> %1
}

define dso_local <vscale x 2 x i64> @vwadd_wx(<vscale x 2 x i32> %a, i32 signext %x, i64 %gvl) nounwind {
; NOFOLD-LABEL: @vwadd_wx(
; NOFOLD-NEXT:  entry:
; NOFOLD-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 [[X:%.*]], i64 [[GVL:%.*]])
; NOFOLD-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwadd.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[A:%.*]], <vscale x 2 x i32> [[TMP0]], i64 [[GVL]])
; NOFOLD-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
;
; FOLD-LABEL: @vwadd_wx(
; FOLD-NEXT:  entry:
; FOLD-NEXT:    [[TMP0:%.*]] = call <vscale x 2 x i64> @llvm.epi.vwadd.nxv2i64.nxv2i32.i32(<vscale x 2 x i32> [[A:%.*]], i32 [[X:%.*]], i64 [[GVL:%.*]])
; FOLD-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
;
entry:
  %0 = tail call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 %x, i64 %gvl)
  %1 = tail call <vscale x 2 x i64> @llvm.epi.vwadd.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> %a, <vscale x 2 x i32> %0, i64 %gvl)
  ret <vscale x 2 x i64> %1
}

declare <vscale x 2 x i64> @llvm.epi.vwadd.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32>, <vscale x 2 x i32>, i64) #1

define dso_local <vscale x 2 x i64> @vwadd_wx_2(<vscale x 2 x i32> %a, i64 %gvl) nounwind {
; NOFOLD-LABEL: @vwadd_wx_2(
; NOFOLD-NEXT:  entry:
; NOFOLD-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 5, i64 [[GVL:%.*]])
; NOFOLD-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwadd.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[A:%.*]], <vscale x 2 x i32> [[TMP0]], i64 [[GVL]])
; NOFOLD-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
;
; FOLD-LABEL: @vwadd_wx_2(
; FOLD-NEXT:  entry:
; FOLD-NEXT:    [[TMP0:%.*]] = call <vscale x 2 x i64> @llvm.epi.vwadd.nxv2i64.nxv2i32.i32(<vscale x 2 x i32> [[A:%.*]], i32 5, i64 [[GVL:%.*]])
; FOLD-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
;
entry:
  %0 = tail call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 5, i64 %gvl)
  %1 = tail call <vscale x 2 x i64> @llvm.epi.vwadd.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> %a, <vscale x 2 x i32> %0, i64 %gvl)
  ret <vscale x 2 x i64> %1
}

define dso_local <vscale x 2 x i64> @vwadd_w_wx(<vscale x 2 x i64> %a, i32 signext %x, i64 %gvl) nounwind {
; NOFOLD-LABEL: @vwadd_w_wx(
; NOFOLD-NEXT:  entry:
; NOFOLD-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 [[X:%.*]], i64 [[GVL:%.*]])
; NOFOLD-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwadd.w.nxv2i64.nxv2i32(<vscale x 2 x i64> [[A:%.*]], <vscale x 2 x i32> [[TMP0]], i64 [[GVL]])
; NOFOLD-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
;
; FOLD-LABEL: @vwadd_w_wx(
; FOLD-NEXT:  entry:
; FOLD-NEXT:    [[TMP0:%.*]] = call <vscale x 2 x i64> @llvm.epi.vwadd.w.nxv2i64.i32(<vscale x 2 x i64> [[A:%.*]], i32 [[X:%.*]], i64 [[GVL:%.*]])
; FOLD-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
;
entry:
  %0 = tail call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 %x, i64 %gvl)
  %1 = tail call <vscale x 2 x i64> @llvm.epi.vwadd.w.nxv2i64.nxv2i32(<vscale x 2 x i64> %a, <vscale x 2 x i32> %0, i64 %gvl)
  ret <vscale x 2 x i64> %1
}

declare <vscale x 2 x i64> @llvm.epi.vwadd.w.nxv2i64.nxv2i32(<vscale x 2 x i64>, <vscale x 2 x i32>, i64) #1

define dso_local <vscale x 2 x i64> @vwadd_w_wx_2(<vscale x 2 x i64> %a, i64 %gvl) nounwind {
; NOFOLD-LABEL: @vwadd_w_wx_2(
; NOFOLD-NEXT:  entry:
; NOFOLD-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 5, i64 [[GVL:%.*]])
; NOFOLD-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwadd.w.nxv2i64.nxv2i32(<vscale x 2 x i64> [[A:%.*]], <vscale x 2 x i32> [[TMP0]], i64 [[GVL]])
; NOFOLD-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
;
; FOLD-LABEL: @vwadd_w_wx_2(
; FOLD-NEXT:  entry:
; FOLD-NEXT:    [[TMP0:%.*]] = call <vscale x 2 x i64> @llvm.epi.vwadd.w.nxv2i64.i32(<vscale x 2 x i64> [[A:%.*]], i32 5, i64 [[GVL:%.*]])
; FOLD-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
;
entry:
  %0 = tail call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 5, i64 %gvl)
  %1 = tail call <vscale x 2 x i64> @llvm.epi.vwadd.w.nxv2i64.nxv2i32(<vscale x 2 x i64> %a, <vscale x 2 x i32> %0, i64 %gvl)
  ret <vscale x 2 x i64> %1
}
