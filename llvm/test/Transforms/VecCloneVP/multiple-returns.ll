; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --include-generated-funcs
; RUN: opt -S --vec-clone-vp %s | FileCheck %s

define i32 @foo(i32 %x, i32 %y) #0 {
entry:
  %cmp = icmp sgt i32 %x, %y
  br i1 %cmp, label %if.then, label %if.else

if.then:
  %mul = shl nsw i32 %x, 1
  ret i32 %mul

if.else:
  %div = sdiv i32 %x, 2
  ret i32 %div
}

attributes #0 = { "_ZGVEMk2vv_foo" "_ZGVENk2vv_foo" }

; CHECK-LABEL: @foo(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[X:%.*]], [[Y:%.*]]
; CHECK-NEXT:    br i1 [[CMP]], label [[IF_THEN:%.*]], label [[IF_ELSE:%.*]]
; CHECK:       if.then:
; CHECK-NEXT:    [[MUL:%.*]] = shl nsw i32 [[X]], 1
; CHECK-NEXT:    ret i32 [[MUL]]
; CHECK:       if.else:
; CHECK-NEXT:    [[DIV:%.*]] = sdiv i32 [[X]], 2
; CHECK-NEXT:    ret i32 [[DIV]]
;
;
; CHECK-LABEL: @_ZGVEMk2vv_foo(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VSCALE:%.*]] = call i32 @llvm.vscale.i32()
; CHECK-NEXT:    [[TMP0:%.*]] = mul i32 [[VSCALE]], 2
; CHECK-NEXT:    [[ASSUME_COND:%.*]] = icmp ule i32 [[VL:%.*]], [[TMP0]]
; CHECK-NEXT:    call void @llvm.assume(i1 [[ASSUME_COND]])
; CHECK-NEXT:    [[ZEXT_MASK:%.*]] = zext <vscale x 2 x i1> [[MASK:%.*]] to <vscale x 2 x i32>
; CHECK-NEXT:    [[VEC_MASK:%.*]] = alloca <vscale x 2 x i32>, align 8
; CHECK-NEXT:    call void @llvm.vp.store.nxv2i32.p0(<vscale x 2 x i32> [[ZEXT_MASK]], ptr [[VEC_MASK]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[VL]])
; CHECK-NEXT:    [[VEC_X:%.*]] = alloca <vscale x 2 x i32>, align 8
; CHECK-NEXT:    call void @llvm.vp.store.nxv2i32.p0(<vscale x 2 x i32> [[X:%.*]], ptr [[VEC_X]], <vscale x 2 x i1> [[MASK]], i32 [[VL]])
; CHECK-NEXT:    [[VEC_Y:%.*]] = alloca <vscale x 2 x i32>, align 8
; CHECK-NEXT:    call void @llvm.vp.store.nxv2i32.p0(<vscale x 2 x i32> [[Y:%.*]], ptr [[VEC_Y]], <vscale x 2 x i1> [[MASK]], i32 [[VL]])
; CHECK-NEXT:    [[VEC_RET:%.*]] = alloca <vscale x 2 x i32>, align 8
; CHECK-NEXT:    [[VL_CHECK:%.*]] = icmp uge i32 [[VL]], 0
; CHECK-NEXT:    br i1 [[VL_CHECK]], label [[SIMD_LOOP:%.*]], label [[RETURN:%.*]]
; CHECK:       simd.loop:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i32 [ 0, [[ENTRY:%.*]] ], [ [[INDVAR:%.*]], [[SIMD_LOOP_EXIT:%.*]] ]
; CHECK-NEXT:    [[VEC_MASK_GEP:%.*]] = getelementptr i32, ptr [[VEC_MASK]], i32 [[INDEX]]
; CHECK-NEXT:    [[MASK_PARM:%.*]] = load i32, ptr [[VEC_MASK_GEP]], align 4
; CHECK-NEXT:    [[MASK_VALUE:%.*]] = icmp ne i32 [[MASK_PARM]], 0
; CHECK-NEXT:    br i1 [[MASK_VALUE]], label [[SIMD_LOOP_THEN:%.*]], label [[SIMD_LOOP_EXIT]]
; CHECK:       simd.loop.then:
; CHECK-NEXT:    [[VEC_X_GEP3:%.*]] = getelementptr i32, ptr [[VEC_X]], i32 [[INDEX]]
; CHECK-NEXT:    [[VEC_X_ELEM4:%.*]] = load i32, ptr [[VEC_X_GEP3]], align 4
; CHECK-NEXT:    [[VEC_Y_GEP:%.*]] = getelementptr i32, ptr [[VEC_Y]], i32 [[INDEX]]
; CHECK-NEXT:    [[VEC_Y_ELEM:%.*]] = load i32, ptr [[VEC_Y_GEP]], align 4
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[VEC_X_ELEM4]], [[VEC_Y_ELEM]]
; CHECK-NEXT:    br i1 [[CMP]], label [[IF_THEN:%.*]], label [[IF_ELSE:%.*]]
; CHECK:       if.then:
; CHECK-NEXT:    [[VEC_X_GEP1:%.*]] = getelementptr i32, ptr [[VEC_X]], i32 [[INDEX]]
; CHECK-NEXT:    [[VEC_X_ELEM2:%.*]] = load i32, ptr [[VEC_X_GEP1]], align 4
; CHECK-NEXT:    [[MUL:%.*]] = shl nsw i32 [[VEC_X_ELEM2]], 1
; CHECK-NEXT:    [[VEC_RET_GEP:%.*]] = getelementptr i32, ptr [[VEC_RET]], i32 [[INDEX]]
; CHECK-NEXT:    store i32 [[MUL]], ptr [[VEC_RET_GEP]], align 4
; CHECK-NEXT:    br label [[SIMD_LOOP_EXIT]]
; CHECK:       if.else:
; CHECK-NEXT:    [[VEC_X_GEP:%.*]] = getelementptr i32, ptr [[VEC_X]], i32 [[INDEX]]
; CHECK-NEXT:    [[VEC_X_ELEM:%.*]] = load i32, ptr [[VEC_X_GEP]], align 4
; CHECK-NEXT:    [[DIV:%.*]] = sdiv i32 [[VEC_X_ELEM]], 2
; CHECK-NEXT:    [[VEC_RET_GEP5:%.*]] = getelementptr i32, ptr [[VEC_RET]], i32 [[INDEX]]
; CHECK-NEXT:    store i32 [[DIV]], ptr [[VEC_RET_GEP5]], align 4
; CHECK-NEXT:    br label [[SIMD_LOOP_EXIT]]
; CHECK:       simd.loop.exit:
; CHECK-NEXT:    [[INDVAR]] = add nsw i32 [[INDEX]], 1
; CHECK-NEXT:    [[EXIT_COND:%.*]] = icmp eq i32 [[INDVAR]], [[VL]]
; CHECK-NEXT:    br i1 [[EXIT_COND]], label [[RETURN]], label [[SIMD_LOOP]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       return:
; CHECK-NEXT:    [[VEC_RET6:%.*]] = call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0(ptr [[VEC_RET]], <vscale x 2 x i1> [[MASK]], i32 [[VL]])
; CHECK-NEXT:    ret <vscale x 2 x i32> [[VEC_RET6]]
;
;
; CHECK-LABEL: @_ZGVENk2vv_foo(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VSCALE:%.*]] = call i32 @llvm.vscale.i32()
; CHECK-NEXT:    [[TMP0:%.*]] = mul i32 [[VSCALE]], 2
; CHECK-NEXT:    [[ASSUME_COND:%.*]] = icmp ule i32 [[VL:%.*]], [[TMP0]]
; CHECK-NEXT:    call void @llvm.assume(i1 [[ASSUME_COND]])
; CHECK-NEXT:    [[VEC_X:%.*]] = alloca <vscale x 2 x i32>, align 8
; CHECK-NEXT:    call void @llvm.vp.store.nxv2i32.p0(<vscale x 2 x i32> [[X:%.*]], ptr [[VEC_X]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[VL]])
; CHECK-NEXT:    [[VEC_Y:%.*]] = alloca <vscale x 2 x i32>, align 8
; CHECK-NEXT:    call void @llvm.vp.store.nxv2i32.p0(<vscale x 2 x i32> [[Y:%.*]], ptr [[VEC_Y]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[VL]])
; CHECK-NEXT:    [[VEC_RET:%.*]] = alloca <vscale x 2 x i32>, align 8
; CHECK-NEXT:    [[VL_CHECK:%.*]] = icmp uge i32 [[VL]], 0
; CHECK-NEXT:    br i1 [[VL_CHECK]], label [[SIMD_LOOP:%.*]], label [[RETURN:%.*]]
; CHECK:       simd.loop:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i32 [ 0, [[ENTRY:%.*]] ], [ [[INDVAR:%.*]], [[SIMD_LOOP_EXIT:%.*]] ]
; CHECK-NEXT:    [[VEC_X_GEP3:%.*]] = getelementptr i32, ptr [[VEC_X]], i32 [[INDEX]]
; CHECK-NEXT:    [[VEC_X_ELEM4:%.*]] = load i32, ptr [[VEC_X_GEP3]], align 4
; CHECK-NEXT:    [[VEC_Y_GEP:%.*]] = getelementptr i32, ptr [[VEC_Y]], i32 [[INDEX]]
; CHECK-NEXT:    [[VEC_Y_ELEM:%.*]] = load i32, ptr [[VEC_Y_GEP]], align 4
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[VEC_X_ELEM4]], [[VEC_Y_ELEM]]
; CHECK-NEXT:    br i1 [[CMP]], label [[IF_THEN:%.*]], label [[IF_ELSE:%.*]]
; CHECK:       if.then:
; CHECK-NEXT:    [[VEC_X_GEP1:%.*]] = getelementptr i32, ptr [[VEC_X]], i32 [[INDEX]]
; CHECK-NEXT:    [[VEC_X_ELEM2:%.*]] = load i32, ptr [[VEC_X_GEP1]], align 4
; CHECK-NEXT:    [[MUL:%.*]] = shl nsw i32 [[VEC_X_ELEM2]], 1
; CHECK-NEXT:    [[VEC_RET_GEP:%.*]] = getelementptr i32, ptr [[VEC_RET]], i32 [[INDEX]]
; CHECK-NEXT:    store i32 [[MUL]], ptr [[VEC_RET_GEP]], align 4
; CHECK-NEXT:    br label [[SIMD_LOOP_EXIT]]
; CHECK:       if.else:
; CHECK-NEXT:    [[VEC_X_GEP:%.*]] = getelementptr i32, ptr [[VEC_X]], i32 [[INDEX]]
; CHECK-NEXT:    [[VEC_X_ELEM:%.*]] = load i32, ptr [[VEC_X_GEP]], align 4
; CHECK-NEXT:    [[DIV:%.*]] = sdiv i32 [[VEC_X_ELEM]], 2
; CHECK-NEXT:    [[VEC_RET_GEP5:%.*]] = getelementptr i32, ptr [[VEC_RET]], i32 [[INDEX]]
; CHECK-NEXT:    store i32 [[DIV]], ptr [[VEC_RET_GEP5]], align 4
; CHECK-NEXT:    br label [[SIMD_LOOP_EXIT]]
; CHECK:       simd.loop.exit:
; CHECK-NEXT:    [[INDVAR]] = add nsw i32 [[INDEX]], 1
; CHECK-NEXT:    [[EXIT_COND:%.*]] = icmp eq i32 [[INDVAR]], [[VL]]
; CHECK-NEXT:    br i1 [[EXIT_COND]], label [[RETURN]], label [[SIMD_LOOP]], !llvm.loop [[LOOP8:![0-9]+]]
; CHECK:       return:
; CHECK-NEXT:    [[VEC_RET6:%.*]] = call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0(ptr [[VEC_RET]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[VL]])
; CHECK-NEXT:    ret <vscale x 2 x i32> [[VEC_RET6]]
;
