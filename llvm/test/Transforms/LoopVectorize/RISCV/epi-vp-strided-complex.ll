; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -mtriple riscv64 -mattr +m,+a,+f,+d,+zepi \
; RUN:    -scalable-vectorization=only -prefer-predicate-over-epilogue=predicate-dont-vectorize \
; RUN:    -S --passes=loop-vectorize,instcombine,simplifycfg -riscv-v-vector-bits-min=64 < %s -o - \
; RUN:    -vectorizer-use-vp-strided-load-store=false \
; RUN:    | FileCheck --check-prefix=GATHER %s
; RUN: opt -mtriple riscv64 -mattr +m,+a,+f,+d,+zepi \
; RUN:    -scalable-vectorization=only -prefer-predicate-over-epilogue=predicate-dont-vectorize \
; RUN:    -S --passes=loop-vectorize,instcombine,simplifycfg -riscv-v-vector-bits-min=64 < %s -o - \
; RUN:    | FileCheck --check-prefix=STRIDED %s

; ModuleID = 'nostride.c'
source_filename = "nostride.c"
target datalayout = "e-m:e-p:64:64-i64:64-i128:128-n64-S128-v128:128:128-v256:128:128-v512:128:128-v1024:128:128"
target triple = "riscv64-unknown-linux-gnu"

; #include <complex.h>
;
; void foo(int n, int j, float complex temp1, float complex temp2,
;          float complex x[n], float complex y[n], float complex A[n][n]) {
; #pragma clang loop vectorize(assume_safety)
;   for (int i = 0; i <= j - 1; i++) {
;     A[i][j] = A[i][j] + x[i] * temp1 + y[i] * temp2;
;   }
; }

; Function Attrs: nofree norecurse nosync nounwind
define dso_local void @foo(i32 signext %n, i32 signext %j, float %temp1.coerce0, float %temp1.coerce1, float %temp2.coerce0, float %temp2.coerce1, { float, float }* nocapture readonly %x, { float, float }* nocapture readonly %y, { float, float }* nocapture %A) local_unnamed_addr #0 {
; GATHER-LABEL: @foo(
; GATHER-NEXT:  entry:
; GATHER-NEXT:    [[TMP0:%.*]] = zext i32 [[N:%.*]] to i64
; GATHER-NEXT:    [[CMP_NOT_NOT40:%.*]] = icmp sgt i32 [[J:%.*]], 0
; GATHER-NEXT:    br i1 [[CMP_NOT_NOT40]], label [[FOR_BODY_PREHEADER:%.*]], label [[FOR_COND_CLEANUP:%.*]]
; GATHER:       for.body.preheader:
; GATHER-NEXT:    [[IDXPROM1:%.*]] = sext i32 [[J]] to i64
; GATHER-NEXT:    [[WIDE_TRIP_COUNT:%.*]] = zext i32 [[J]] to i64
; GATHER-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds { float, float }, ptr [[A:%.*]], i64 [[IDXPROM1]]
; GATHER-NEXT:    [[TMP1:%.*]] = xor i64 [[WIDE_TRIP_COUNT]], -1
; GATHER-NEXT:    [[TMP2:%.*]] = call i64 @llvm.vscale.i64()
; GATHER-NEXT:    [[TMP3:%.*]] = shl i64 [[TMP2]], 1
; GATHER-NEXT:    [[TMP4:%.*]] = icmp ugt i64 [[TMP3]], [[TMP1]]
; GATHER-NEXT:    br i1 [[TMP4]], label [[FOR_BODY:%.*]], label [[VECTOR_PH:%.*]]
; GATHER:       vector.ph:
; GATHER-NEXT:    [[TMP5:%.*]] = call <vscale x 2 x i64> @llvm.experimental.stepvector.nxv2i64()
; GATHER-NEXT:    [[BROADCAST_SPLATINSERT3:%.*]] = insertelement <vscale x 2 x i64> poison, i64 [[TMP0]], i64 0
; GATHER-NEXT:    [[BROADCAST_SPLAT4:%.*]] = shufflevector <vscale x 2 x i64> [[BROADCAST_SPLATINSERT3]], <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer
; GATHER-NEXT:    [[BROADCAST_SPLATINSERT8:%.*]] = insertelement <vscale x 2 x float> poison, float [[TEMP2_COERCE1:%.*]], i64 0
; GATHER-NEXT:    [[BROADCAST_SPLAT9:%.*]] = shufflevector <vscale x 2 x float> [[BROADCAST_SPLATINSERT8]], <vscale x 2 x float> poison, <vscale x 2 x i32> zeroinitializer
; GATHER-NEXT:    [[BROADCAST_SPLATINSERT11:%.*]] = insertelement <vscale x 2 x float> poison, float [[TEMP2_COERCE0:%.*]], i64 0
; GATHER-NEXT:    [[BROADCAST_SPLAT12:%.*]] = shufflevector <vscale x 2 x float> [[BROADCAST_SPLATINSERT11]], <vscale x 2 x float> poison, <vscale x 2 x i32> zeroinitializer
; GATHER-NEXT:    [[BROADCAST_SPLATINSERT17:%.*]] = insertelement <vscale x 2 x float> poison, float [[TEMP1_COERCE1:%.*]], i64 0
; GATHER-NEXT:    [[BROADCAST_SPLAT18:%.*]] = shufflevector <vscale x 2 x float> [[BROADCAST_SPLATINSERT17]], <vscale x 2 x float> poison, <vscale x 2 x i32> zeroinitializer
; GATHER-NEXT:    [[BROADCAST_SPLATINSERT20:%.*]] = insertelement <vscale x 2 x float> poison, float [[TEMP1_COERCE0:%.*]], i64 0
; GATHER-NEXT:    [[BROADCAST_SPLAT21:%.*]] = shufflevector <vscale x 2 x float> [[BROADCAST_SPLATINSERT20]], <vscale x 2 x float> poison, <vscale x 2 x i32> zeroinitializer
; GATHER-NEXT:    br label [[VECTOR_BODY:%.*]]
; GATHER:       vector.body:
; GATHER-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; GATHER-NEXT:    [[VEC_IND:%.*]] = phi <vscale x 2 x i64> [ [[TMP5]], [[VECTOR_PH]] ], [ [[VEC_IND_NEXT:%.*]], [[VECTOR_BODY]] ]
; GATHER-NEXT:    [[TMP6:%.*]] = sub i64 [[WIDE_TRIP_COUNT]], [[INDEX]]
; GATHER-NEXT:    [[TMP7:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP6]], i64 2, i64 0)
; GATHER-NEXT:    [[TMP8:%.*]] = trunc i64 [[TMP7]] to i32
; GATHER-NEXT:    [[TMP9:%.*]] = and i64 [[TMP7]], 4294967295
; GATHER-NEXT:    [[DOTSPLATINSERT1:%.*]] = insertelement <vscale x 2 x i64> poison, i64 [[TMP9]], i64 0
; GATHER-NEXT:    [[DOTSPLAT2:%.*]] = shufflevector <vscale x 2 x i64> [[DOTSPLATINSERT1]], <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer
; GATHER-NEXT:    [[VP_OP:%.*]] = call <vscale x 2 x i64> @llvm.vp.mul.nxv2i64(<vscale x 2 x i64> [[VEC_IND]], <vscale x 2 x i64> [[BROADCAST_SPLAT4]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP10:%.*]] = getelementptr inbounds { float, float }, ptr [[ARRAYIDX]], <vscale x 2 x i64> [[VP_OP]]
; GATHER-NEXT:    [[TMP11:%.*]] = call <vscale x 2 x i64> @llvm.vp.ptrtoint.nxv2i64.nxv2p0(<vscale x 2 x ptr> [[TMP10]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP12:%.*]] = call <vscale x 2 x i64> @llvm.vp.add.nxv2i64(<vscale x 2 x i64> [[TMP11]], <vscale x 2 x i64> shufflevector (<vscale x 2 x i64> insertelement (<vscale x 2 x i64> poison, i64 4, i64 0), <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer), <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP13:%.*]] = call <vscale x 2 x ptr> @llvm.vp.inttoptr.nxv2p0.nxv2i64(<vscale x 2 x i64> [[TMP12]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP14:%.*]] = call <vscale x 2 x i64> @llvm.vp.shl.nxv2i64(<vscale x 2 x i64> [[VEC_IND]], <vscale x 2 x i64> shufflevector (<vscale x 2 x i64> insertelement (<vscale x 2 x i64> poison, i64 3, i64 0), <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer), <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[DOTSPLATINSERT:%.*]] = insertelement <vscale x 2 x ptr> poison, ptr [[X:%.*]], i64 0
; GATHER-NEXT:    [[DOTSPLAT:%.*]] = shufflevector <vscale x 2 x ptr> [[DOTSPLATINSERT]], <vscale x 2 x ptr> poison, <vscale x 2 x i32> zeroinitializer
; GATHER-NEXT:    [[TMP15:%.*]] = call <vscale x 2 x i64> @llvm.vp.ptrtoint.nxv2i64.nxv2p0(<vscale x 2 x ptr> [[DOTSPLAT]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP16:%.*]] = call <vscale x 2 x i64> @llvm.vp.add.nxv2i64(<vscale x 2 x i64> [[TMP15]], <vscale x 2 x i64> [[TMP14]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP17:%.*]] = call <vscale x 2 x ptr> @llvm.vp.inttoptr.nxv2p0.nxv2i64(<vscale x 2 x i64> [[TMP16]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_GATHER:%.*]] = call <vscale x 2 x float> @llvm.vp.gather.nxv2f32.nxv2p0(<vscale x 2 x ptr> [[TMP17]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]]), !llvm.access.group [[ACC_GRP4:![0-9]+]]
; GATHER-NEXT:    [[TMP18:%.*]] = call <vscale x 2 x i64> @llvm.vp.shl.nxv2i64(<vscale x 2 x i64> [[VEC_IND]], <vscale x 2 x i64> shufflevector (<vscale x 2 x i64> insertelement (<vscale x 2 x i64> poison, i64 3, i64 0), <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer), <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP19:%.*]] = call <vscale x 2 x i64> @llvm.vp.add.nxv2i64(<vscale x 2 x i64> [[TMP18]], <vscale x 2 x i64> shufflevector (<vscale x 2 x i64> insertelement (<vscale x 2 x i64> poison, i64 4, i64 0), <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer), <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[DOTSPLATINSERT35:%.*]] = insertelement <vscale x 2 x ptr> poison, ptr [[X]], i64 0
; GATHER-NEXT:    [[DOTSPLAT36:%.*]] = shufflevector <vscale x 2 x ptr> [[DOTSPLATINSERT35]], <vscale x 2 x ptr> poison, <vscale x 2 x i32> zeroinitializer
; GATHER-NEXT:    [[TMP20:%.*]] = call <vscale x 2 x i64> @llvm.vp.ptrtoint.nxv2i64.nxv2p0(<vscale x 2 x ptr> [[DOTSPLAT36]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP21:%.*]] = call <vscale x 2 x i64> @llvm.vp.add.nxv2i64(<vscale x 2 x i64> [[TMP20]], <vscale x 2 x i64> [[TMP19]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP22:%.*]] = call <vscale x 2 x ptr> @llvm.vp.inttoptr.nxv2p0.nxv2i64(<vscale x 2 x i64> [[TMP21]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_GATHER5:%.*]] = call <vscale x 2 x float> @llvm.vp.gather.nxv2f32.nxv2p0(<vscale x 2 x ptr> [[TMP22]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]]), !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    [[TMP23:%.*]] = call <vscale x 2 x i64> @llvm.vp.shl.nxv2i64(<vscale x 2 x i64> [[VEC_IND]], <vscale x 2 x i64> shufflevector (<vscale x 2 x i64> insertelement (<vscale x 2 x i64> poison, i64 3, i64 0), <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer), <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[DOTSPLATINSERT37:%.*]] = insertelement <vscale x 2 x ptr> poison, ptr [[Y:%.*]], i64 0
; GATHER-NEXT:    [[DOTSPLAT38:%.*]] = shufflevector <vscale x 2 x ptr> [[DOTSPLATINSERT37]], <vscale x 2 x ptr> poison, <vscale x 2 x i32> zeroinitializer
; GATHER-NEXT:    [[TMP24:%.*]] = call <vscale x 2 x i64> @llvm.vp.ptrtoint.nxv2i64.nxv2p0(<vscale x 2 x ptr> [[DOTSPLAT38]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP25:%.*]] = call <vscale x 2 x i64> @llvm.vp.add.nxv2i64(<vscale x 2 x i64> [[TMP24]], <vscale x 2 x i64> [[TMP23]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP26:%.*]] = call <vscale x 2 x ptr> @llvm.vp.inttoptr.nxv2p0.nxv2i64(<vscale x 2 x i64> [[TMP25]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_GATHER6:%.*]] = call <vscale x 2 x float> @llvm.vp.gather.nxv2f32.nxv2p0(<vscale x 2 x ptr> [[TMP26]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]]), !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    [[TMP27:%.*]] = call <vscale x 2 x i64> @llvm.vp.shl.nxv2i64(<vscale x 2 x i64> [[VEC_IND]], <vscale x 2 x i64> shufflevector (<vscale x 2 x i64> insertelement (<vscale x 2 x i64> poison, i64 3, i64 0), <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer), <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP28:%.*]] = call <vscale x 2 x i64> @llvm.vp.add.nxv2i64(<vscale x 2 x i64> [[TMP27]], <vscale x 2 x i64> shufflevector (<vscale x 2 x i64> insertelement (<vscale x 2 x i64> poison, i64 4, i64 0), <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer), <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[DOTSPLATINSERT39:%.*]] = insertelement <vscale x 2 x ptr> poison, ptr [[Y]], i64 0
; GATHER-NEXT:    [[DOTSPLAT40:%.*]] = shufflevector <vscale x 2 x ptr> [[DOTSPLATINSERT39]], <vscale x 2 x ptr> poison, <vscale x 2 x i32> zeroinitializer
; GATHER-NEXT:    [[TMP29:%.*]] = call <vscale x 2 x i64> @llvm.vp.ptrtoint.nxv2i64.nxv2p0(<vscale x 2 x ptr> [[DOTSPLAT40]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP30:%.*]] = call <vscale x 2 x i64> @llvm.vp.add.nxv2i64(<vscale x 2 x i64> [[TMP29]], <vscale x 2 x i64> [[TMP28]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[TMP31:%.*]] = call <vscale x 2 x ptr> @llvm.vp.inttoptr.nxv2p0.nxv2i64(<vscale x 2 x i64> [[TMP30]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_GATHER7:%.*]] = call <vscale x 2 x float> @llvm.vp.gather.nxv2f32.nxv2p0(<vscale x 2 x ptr> [[TMP31]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]]), !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    [[VP_OP10:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_GATHER6]], <vscale x 2 x float> [[BROADCAST_SPLAT9]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_OP13:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_GATHER7]], <vscale x 2 x float> [[BROADCAST_SPLAT12]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_OP14:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_GATHER6]], <vscale x 2 x float> [[BROADCAST_SPLAT12]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_OP15:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_GATHER7]], <vscale x 2 x float> [[BROADCAST_SPLAT9]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_GATHER16:%.*]] = call <vscale x 2 x float> @llvm.vp.gather.nxv2f32.nxv2p0(<vscale x 2 x ptr> [[TMP13]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]]), !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    [[VP_OP19:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_GATHER]], <vscale x 2 x float> [[BROADCAST_SPLAT18]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_OP22:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_GATHER5]], <vscale x 2 x float> [[BROADCAST_SPLAT21]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_GATHER23:%.*]] = call <vscale x 2 x float> @llvm.vp.gather.nxv2f32.nxv2p0(<vscale x 2 x ptr> [[TMP10]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]]), !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    [[VP_OP24:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_GATHER]], <vscale x 2 x float> [[BROADCAST_SPLAT21]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_OP25:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_GATHER5]], <vscale x 2 x float> [[BROADCAST_SPLAT18]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_OP26:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP15]], <vscale x 2 x float> [[VP_OP25]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_OP27:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP14]], <vscale x 2 x float> [[VP_OP24]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_OP28:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP27]], <vscale x 2 x float> [[VP_GATHER23]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_OP29:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fsub.nxv2f32(<vscale x 2 x float> [[VP_OP28]], <vscale x 2 x float> [[VP_OP26]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_OP30:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP22]], <vscale x 2 x float> [[VP_OP19]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_OP31:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP30]], <vscale x 2 x float> [[VP_OP10]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_OP32:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP31]], <vscale x 2 x float> [[VP_GATHER16]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    [[VP_OP33:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP32]], <vscale x 2 x float> [[VP_OP13]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]])
; GATHER-NEXT:    call void @llvm.vp.scatter.nxv2f32.nxv2p0(<vscale x 2 x float> [[VP_OP29]], <vscale x 2 x ptr> [[TMP10]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]]), !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    call void @llvm.vp.scatter.nxv2f32.nxv2p0(<vscale x 2 x float> [[VP_OP33]], <vscale x 2 x ptr> [[TMP13]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP8]]), !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    [[TMP32:%.*]] = and i64 [[TMP7]], 4294967295
; GATHER-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP32]]
; GATHER-NEXT:    [[VEC_IND_NEXT]] = add <vscale x 2 x i64> [[VEC_IND]], [[DOTSPLAT2]]
; GATHER-NEXT:    [[TMP33:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[WIDE_TRIP_COUNT]]
; GATHER-NEXT:    br i1 [[TMP33]], label [[FOR_COND_CLEANUP]], label [[VECTOR_BODY]], !llvm.loop [[LOOP5:![0-9]+]]
; GATHER:       for.cond.cleanup:
; GATHER-NEXT:    ret void
; GATHER:       for.body:
; GATHER-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY]] ], [ 0, [[FOR_BODY_PREHEADER]] ]
; GATHER-NEXT:    [[TMP34:%.*]] = mul nuw nsw i64 [[INDVARS_IV]], [[TMP0]]
; GATHER-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds { float, float }, ptr [[ARRAYIDX]], i64 [[TMP34]]
; GATHER-NEXT:    [[ARRAYIDX2_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[ARRAYIDX2]], i64 0, i32 1
; GATHER-NEXT:    [[ARRAYIDX4_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[X]], i64 [[INDVARS_IV]], i32 0
; GATHER-NEXT:    [[ARRAYIDX4_REAL:%.*]] = load float, ptr [[ARRAYIDX4_REALP]], align 4, !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    [[ARRAYIDX4_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[X]], i64 [[INDVARS_IV]], i32 1
; GATHER-NEXT:    [[ARRAYIDX4_IMAG:%.*]] = load float, ptr [[ARRAYIDX4_IMAGP]], align 4, !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    [[ARRAYIDX7_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[Y]], i64 [[INDVARS_IV]], i32 0
; GATHER-NEXT:    [[ARRAYIDX7_REAL:%.*]] = load float, ptr [[ARRAYIDX7_REALP]], align 4, !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    [[ARRAYIDX7_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[Y]], i64 [[INDVARS_IV]], i32 1
; GATHER-NEXT:    [[ARRAYIDX7_IMAG:%.*]] = load float, ptr [[ARRAYIDX7_IMAGP]], align 4, !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    [[MUL_AD10:%.*]] = fmul fast float [[ARRAYIDX7_REAL]], [[TEMP2_COERCE1]]
; GATHER-NEXT:    [[MUL_BC11:%.*]] = fmul fast float [[ARRAYIDX7_IMAG]], [[TEMP2_COERCE0]]
; GATHER-NEXT:    [[MUL_AC8:%.*]] = fmul fast float [[ARRAYIDX7_REAL]], [[TEMP2_COERCE0]]
; GATHER-NEXT:    [[MUL_BD9_NEG:%.*]] = fmul fast float [[ARRAYIDX7_IMAG]], [[TEMP2_COERCE1]]
; GATHER-NEXT:    [[ARRAYIDX2_IMAG:%.*]] = load float, ptr [[ARRAYIDX2_IMAGP]], align 4, !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    [[MUL_AD:%.*]] = fmul fast float [[ARRAYIDX4_REAL]], [[TEMP1_COERCE1]]
; GATHER-NEXT:    [[MUL_BC:%.*]] = fmul fast float [[ARRAYIDX4_IMAG]], [[TEMP1_COERCE0]]
; GATHER-NEXT:    [[ARRAYIDX2_REAL:%.*]] = load float, ptr [[ARRAYIDX2]], align 4, !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    [[MUL_AC:%.*]] = fmul fast float [[ARRAYIDX4_REAL]], [[TEMP1_COERCE0]]
; GATHER-NEXT:    [[MUL_BD_NEG:%.*]] = fmul fast float [[ARRAYIDX4_IMAG]], [[TEMP1_COERCE1]]
; GATHER-NEXT:    [[REASS_ADD:%.*]] = fadd fast float [[MUL_BD9_NEG]], [[MUL_BD_NEG]]
; GATHER-NEXT:    [[ADD_R:%.*]] = fadd fast float [[MUL_AC8]], [[MUL_AC]]
; GATHER-NEXT:    [[MUL_R12:%.*]] = fadd fast float [[ADD_R]], [[ARRAYIDX2_REAL]]
; GATHER-NEXT:    [[ADD_R22:%.*]] = fsub fast float [[MUL_R12]], [[REASS_ADD]]
; GATHER-NEXT:    [[MUL_I13:%.*]] = fadd fast float [[MUL_BC]], [[MUL_AD]]
; GATHER-NEXT:    [[MUL_I:%.*]] = fadd fast float [[MUL_I13]], [[MUL_AD10]]
; GATHER-NEXT:    [[ADD_I:%.*]] = fadd fast float [[MUL_I]], [[ARRAYIDX2_IMAG]]
; GATHER-NEXT:    [[ADD_I23:%.*]] = fadd fast float [[ADD_I]], [[MUL_BC11]]
; GATHER-NEXT:    store float [[ADD_R22]], ptr [[ARRAYIDX2]], align 4, !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    store float [[ADD_I23]], ptr [[ARRAYIDX2_IMAGP]], align 4, !llvm.access.group [[ACC_GRP4]]
; GATHER-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; GATHER-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], [[WIDE_TRIP_COUNT]]
; GATHER-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]], !llvm.loop [[LOOP10:![0-9]+]]
;
; STRIDED-LABEL: @foo(
; STRIDED-NEXT:  entry:
; STRIDED-NEXT:    [[TMP0:%.*]] = zext i32 [[N:%.*]] to i64
; STRIDED-NEXT:    [[CMP_NOT_NOT40:%.*]] = icmp sgt i32 [[J:%.*]], 0
; STRIDED-NEXT:    br i1 [[CMP_NOT_NOT40]], label [[FOR_BODY_PREHEADER:%.*]], label [[FOR_COND_CLEANUP:%.*]]
; STRIDED:       for.body.preheader:
; STRIDED-NEXT:    [[IDXPROM1:%.*]] = sext i32 [[J]] to i64
; STRIDED-NEXT:    [[WIDE_TRIP_COUNT:%.*]] = zext i32 [[J]] to i64
; STRIDED-NEXT:    [[ARRAYIDX:%.*]] = getelementptr { float, float }, ptr [[A:%.*]], i64 [[IDXPROM1]]
; STRIDED-NEXT:    [[TMP1:%.*]] = xor i64 [[WIDE_TRIP_COUNT]], -1
; STRIDED-NEXT:    [[TMP2:%.*]] = call i64 @llvm.vscale.i64()
; STRIDED-NEXT:    [[TMP3:%.*]] = shl i64 [[TMP2]], 1
; STRIDED-NEXT:    [[TMP4:%.*]] = icmp ugt i64 [[TMP3]], [[TMP1]]
; STRIDED-NEXT:    br i1 [[TMP4]], label [[FOR_BODY:%.*]], label [[VECTOR_PH:%.*]]
; STRIDED:       vector.ph:
; STRIDED-NEXT:    [[UGLYGEP:%.*]] = getelementptr i8, ptr [[X:%.*]], i64 4
; STRIDED-NEXT:    [[UGLYGEP1:%.*]] = getelementptr i8, ptr [[Y:%.*]], i64 4
; STRIDED-NEXT:    [[TMP5:%.*]] = shl nsw i64 [[IDXPROM1]], 3
; STRIDED-NEXT:    [[TMP6:%.*]] = or i64 [[TMP5]], 4
; STRIDED-NEXT:    [[UGLYGEP2:%.*]] = getelementptr i8, ptr [[A]], i64 [[TMP6]]
; STRIDED-NEXT:    [[TMP7:%.*]] = shl nuw nsw i64 [[TMP0]], 3
; STRIDED-NEXT:    [[BROADCAST_SPLATINSERT10:%.*]] = insertelement <vscale x 2 x float> poison, float [[TEMP2_COERCE1:%.*]], i64 0
; STRIDED-NEXT:    [[BROADCAST_SPLAT11:%.*]] = shufflevector <vscale x 2 x float> [[BROADCAST_SPLATINSERT10]], <vscale x 2 x float> poison, <vscale x 2 x i32> zeroinitializer
; STRIDED-NEXT:    [[BROADCAST_SPLATINSERT13:%.*]] = insertelement <vscale x 2 x float> poison, float [[TEMP2_COERCE0:%.*]], i64 0
; STRIDED-NEXT:    [[BROADCAST_SPLAT14:%.*]] = shufflevector <vscale x 2 x float> [[BROADCAST_SPLATINSERT13]], <vscale x 2 x float> poison, <vscale x 2 x i32> zeroinitializer
; STRIDED-NEXT:    [[BROADCAST_SPLATINSERT19:%.*]] = insertelement <vscale x 2 x float> poison, float [[TEMP1_COERCE1:%.*]], i64 0
; STRIDED-NEXT:    [[BROADCAST_SPLAT20:%.*]] = shufflevector <vscale x 2 x float> [[BROADCAST_SPLATINSERT19]], <vscale x 2 x float> poison, <vscale x 2 x i32> zeroinitializer
; STRIDED-NEXT:    [[BROADCAST_SPLATINSERT22:%.*]] = insertelement <vscale x 2 x float> poison, float [[TEMP1_COERCE0:%.*]], i64 0
; STRIDED-NEXT:    [[BROADCAST_SPLAT23:%.*]] = shufflevector <vscale x 2 x float> [[BROADCAST_SPLATINSERT22]], <vscale x 2 x float> poison, <vscale x 2 x i32> zeroinitializer
; STRIDED-NEXT:    br label [[VECTOR_BODY:%.*]]
; STRIDED:       vector.body:
; STRIDED-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; STRIDED-NEXT:    [[TMP8:%.*]] = sub i64 [[WIDE_TRIP_COUNT]], [[INDEX]]
; STRIDED-NEXT:    [[TMP9:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP8]], i64 2, i64 0)
; STRIDED-NEXT:    [[TMP10:%.*]] = trunc i64 [[TMP9]] to i32
; STRIDED-NEXT:    [[TMP11:%.*]] = shl i64 [[INDEX]], 3
; STRIDED-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[X]], i64 [[TMP11]]
; STRIDED-NEXT:    [[VP_STRIDED_LOAD:%.*]] = call <vscale x 2 x float> @llvm.experimental.vp.strided.load.nxv2f32.p0.i64(ptr [[TMP12]], i64 8, <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]]), !llvm.access.group [[ACC_GRP4:![0-9]+]]
; STRIDED-NEXT:    [[TMP13:%.*]] = shl i64 [[INDEX]], 3
; STRIDED-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[UGLYGEP]], i64 [[TMP13]]
; STRIDED-NEXT:    [[VP_STRIDED_LOAD7:%.*]] = call <vscale x 2 x float> @llvm.experimental.vp.strided.load.nxv2f32.p0.i64(ptr [[TMP14]], i64 8, <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]]), !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[TMP15:%.*]] = shl i64 [[INDEX]], 3
; STRIDED-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 [[TMP15]]
; STRIDED-NEXT:    [[VP_STRIDED_LOAD8:%.*]] = call <vscale x 2 x float> @llvm.experimental.vp.strided.load.nxv2f32.p0.i64(ptr [[TMP16]], i64 8, <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]]), !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[TMP17:%.*]] = shl i64 [[INDEX]], 3
; STRIDED-NEXT:    [[TMP18:%.*]] = getelementptr i8, ptr [[UGLYGEP1]], i64 [[TMP17]]
; STRIDED-NEXT:    [[VP_STRIDED_LOAD9:%.*]] = call <vscale x 2 x float> @llvm.experimental.vp.strided.load.nxv2f32.p0.i64(ptr [[TMP18]], i64 8, <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]]), !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[VP_OP12:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_STRIDED_LOAD8]], <vscale x 2 x float> [[BROADCAST_SPLAT11]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[VP_OP15:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_STRIDED_LOAD9]], <vscale x 2 x float> [[BROADCAST_SPLAT14]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[VP_OP16:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_STRIDED_LOAD8]], <vscale x 2 x float> [[BROADCAST_SPLAT14]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[VP_OP17:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_STRIDED_LOAD9]], <vscale x 2 x float> [[BROADCAST_SPLAT11]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[TMP19:%.*]] = mul i64 [[INDEX]], [[TMP7]]
; STRIDED-NEXT:    [[TMP20:%.*]] = getelementptr i8, ptr [[UGLYGEP2]], i64 [[TMP19]]
; STRIDED-NEXT:    [[VP_STRIDED_LOAD18:%.*]] = call <vscale x 2 x float> @llvm.experimental.vp.strided.load.nxv2f32.p0.i64(ptr [[TMP20]], i64 [[TMP7]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]]), !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[VP_OP21:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_STRIDED_LOAD]], <vscale x 2 x float> [[BROADCAST_SPLAT20]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[VP_OP24:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_STRIDED_LOAD7]], <vscale x 2 x float> [[BROADCAST_SPLAT23]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[TMP21:%.*]] = mul i64 [[INDEX]], [[TMP7]]
; STRIDED-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[ARRAYIDX]], i64 [[TMP21]]
; STRIDED-NEXT:    [[VP_STRIDED_LOAD25:%.*]] = call <vscale x 2 x float> @llvm.experimental.vp.strided.load.nxv2f32.p0.i64(ptr [[TMP22]], i64 [[TMP7]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]]), !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[VP_OP26:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_STRIDED_LOAD]], <vscale x 2 x float> [[BROADCAST_SPLAT23]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[VP_OP27:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fmul.nxv2f32(<vscale x 2 x float> [[VP_STRIDED_LOAD7]], <vscale x 2 x float> [[BROADCAST_SPLAT20]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[VP_OP28:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP17]], <vscale x 2 x float> [[VP_OP27]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[VP_OP29:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP16]], <vscale x 2 x float> [[VP_OP26]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[VP_OP30:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP29]], <vscale x 2 x float> [[VP_STRIDED_LOAD25]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[VP_OP31:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fsub.nxv2f32(<vscale x 2 x float> [[VP_OP30]], <vscale x 2 x float> [[VP_OP28]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[VP_OP32:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP24]], <vscale x 2 x float> [[VP_OP21]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[VP_OP33:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP32]], <vscale x 2 x float> [[VP_OP12]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[VP_OP34:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP33]], <vscale x 2 x float> [[VP_STRIDED_LOAD18]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[VP_OP35:%.*]] = call fast <vscale x 2 x float> @llvm.vp.fadd.nxv2f32(<vscale x 2 x float> [[VP_OP34]], <vscale x 2 x float> [[VP_OP15]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]])
; STRIDED-NEXT:    [[TMP23:%.*]] = mul i64 [[INDEX]], [[TMP7]]
; STRIDED-NEXT:    [[TMP24:%.*]] = getelementptr i8, ptr [[ARRAYIDX]], i64 [[TMP23]]
; STRIDED-NEXT:    call void @llvm.experimental.vp.strided.store.nxv2f32.p0.i64(<vscale x 2 x float> [[VP_OP31]], ptr [[TMP24]], i64 [[TMP7]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]]), !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[TMP25:%.*]] = mul i64 [[INDEX]], [[TMP7]]
; STRIDED-NEXT:    [[TMP26:%.*]] = getelementptr i8, ptr [[UGLYGEP2]], i64 [[TMP25]]
; STRIDED-NEXT:    call void @llvm.experimental.vp.strided.store.nxv2f32.p0.i64(<vscale x 2 x float> [[VP_OP35]], ptr [[TMP26]], i64 [[TMP7]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i64 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP10]]), !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[TMP27:%.*]] = and i64 [[TMP9]], 4294967295
; STRIDED-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP27]]
; STRIDED-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[WIDE_TRIP_COUNT]]
; STRIDED-NEXT:    br i1 [[TMP28]], label [[FOR_COND_CLEANUP]], label [[VECTOR_BODY]], !llvm.loop [[LOOP5:![0-9]+]]
; STRIDED:       for.cond.cleanup:
; STRIDED-NEXT:    ret void
; STRIDED:       for.body:
; STRIDED-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY]] ], [ 0, [[FOR_BODY_PREHEADER]] ]
; STRIDED-NEXT:    [[TMP29:%.*]] = mul nuw nsw i64 [[INDVARS_IV]], [[TMP0]]
; STRIDED-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds { float, float }, ptr [[ARRAYIDX]], i64 [[TMP29]]
; STRIDED-NEXT:    [[ARRAYIDX2_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[ARRAYIDX2]], i64 0, i32 1
; STRIDED-NEXT:    [[ARRAYIDX4_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[X]], i64 [[INDVARS_IV]], i32 0
; STRIDED-NEXT:    [[ARRAYIDX4_REAL:%.*]] = load float, ptr [[ARRAYIDX4_REALP]], align 4, !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[ARRAYIDX4_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[X]], i64 [[INDVARS_IV]], i32 1
; STRIDED-NEXT:    [[ARRAYIDX4_IMAG:%.*]] = load float, ptr [[ARRAYIDX4_IMAGP]], align 4, !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[ARRAYIDX7_REALP:%.*]] = getelementptr inbounds { float, float }, ptr [[Y]], i64 [[INDVARS_IV]], i32 0
; STRIDED-NEXT:    [[ARRAYIDX7_REAL:%.*]] = load float, ptr [[ARRAYIDX7_REALP]], align 4, !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[ARRAYIDX7_IMAGP:%.*]] = getelementptr inbounds { float, float }, ptr [[Y]], i64 [[INDVARS_IV]], i32 1
; STRIDED-NEXT:    [[ARRAYIDX7_IMAG:%.*]] = load float, ptr [[ARRAYIDX7_IMAGP]], align 4, !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[MUL_AD10:%.*]] = fmul fast float [[ARRAYIDX7_REAL]], [[TEMP2_COERCE1]]
; STRIDED-NEXT:    [[MUL_BC11:%.*]] = fmul fast float [[ARRAYIDX7_IMAG]], [[TEMP2_COERCE0]]
; STRIDED-NEXT:    [[MUL_AC8:%.*]] = fmul fast float [[ARRAYIDX7_REAL]], [[TEMP2_COERCE0]]
; STRIDED-NEXT:    [[MUL_BD9_NEG:%.*]] = fmul fast float [[ARRAYIDX7_IMAG]], [[TEMP2_COERCE1]]
; STRIDED-NEXT:    [[ARRAYIDX2_IMAG:%.*]] = load float, ptr [[ARRAYIDX2_IMAGP]], align 4, !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[MUL_AD:%.*]] = fmul fast float [[ARRAYIDX4_REAL]], [[TEMP1_COERCE1]]
; STRIDED-NEXT:    [[MUL_BC:%.*]] = fmul fast float [[ARRAYIDX4_IMAG]], [[TEMP1_COERCE0]]
; STRIDED-NEXT:    [[ARRAYIDX2_REAL:%.*]] = load float, ptr [[ARRAYIDX2]], align 4, !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[MUL_AC:%.*]] = fmul fast float [[ARRAYIDX4_REAL]], [[TEMP1_COERCE0]]
; STRIDED-NEXT:    [[MUL_BD_NEG:%.*]] = fmul fast float [[ARRAYIDX4_IMAG]], [[TEMP1_COERCE1]]
; STRIDED-NEXT:    [[REASS_ADD:%.*]] = fadd fast float [[MUL_BD9_NEG]], [[MUL_BD_NEG]]
; STRIDED-NEXT:    [[ADD_R:%.*]] = fadd fast float [[MUL_AC8]], [[MUL_AC]]
; STRIDED-NEXT:    [[MUL_R12:%.*]] = fadd fast float [[ADD_R]], [[ARRAYIDX2_REAL]]
; STRIDED-NEXT:    [[ADD_R22:%.*]] = fsub fast float [[MUL_R12]], [[REASS_ADD]]
; STRIDED-NEXT:    [[MUL_I13:%.*]] = fadd fast float [[MUL_BC]], [[MUL_AD]]
; STRIDED-NEXT:    [[MUL_I:%.*]] = fadd fast float [[MUL_I13]], [[MUL_AD10]]
; STRIDED-NEXT:    [[ADD_I:%.*]] = fadd fast float [[MUL_I]], [[ARRAYIDX2_IMAG]]
; STRIDED-NEXT:    [[ADD_I23:%.*]] = fadd fast float [[ADD_I]], [[MUL_BC11]]
; STRIDED-NEXT:    store float [[ADD_R22]], ptr [[ARRAYIDX2]], align 4, !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    store float [[ADD_I23]], ptr [[ARRAYIDX2_IMAGP]], align 4, !llvm.access.group [[ACC_GRP4]]
; STRIDED-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; STRIDED-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], [[WIDE_TRIP_COUNT]]
; STRIDED-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]], !llvm.loop [[LOOP10:![0-9]+]]
;
entry:
  %0 = zext i32 %n to i64
  %cmp.not.not40 = icmp sgt i32 %j, 0
  br i1 %cmp.not.not40, label %for.body.preheader, label %for.cond.cleanup

for.body.preheader:                               ; preds = %entry
  %idxprom1 = sext i32 %j to i64
  %wide.trip.count = zext i32 %j to i64
  %arrayidx = getelementptr inbounds { float, float }, { float, float }* %A, i64 %idxprom1
  br label %for.body

for.cond.cleanup.loopexit:                        ; preds = %for.body
  br label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond.cleanup.loopexit, %entry
  ret void

for.body:                                         ; preds = %for.body.preheader, %for.body
  %indvars.iv = phi i64 [ 0, %for.body.preheader ], [ %indvars.iv.next, %for.body ]
  %1 = mul nuw nsw i64 %indvars.iv, %0
  %arrayidx2 = getelementptr inbounds { float, float }, { float, float }* %arrayidx, i64 %1
  %arrayidx2.realp = getelementptr inbounds { float, float }, { float, float }* %arrayidx2, i64 0, i32 0
  %arrayidx2.imagp = getelementptr inbounds { float, float }, { float, float }* %arrayidx2, i64 0, i32 1
  %arrayidx4.realp = getelementptr inbounds { float, float }, { float, float }* %x, i64 %indvars.iv, i32 0
  %arrayidx4.real = load float, float* %arrayidx4.realp, align 4, !llvm.access.group !4
  %arrayidx4.imagp = getelementptr inbounds { float, float }, { float, float }* %x, i64 %indvars.iv, i32 1
  %arrayidx4.imag = load float, float* %arrayidx4.imagp, align 4, !llvm.access.group !4
  %arrayidx7.realp = getelementptr inbounds { float, float }, { float, float }* %y, i64 %indvars.iv, i32 0
  %arrayidx7.real = load float, float* %arrayidx7.realp, align 4, !llvm.access.group !4
  %arrayidx7.imagp = getelementptr inbounds { float, float }, { float, float }* %y, i64 %indvars.iv, i32 1
  %arrayidx7.imag = load float, float* %arrayidx7.imagp, align 4, !llvm.access.group !4
  %mul_ad10 = fmul fast float %arrayidx7.real, %temp2.coerce1
  %mul_bc11 = fmul fast float %arrayidx7.imag, %temp2.coerce0
  %mul_ac8 = fmul fast float %arrayidx7.real, %temp2.coerce0
  %mul_bd9.neg = fmul fast float %arrayidx7.imag, %temp2.coerce1
  %arrayidx2.imag = load float, float* %arrayidx2.imagp, align 4, !llvm.access.group !4
  %mul_ad = fmul fast float %arrayidx4.real, %temp1.coerce1
  %mul_bc = fmul fast float %arrayidx4.imag, %temp1.coerce0
  %arrayidx2.real = load float, float* %arrayidx2.realp, align 4, !llvm.access.group !4
  %mul_ac = fmul fast float %arrayidx4.real, %temp1.coerce0
  %mul_bd.neg = fmul fast float %arrayidx4.imag, %temp1.coerce1
  %reass.add = fadd fast float %mul_bd9.neg, %mul_bd.neg
  %add.r = fadd fast float %mul_ac8, %mul_ac
  %mul_r12 = fadd fast float %add.r, %arrayidx2.real
  %add.r22 = fsub fast float %mul_r12, %reass.add
  %mul_i13 = fadd fast float %mul_bc, %mul_ad
  %mul_i = fadd fast float %mul_i13, %mul_ad10
  %add.i = fadd fast float %mul_i, %arrayidx2.imag
  %add.i23 = fadd fast float %add.i, %mul_bc11
  store float %add.r22, float* %arrayidx2.realp, align 4, !llvm.access.group !4
  store float %add.i23, float* %arrayidx2.imagp, align 4, !llvm.access.group !4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond.not, label %for.cond.cleanup.loopexit, label %for.body, !llvm.loop !5
}

attributes #0 = { nofree norecurse nosync nounwind "frame-pointer"="none" "min-legal-vector-width"="0" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-features"="+64bit,+a,+c,+d,+zepi,+f,+m,-relax,-save-restore" "unsafe-fp-math"="true" }

!llvm.module.flags = !{!0, !1, !2}
!llvm.ident = !{!3}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 1, !"target-abi", !"lp64d"}
!2 = !{i32 1, !"SmallDataLimit", i32 8}
!3 = !{!"clang version 14.0.0"}
!4 = distinct !{}
!5 = distinct !{!5, !6, !7, !8}
!6 = !{!"llvm.loop.mustprogress"}
!7 = !{!"llvm.loop.parallel_accesses", !4}
!8 = !{!"llvm.loop.vectorize.enable", i1 true}

