; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -mtriple riscv64 -mattr +m,+a,+f,+d,+zepi \
; RUN:    -scalable-vectorization=only -prefer-predicate-over-epilogue=predicate-dont-vectorize \
; RUN:    -S --passes=loop-vectorize,instcombine,simplifycfg -riscv-v-vector-bits-min=64 < %s -o - \
; RUN:    | FileCheck %s

; Make sure we do not misclassify memory accesses as strided when they are
; strided in the enclosing loop.

; ModuleID = 't.c'
source_filename = "t.c"
target datalayout = "e-m:e-p:64:64-i64:64-i128:128-n32:64-S128"
target triple = "riscv64-unknown-linux-gnu"

; Function Attrs: nofree nosync nounwind memory(argmem: readwrite) vscale_range(1,1024)
define dso_local void @kernel_atax(i32 noundef signext %nx, i32 noundef signext %ny, ptr nocapture noundef readonly %A, ptr nocapture noundef readonly %x, ptr nocapture noundef %y, ptr nocapture noundef %tmp) local_unnamed_addr #0 {
; CHECK-LABEL: @kernel_atax(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP58:%.*]] = icmp sgt i32 [[NX:%.*]], 0
; CHECK-NEXT:    br i1 [[CMP58]], label [[FOR_BODY_LR_PH:%.*]], label [[FOR_END32:%.*]]
; CHECK:       for.body.lr.ph:
; CHECK-NEXT:    [[CMP254:%.*]] = icmp sgt i32 [[NY:%.*]], 0
; CHECK-NEXT:    [[WIDE_TRIP_COUNT66:%.*]] = zext i32 [[NX]] to i64
; CHECK-NEXT:    [[WIDE_TRIP_COUNT:%.*]] = zext i32 [[NY]] to i64
; CHECK-NEXT:    [[WIDE_TRIP_COUNT62:%.*]] = zext i32 [[NY]] to i64
; CHECK-NEXT:    [[TMP0:%.*]] = shl nuw nsw i64 [[WIDE_TRIP_COUNT62]], 3
; CHECK-NEXT:    [[UGLYGEP:%.*]] = getelementptr i8, ptr [[Y:%.*]], i64 [[TMP0]]
; CHECK-NEXT:    br label [[FOR_BODY:%.*]]
; CHECK:       for.body:
; CHECK-NEXT:    [[INDVARS_IV64:%.*]] = phi i64 [ 0, [[FOR_BODY_LR_PH]] ], [ [[INDVARS_IV_NEXT65:%.*]], [[FOR_INC30:%.*]] ]
; CHECK-NEXT:    [[TMP1:%.*]] = mul nuw nsw i64 [[INDVARS_IV64]], 32000
; CHECK-NEXT:    [[UGLYGEP1:%.*]] = getelementptr i8, ptr [[A:%.*]], i64 [[TMP1]]
; CHECK-NEXT:    [[TMP2:%.*]] = add nuw i64 [[TMP0]], [[TMP1]]
; CHECK-NEXT:    [[UGLYGEP2:%.*]] = getelementptr i8, ptr [[A]], i64 [[TMP2]]
; CHECK-NEXT:    [[TMP3:%.*]] = shl nuw nsw i64 [[INDVARS_IV64]], 3
; CHECK-NEXT:    [[UGLYGEP3:%.*]] = getelementptr i8, ptr [[TMP:%.*]], i64 [[TMP3]]
; CHECK-NEXT:    [[TMP4:%.*]] = add nuw i64 [[TMP3]], 8
; CHECK-NEXT:    [[UGLYGEP4:%.*]] = getelementptr i8, ptr [[TMP]], i64 [[TMP4]]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds double, ptr [[TMP]], i64 [[INDVARS_IV64]]
; CHECK-NEXT:    store double 0.000000e+00, ptr [[ARRAYIDX]], align 8, !tbaa [[TBAA6:![0-9]+]]
; CHECK-NEXT:    br i1 [[CMP254]], label [[FOR_BODY3:%.*]], label [[FOR_INC30]]
; CHECK:       for.cond14.preheader:
; CHECK-NEXT:    br i1 [[CMP254]], label [[VECTOR_MEMCHECK:%.*]], label [[FOR_INC30]]
; CHECK:       vector.memcheck:
; CHECK-NEXT:    [[BOUND0:%.*]] = icmp ugt ptr [[UGLYGEP2]], [[Y]]
; CHECK-NEXT:    [[BOUND1:%.*]] = icmp ult ptr [[UGLYGEP1]], [[UGLYGEP]]
; CHECK-NEXT:    [[FOUND_CONFLICT:%.*]] = and i1 [[BOUND0]], [[BOUND1]]
; CHECK-NEXT:    [[BOUND05:%.*]] = icmp ugt ptr [[UGLYGEP4]], [[Y]]
; CHECK-NEXT:    [[BOUND16:%.*]] = icmp ult ptr [[UGLYGEP3]], [[UGLYGEP]]
; CHECK-NEXT:    [[FOUND_CONFLICT7:%.*]] = and i1 [[BOUND05]], [[BOUND16]]
; CHECK-NEXT:    [[CONFLICT_RDX:%.*]] = or i1 [[FOUND_CONFLICT]], [[FOUND_CONFLICT7]]
; CHECK-NEXT:    br i1 [[CONFLICT_RDX]], label [[FOR_BODY16:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT11:%.*]] = insertelement <vscale x 1 x ptr> poison, ptr [[ARRAYIDX]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT12:%.*]] = shufflevector <vscale x 1 x ptr> [[BROADCAST_SPLATINSERT11]], <vscale x 1 x ptr> poison, <vscale x 1 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP5:%.*]] = sub i64 [[WIDE_TRIP_COUNT62]], [[INDEX]]
; CHECK-NEXT:    [[TMP6:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP5]], i64 3, i64 0)
; CHECK-NEXT:    [[TMP7:%.*]] = trunc i64 [[TMP6]] to i32
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr inbounds double, ptr [[Y]], i64 [[INDEX]]
; CHECK-NEXT:    [[VP_OP_LOAD:%.*]] = call <vscale x 1 x double> @llvm.vp.load.nxv1f64.p0(ptr [[TMP8]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA6]], !alias.scope !10, !noalias !13
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [4000 x double], ptr [[A]], i64 [[INDVARS_IV64]], i64 [[INDEX]]
; CHECK-NEXT:    [[VP_OP_LOAD10:%.*]] = call <vscale x 1 x double> @llvm.vp.load.nxv1f64.p0(ptr [[TMP9]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA6]], !alias.scope !16
; CHECK-NEXT:    [[VP_GATHER:%.*]] = call <vscale x 1 x double> @llvm.vp.gather.nxv1f64.nxv1p0(<vscale x 1 x ptr> [[BROADCAST_SPLAT12]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP7]])
; CHECK-NEXT:    [[TMP10:%.*]] = call <vscale x 1 x double> @llvm.vp.fmuladd.nxv1f64(<vscale x 1 x double> [[VP_OP_LOAD10]], <vscale x 1 x double> [[VP_GATHER]], <vscale x 1 x double> [[VP_OP_LOAD]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP7]])
; CHECK-NEXT:    call void @llvm.vp.store.nxv1f64.p0(<vscale x 1 x double> [[TMP10]], ptr [[TMP8]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA6]], !alias.scope !10, !noalias !13
; CHECK-NEXT:    [[TMP11:%.*]] = and i64 [[TMP6]], 4294967295
; CHECK-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP11]]
; CHECK-NEXT:    [[TMP12:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[WIDE_TRIP_COUNT62]]
; CHECK-NEXT:    br i1 [[TMP12]], label [[FOR_INC30]], label [[VECTOR_BODY]], !llvm.loop [[LOOP17:![0-9]+]]
; CHECK:       for.body3:
; CHECK-NEXT:    [[TMP13:%.*]] = phi double [ [[TMP16:%.*]], [[FOR_BODY3]] ], [ 0.000000e+00, [[FOR_BODY]] ]
; CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY3]] ], [ 0, [[FOR_BODY]] ]
; CHECK-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr inbounds [4000 x double], ptr [[A]], i64 [[INDVARS_IV64]], i64 [[INDVARS_IV]]
; CHECK-NEXT:    [[TMP14:%.*]] = load double, ptr [[ARRAYIDX9]], align 8, !tbaa [[TBAA6]]
; CHECK-NEXT:    [[ARRAYIDX11:%.*]] = getelementptr inbounds double, ptr [[X:%.*]], i64 [[INDVARS_IV]]
; CHECK-NEXT:    [[TMP15:%.*]] = load double, ptr [[ARRAYIDX11]], align 8, !tbaa [[TBAA6]]
; CHECK-NEXT:    [[TMP16]] = tail call double @llvm.fmuladd.f64(double [[TMP14]], double [[TMP15]], double [[TMP13]])
; CHECK-NEXT:    store double [[TMP16]], ptr [[ARRAYIDX]], align 8, !tbaa [[TBAA6]]
; CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], [[WIDE_TRIP_COUNT]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND14_PREHEADER:%.*]], label [[FOR_BODY3]], !llvm.loop [[LOOP20:![0-9]+]]
; CHECK:       for.body16:
; CHECK-NEXT:    [[INDVARS_IV60:%.*]] = phi i64 [ [[INDVARS_IV_NEXT61:%.*]], [[FOR_BODY16]] ], [ 0, [[VECTOR_MEMCHECK]] ]
; CHECK-NEXT:    [[ARRAYIDX18:%.*]] = getelementptr inbounds double, ptr [[Y]], i64 [[INDVARS_IV60]]
; CHECK-NEXT:    [[TMP17:%.*]] = load double, ptr [[ARRAYIDX18]], align 8, !tbaa [[TBAA6]]
; CHECK-NEXT:    [[ARRAYIDX22:%.*]] = getelementptr inbounds [4000 x double], ptr [[A]], i64 [[INDVARS_IV64]], i64 [[INDVARS_IV60]]
; CHECK-NEXT:    [[TMP18:%.*]] = load double, ptr [[ARRAYIDX22]], align 8, !tbaa [[TBAA6]]
; CHECK-NEXT:    [[TMP19:%.*]] = load double, ptr [[ARRAYIDX]], align 8, !tbaa [[TBAA6]]
; CHECK-NEXT:    [[TMP20:%.*]] = tail call double @llvm.fmuladd.f64(double [[TMP18]], double [[TMP19]], double [[TMP17]])
; CHECK-NEXT:    store double [[TMP20]], ptr [[ARRAYIDX18]], align 8, !tbaa [[TBAA6]]
; CHECK-NEXT:    [[INDVARS_IV_NEXT61]] = add nuw nsw i64 [[INDVARS_IV60]], 1
; CHECK-NEXT:    [[EXITCOND63_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT61]], [[WIDE_TRIP_COUNT62]]
; CHECK-NEXT:    br i1 [[EXITCOND63_NOT]], label [[FOR_INC30]], label [[FOR_BODY16]], !llvm.loop [[LOOP22:![0-9]+]]
; CHECK:       for.inc30:
; CHECK-NEXT:    [[INDVARS_IV_NEXT65]] = add nuw nsw i64 [[INDVARS_IV64]], 1
; CHECK-NEXT:    [[EXITCOND67_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT65]], [[WIDE_TRIP_COUNT66]]
; CHECK-NEXT:    br i1 [[EXITCOND67_NOT]], label [[FOR_END32]], label [[FOR_BODY]], !llvm.loop [[LOOP23:![0-9]+]]
; CHECK:       for.end32:
; CHECK-NEXT:    ret void
;
entry:
  %cmp58 = icmp sgt i32 %nx, 0
  br i1 %cmp58, label %for.body.lr.ph, label %for.end32

for.body.lr.ph:                                   ; preds = %entry
  %cmp254 = icmp sgt i32 %ny, 0
  %wide.trip.count66 = zext i32 %nx to i64
  %wide.trip.count = zext i32 %ny to i64
  %wide.trip.count62 = zext i32 %ny to i64
  br label %for.body

for.body:                                         ; preds = %for.body.lr.ph, %for.inc30
  %indvars.iv64 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next65, %for.inc30 ]
  %arrayidx = getelementptr inbounds double, ptr %tmp, i64 %indvars.iv64
  store double 0.000000e+00, ptr %arrayidx, align 8, !tbaa !6
  br i1 %cmp254, label %for.body3.preheader, label %for.inc30

for.body3.preheader:                              ; preds = %for.body
  br label %for.body3

for.cond14.preheader:                             ; preds = %for.body3
  br i1 %cmp254, label %for.body16.preheader, label %for.inc30

for.body16.preheader:                             ; preds = %for.cond14.preheader
  br label %for.body16

for.body3:                                        ; preds = %for.body3.preheader, %for.body3
  %0 = phi double [ %3, %for.body3 ], [ 0.000000e+00, %for.body3.preheader ]
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body3 ], [ 0, %for.body3.preheader ]
  %arrayidx9 = getelementptr inbounds [4000 x double], ptr %A, i64 %indvars.iv64, i64 %indvars.iv
  %1 = load double, ptr %arrayidx9, align 8, !tbaa !6
  %arrayidx11 = getelementptr inbounds double, ptr %x, i64 %indvars.iv
  %2 = load double, ptr %arrayidx11, align 8, !tbaa !6
  %3 = tail call double @llvm.fmuladd.f64(double %1, double %2, double %0)
  store double %3, ptr %arrayidx, align 8, !tbaa !6
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond.not, label %for.cond14.preheader, label %for.body3, !llvm.loop !10

for.body16:                                       ; preds = %for.body16.preheader, %for.body16
  %indvars.iv60 = phi i64 [ %indvars.iv.next61, %for.body16 ], [ 0, %for.body16.preheader ]
  %arrayidx18 = getelementptr inbounds double, ptr %y, i64 %indvars.iv60
  %4 = load double, ptr %arrayidx18, align 8, !tbaa !6
  %arrayidx22 = getelementptr inbounds [4000 x double], ptr %A, i64 %indvars.iv64, i64 %indvars.iv60
  %5 = load double, ptr %arrayidx22, align 8, !tbaa !6
  %6 = load double, ptr %arrayidx, align 8, !tbaa !6
  %7 = tail call double @llvm.fmuladd.f64(double %5, double %6, double %4)
  store double %7, ptr %arrayidx18, align 8, !tbaa !6
  %indvars.iv.next61 = add nuw nsw i64 %indvars.iv60, 1
  %exitcond63.not = icmp eq i64 %indvars.iv.next61, %wide.trip.count62
  br i1 %exitcond63.not, label %for.inc30.loopexit, label %for.body16, !llvm.loop !13

for.inc30.loopexit:                               ; preds = %for.body16
  br label %for.inc30

for.inc30:                                        ; preds = %for.inc30.loopexit, %for.body, %for.cond14.preheader
  %indvars.iv.next65 = add nuw nsw i64 %indvars.iv64, 1
  %exitcond67.not = icmp eq i64 %indvars.iv.next65, %wide.trip.count66
  br i1 %exitcond67.not, label %for.end32.loopexit, label %for.body, !llvm.loop !14

for.end32.loopexit:                               ; preds = %for.inc30
  br label %for.end32

for.end32:                                        ; preds = %for.end32.loopexit, %entry
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare double @llvm.fmuladd.f64(double, double, double) #1

attributes #0 = { nofree nosync nounwind memory(argmem: readwrite) vscale_range(1,1024) "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="generic-rv64" "target-features"="+64bit,+a,+c,+d,+f,+m,+zepi,+zve32f,+zve32x,+zve64d,+zve64f,+zve64x,+zvl32b,+zvl64b,-relax,-save-restore" }
attributes #1 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!llvm.module.flags = !{!0, !1, !2, !3, !4}
!llvm.ident = !{!5}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 1, !"target-abi", !"lp64d"}
!2 = !{i32 8, !"PIC Level", i32 2}
!3 = !{i32 7, !"PIE Level", i32 2}
!4 = !{i32 1, !"SmallDataLimit", i32 8}
!5 = !{!"clang version 16.0.0"}
!6 = !{!7, !7, i64 0}
!7 = !{!"double", !8, i64 0}
!8 = !{!"omnipotent char", !9, i64 0}
!9 = !{!"Simple C/C++ TBAA"}
!10 = distinct !{!10, !11, !12}
!11 = !{!"llvm.loop.mustprogress"}
!12 = !{!"llvm.loop.vectorize.enable", i1 false}
!13 = distinct !{!13, !11}
!14 = distinct !{!14, !11, !12}
