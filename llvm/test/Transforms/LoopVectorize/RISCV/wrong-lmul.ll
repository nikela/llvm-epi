; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -S -loop-vectorize %s -o - 2>&1 | FileCheck %s

; CHECK: remark: <unknown>:0:0: UserVF ignored because of invalid costs.
; CHECK: remark: <unknown>:0:0: Instruction with invalid costs prevented vectorization at VF=(vscale x 16): add

; ModuleID = 'custom/LoopVectorize/wrong-lmul.c'
source_filename = "custom/LoopVectorize/wrong-lmul.c"
target datalayout = "e-m:e-p:64:64-i64:64-i128:128-n64-S128"
target triple = "riscv64-unknown-linux-gnu"

; Function Attrs: mustprogress nofree norecurse nosync nounwind readnone willreturn
define dso_local <vscale x 16 x i64> @_ZGVENk16vv_foo(<vscale x 16 x i64> noundef %A, <vscale x 16 x i64> noundef %B, i32 zeroext %vl) local_unnamed_addr #0 {
; CHECK-LABEL: @_ZGVENk16vv_foo(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VSCALE:%.*]] = call i32 @llvm.vscale.i32()
; CHECK-NEXT:    [[TMP0:%.*]] = mul i32 [[VSCALE]], 16
; CHECK-NEXT:    [[ASSUME_COND:%.*]] = icmp ule i32 [[VL:%.*]], [[TMP0]]
; CHECK-NEXT:    call void @llvm.assume(i1 [[ASSUME_COND]])
; CHECK-NEXT:    [[VEC_A:%.*]] = alloca <vscale x 16 x i64>, align 128
; CHECK-NEXT:    call void @llvm.vp.store.nxv16i64.p0(<vscale x 16 x i64> [[A:%.*]], ptr [[VEC_A]], <vscale x 16 x i1> shufflevector (<vscale x 16 x i1> insertelement (<vscale x 16 x i1> poison, i1 true, i32 0), <vscale x 16 x i1> poison, <vscale x 16 x i32> zeroinitializer), i32 [[VL]])
; CHECK-NEXT:    [[VEC_B:%.*]] = alloca <vscale x 16 x i64>, align 128
; CHECK-NEXT:    call void @llvm.vp.store.nxv16i64.p0(<vscale x 16 x i64> [[B:%.*]], ptr [[VEC_B]], <vscale x 16 x i1> shufflevector (<vscale x 16 x i1> insertelement (<vscale x 16 x i1> poison, i1 true, i32 0), <vscale x 16 x i1> poison, <vscale x 16 x i32> zeroinitializer), i32 [[VL]])
; CHECK-NEXT:    [[VEC_RET:%.*]] = alloca <vscale x 16 x i64>, align 128
; CHECK-NEXT:    [[VL_CHECK:%.*]] = icmp uge i32 [[VL]], 0
; CHECK-NEXT:    br i1 [[VL_CHECK]], label [[SIMD_LOOP_PREHEADER:%.*]], label [[RETURN:%.*]]
; CHECK:       simd.loop.preheader:
; CHECK-NEXT:    br i1 false, label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[TRIP_COUNT_MINUS_1:%.*]] = sub i32 [[VL]], 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <vscale x 8 x i32> poison, i32 [[TRIP_COUNT_MINUS_1]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <vscale x 8 x i32> [[BROADCAST_SPLATINSERT]], <vscale x 8 x i32> poison, <vscale x 8 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX1:%.*]] = phi i32 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP1:%.*]] = sub i32 [[VL]], [[INDEX1]]
; CHECK-NEXT:    [[TMP2:%.*]] = zext i32 [[TMP1]] to i64
; CHECK-NEXT:    [[TMP3:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP2]], i64 3, i64 3)
; CHECK-NEXT:    [[TMP4:%.*]] = trunc i64 [[TMP3]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = add i32 [[INDEX1]], 0
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT2:%.*]] = insertelement <vscale x 8 x i32> poison, i32 [[INDEX1]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT3:%.*]] = shufflevector <vscale x 8 x i32> [[BROADCAST_SPLATINSERT2]], <vscale x 8 x i32> poison, <vscale x 8 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP6:%.*]] = call <vscale x 8 x i32> @llvm.experimental.stepvector.nxv8i32()
; CHECK-NEXT:    [[TMP7:%.*]] = add <vscale x 8 x i32> zeroinitializer, [[TMP6]]
; CHECK-NEXT:    [[VEC_IV:%.*]] = add <vscale x 8 x i32> [[BROADCAST_SPLAT3]], [[TMP7]]
; CHECK-NEXT:    [[TMP8:%.*]] = icmp ule <vscale x 8 x i32> [[VEC_IV]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i64, ptr [[VEC_A]], i32 [[TMP5]]
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i64, ptr [[TMP9]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD:%.*]] = call <vscale x 8 x i64> @llvm.vp.load.nxv8i64.p0(ptr [[TMP10]], <vscale x 8 x i1> shufflevector (<vscale x 8 x i1> insertelement (<vscale x 8 x i1> poison, i1 true, i32 0), <vscale x 8 x i1> poison, <vscale x 8 x i32> zeroinitializer), i32 [[TMP4]])
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i64, ptr [[VEC_B]], i32 [[TMP5]]
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i64, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD4:%.*]] = call <vscale x 8 x i64> @llvm.vp.load.nxv8i64.p0(ptr [[TMP12]], <vscale x 8 x i1> shufflevector (<vscale x 8 x i1> insertelement (<vscale x 8 x i1> poison, i1 true, i32 0), <vscale x 8 x i1> poison, <vscale x 8 x i32> zeroinitializer), i32 [[TMP4]])
; CHECK-NEXT:    [[VP_OP:%.*]] = call <vscale x 8 x i64> @llvm.vp.add.nxv8i64(<vscale x 8 x i64> [[VP_OP_LOAD4]], <vscale x 8 x i64> [[VP_OP_LOAD]], <vscale x 8 x i1> shufflevector (<vscale x 8 x i1> insertelement (<vscale x 8 x i1> poison, i1 true, i32 0), <vscale x 8 x i1> poison, <vscale x 8 x i32> zeroinitializer), i32 [[TMP4]])
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i64, ptr [[VEC_RET]], i32 [[TMP5]]
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i64, ptr [[TMP13]], i32 0
; CHECK-NEXT:    call void @llvm.vp.store.nxv8i64.p0(<vscale x 8 x i64> [[VP_OP]], ptr [[TMP14]], <vscale x 8 x i1> shufflevector (<vscale x 8 x i1> insertelement (<vscale x 8 x i1> poison, i1 true, i32 0), <vscale x 8 x i1> poison, <vscale x 8 x i32> zeroinitializer), i32 [[TMP4]])
; CHECK-NEXT:    [[TMP15:%.*]] = call i32 @llvm.vscale.i32()
; CHECK-NEXT:    [[TMP16:%.*]] = mul i32 [[TMP15]], 8
; CHECK-NEXT:    [[INDEX_NEXT]] = add i32 [[INDEX1]], [[TMP4]]
; CHECK-NEXT:    [[TMP17:%.*]] = icmp eq i32 [[INDEX_NEXT]], [[VL]]
; CHECK-NEXT:    br i1 [[TMP17]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP5:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br i1 true, label [[RETURN_LOOPEXIT:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i32 [ [[VL]], [[MIDDLE_BLOCK]] ], [ 0, [[SIMD_LOOP_PREHEADER]] ]
; CHECK-NEXT:    br label [[SIMD_LOOP:%.*]]
; CHECK:       simd.loop:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i32 [ [[INDVAR:%.*]], [[SIMD_LOOP_EXIT:%.*]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; CHECK-NEXT:    [[VEC_A_GEP:%.*]] = getelementptr i64, ptr [[VEC_A]], i32 [[INDEX]]
; CHECK-NEXT:    [[VEC_A_ELEM:%.*]] = load i64, ptr [[VEC_A_GEP]], align 8
; CHECK-NEXT:    [[VEC_B_GEP:%.*]] = getelementptr i64, ptr [[VEC_B]], i32 [[INDEX]]
; CHECK-NEXT:    [[VEC_B_ELEM:%.*]] = load i64, ptr [[VEC_B_GEP]], align 8
; CHECK-NEXT:    [[ADD:%.*]] = add nsw i64 [[VEC_B_ELEM]], [[VEC_A_ELEM]]
; CHECK-NEXT:    [[VEC_RET_GEP:%.*]] = getelementptr i64, ptr [[VEC_RET]], i32 [[INDEX]]
; CHECK-NEXT:    store i64 [[ADD]], ptr [[VEC_RET_GEP]], align 8
; CHECK-NEXT:    br label [[SIMD_LOOP_EXIT]]
; CHECK:       simd.loop.exit:
; CHECK-NEXT:    [[INDVAR]] = add nsw i32 [[INDEX]], 1
; CHECK-NEXT:    [[EXIT_COND:%.*]] = icmp eq i32 [[INDVAR]], [[VL]]
; CHECK-NEXT:    br i1 [[EXIT_COND]], label [[RETURN_LOOPEXIT]], label [[SIMD_LOOP]], !llvm.loop [[LOOP10:![0-9]+]]
; CHECK:       return.loopexit:
; CHECK-NEXT:    br label [[RETURN]]
; CHECK:       return:
; CHECK-NEXT:    [[VEC_RET1:%.*]] = call <vscale x 16 x i64> @llvm.vp.load.nxv16i64.p0(ptr [[VEC_RET]], <vscale x 16 x i1> shufflevector (<vscale x 16 x i1> insertelement (<vscale x 16 x i1> poison, i1 true, i32 0), <vscale x 16 x i1> poison, <vscale x 16 x i32> zeroinitializer), i32 [[VL]])
; CHECK-NEXT:    ret <vscale x 16 x i64> [[VEC_RET1]]
;
entry:
  %vscale = call i32 @llvm.vscale.i32()
  %0 = mul i32 %vscale, 16
  %assume.cond = icmp ule i32 %vl, %0
  call void @llvm.assume(i1 %assume.cond)
  %vec.A = alloca <vscale x 16 x i64>, align 128
  call void @llvm.vp.store.nxv16i64.p0(<vscale x 16 x i64> %A, ptr %vec.A, <vscale x 16 x i1> shufflevector (<vscale x 16 x i1> insertelement (<vscale x 16 x i1> poison, i1 true, i32 0), <vscale x 16 x i1> poison, <vscale x 16 x i32> zeroinitializer), i32 %vl)
  %vec.B = alloca <vscale x 16 x i64>, align 128
  call void @llvm.vp.store.nxv16i64.p0(<vscale x 16 x i64> %B, ptr %vec.B, <vscale x 16 x i1> shufflevector (<vscale x 16 x i1> insertelement (<vscale x 16 x i1> poison, i1 true, i32 0), <vscale x 16 x i1> poison, <vscale x 16 x i32> zeroinitializer), i32 %vl)
  %vec.ret = alloca <vscale x 16 x i64>, align 128
  %vl.check = icmp uge i32 %vl, 0
  br i1 %vl.check, label %simd.loop.preheader, label %return

simd.loop.preheader:                              ; preds = %entry
  br label %simd.loop

simd.loop:                                        ; preds = %simd.loop.preheader, %simd.loop.exit
  %index = phi i32 [ %indvar, %simd.loop.exit ], [ 0, %simd.loop.preheader ]
  %vec.A.gep = getelementptr i64, ptr %vec.A, i32 %index
  %vec.A.elem = load i64, ptr %vec.A.gep, align 8
  %vec.B.gep = getelementptr i64, ptr %vec.B, i32 %index
  %vec.B.elem = load i64, ptr %vec.B.gep, align 8
  %add = add nsw i64 %vec.B.elem, %vec.A.elem
  %vec.ret.gep = getelementptr i64, ptr %vec.ret, i32 %index
  store i64 %add, ptr %vec.ret.gep, align 8
  br label %simd.loop.exit

simd.loop.exit:                                   ; preds = %simd.loop
  %indvar = add nsw i32 %index, 1
  %exit.cond = icmp eq i32 %indvar, %vl
  br i1 %exit.cond, label %return.loopexit, label %simd.loop, !llvm.loop !5

return.loopexit:                                  ; preds = %simd.loop.exit
  br label %return

return:                                           ; preds = %return.loopexit, %entry
  %vec.ret1 = call <vscale x 16 x i64> @llvm.vp.load.nxv16i64.p0(ptr %vec.ret, <vscale x 16 x i1> shufflevector (<vscale x 16 x i1> insertelement (<vscale x 16 x i1> poison, i1 true, i32 0), <vscale x 16 x i1> poison, <vscale x 16 x i32> zeroinitializer), i32 %vl)
  ret <vscale x 16 x i64> %vec.ret1
}

; Function Attrs: argmemonly nocallback nofree nosync nounwind willreturn writeonly
declare void @llvm.vp.store.nxv16i64.p0(<vscale x 16 x i64>, ptr nocapture, <vscale x 16 x i1>, i32) #1

; Function Attrs: argmemonly nocallback nofree nosync nounwind readonly willreturn
declare <vscale x 16 x i64> @llvm.vp.load.nxv16i64.p0(ptr nocapture, <vscale x 16 x i1>, i32) #2

; Function Attrs: nocallback nofree nosync nounwind readnone willreturn
declare i32 @llvm.vscale.i32() #3

; Function Attrs: inaccessiblememonly nocallback nofree nosync nounwind willreturn
declare void @llvm.assume(i1 noundef) #4

attributes #0 = { mustprogress nofree norecurse nosync nounwind readnone willreturn "_ZGVENk16vv_foo" "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-features"="+64bit,+a,+c,+d,+f,+m,+zepi,+zve32f,+zve32x,+zve64d,+zve64f,+zve64x,+zvl32b,+zvl64b,-relax,-save-restore" }
attributes #1 = { argmemonly nocallback nofree nosync nounwind willreturn writeonly }
attributes #2 = { argmemonly nocallback nofree nosync nounwind readonly willreturn }
attributes #3 = { nocallback nofree nosync nounwind readnone willreturn }
attributes #4 = { inaccessiblememonly nocallback nofree nosync nounwind willreturn }

!llvm.module.flags = !{!0, !1, !2, !3}
!llvm.ident = !{!4}
!nvvm.annotations = !{}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 1, !"target-abi", !"lp64d"}
!2 = !{i32 7, !"openmp", i32 50}
!3 = !{i32 1, !"SmallDataLimit", i32 8}
!4 = !{!"clang version 16.0.0"}
!5 = distinct !{!5, !6, !7, !8, !9, !10, !11, !12}
!6 = !{!"llvm.loop.unroll.disable"}
!7 = !{!"llvm.loop.vectorize.enable"}
!8 = !{!"llvm.loop.vectorize.width", i32 16}
!9 = !{!"llvm.loop.vectorize.scalable.enable", i32 2}
!10 = !{!"llvm.loop.vectorize.predicate.enable", i1 true}
!11 = !{!"llvm.loop.single.iteration"}
!12 = !{!"llvm.loop.epilogue.forbid"}
