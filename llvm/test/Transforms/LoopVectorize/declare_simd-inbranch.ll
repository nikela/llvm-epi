; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -S -loop-vectorize -prefer-predicate-over-epilogue=predicate-dont-vectorize %s -o - | \
; RUN:   FileCheck %s

; ModuleID = 'custom/LoopVectorize/declare_simd-inbranch.c'
source_filename = "custom/LoopVectorize/declare_simd-inbranch.c"
target datalayout = "e-m:e-p:64:64-i64:64-i128:128-n64-S128"
target triple = "riscv64-unknown-linux-gnu"

; Function Attrs: nounwind
define dso_local void @notinbranch(i64 noundef %N, ptr nocapture noundef writeonly %C, ptr nocapture noundef readonly %A, ptr nocapture noundef readonly %B) local_unnamed_addr #0 {
; CHECK-LABEL: @notinbranch(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i64 [[N:%.*]], 0
; CHECK-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY_PREHEADER:%.*]], label [[SIMD_IF_END:%.*]]
; CHECK:       omp.inner.for.body.preheader:
; CHECK-NEXT:    [[TMP0:%.*]] = sub i64 -1, [[N]]
; CHECK-NEXT:    [[TMP1:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ult i64 [[TMP0]], [[TMP1]]
; CHECK-NEXT:    br i1 [[TMP2]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[TRIP_COUNT_MINUS_1:%.*]] = sub i64 [[N]], 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <vscale x 1 x i64> poison, i64 [[TRIP_COUNT_MINUS_1]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <vscale x 1 x i64> [[BROADCAST_SPLATINSERT]], <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP4:%.*]] = sub i64 [[N]], [[INDEX]]
; CHECK-NEXT:    [[TMP5:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP4]], i64 2, i64 7)
; CHECK-NEXT:    [[TMP6:%.*]] = trunc i64 [[TMP5]] to i32
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT1:%.*]] = insertelement <vscale x 1 x i64> poison, i64 [[INDEX]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT2:%.*]] = shufflevector <vscale x 1 x i64> [[BROADCAST_SPLATINSERT1]], <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP7:%.*]] = call <vscale x 1 x i64> @llvm.experimental.stepvector.nxv1i64()
; CHECK-NEXT:    [[TMP8:%.*]] = add <vscale x 1 x i64> zeroinitializer, [[TMP7]]
; CHECK-NEXT:    [[VEC_IV:%.*]] = add <vscale x 1 x i64> [[BROADCAST_SPLAT2]], [[TMP8]]
; CHECK-NEXT:    [[TMP9:%.*]] = icmp ule <vscale x 1 x i64> [[VEC_IV]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds float, ptr [[A:%.*]], i64 [[TMP3]]
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds float, ptr [[TMP10]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD:%.*]] = call <vscale x 1 x float> @llvm.vp.load.nxv1f32.p0(ptr [[TMP11]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]]), !tbaa [[TBAA5:![0-9]+]], !llvm.access.group [[ACC_GRP9:![0-9]+]]
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds float, ptr [[B:%.*]], i64 [[TMP3]]
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds float, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD3:%.*]] = call <vscale x 1 x float> @llvm.vp.load.nxv1f32.p0(ptr [[TMP13]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP14:%.*]] = call <vscale x 1 x float> @_ZGVEMk1vv_foo(<vscale x 1 x float> [[VP_OP_LOAD]], <vscale x 1 x float> [[VP_OP_LOAD3]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]]), !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP15:%.*]] = getelementptr inbounds float, ptr [[C:%.*]], i64 [[TMP3]]
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds float, ptr [[TMP15]], i32 0
; CHECK-NEXT:    call void @llvm.vp.store.nxv1f32.p0(<vscale x 1 x float> [[TMP14]], ptr [[TMP16]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP17:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP17]]
; CHECK-NEXT:    [[TMP18:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[TMP18]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP10:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br i1 true, label [[SIMD_IF_END_LOOPEXIT:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N]], [[MIDDLE_BLOCK]] ], [ 0, [[OMP_INNER_FOR_BODY_PREHEADER]] ]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[DOTOMP_IV_021:%.*]] = phi i64 [ [[ADD9:%.*]], [[OMP_INNER_FOR_BODY]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds float, ptr [[A]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    [[TMP19:%.*]] = load float, ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr inbounds float, ptr [[B]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    [[TMP20:%.*]] = load float, ptr [[ARRAYIDX7]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CALL:%.*]] = tail call float @foo(float noundef [[TMP19]], float noundef [[TMP20]]) #[[ATTR6:[0-9]+]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds float, ptr [[C]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    store float [[CALL]], ptr [[ARRAYIDX8]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ADD9]] = add nuw nsw i64 [[DOTOMP_IV_021]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[ADD9]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[SIMD_IF_END_LOOPEXIT]], label [[OMP_INNER_FOR_BODY]], !llvm.loop [[LOOP13:![0-9]+]]
; CHECK:       simd.if.end.loopexit:
; CHECK-NEXT:    br label [[SIMD_IF_END]]
; CHECK:       simd.if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cmp = icmp sgt i64 %N, 0
  br i1 %cmp, label %omp.inner.for.body.preheader, label %simd.if.end

omp.inner.for.body.preheader:                     ; preds = %entry
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body.preheader, %omp.inner.for.body
  %.omp.iv.021 = phi i64 [ %add9, %omp.inner.for.body ], [ 0, %omp.inner.for.body.preheader ]
  %arrayidx = getelementptr inbounds float, ptr %A, i64 %.omp.iv.021
  %0 = load float, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  %arrayidx7 = getelementptr inbounds float, ptr %B, i64 %.omp.iv.021
  %1 = load float, ptr %arrayidx7, align 4, !tbaa !5, !llvm.access.group !9
  %call = tail call float @foo(float noundef %0, float noundef %1) #2, !llvm.access.group !9
  %arrayidx8 = getelementptr inbounds float, ptr %C, i64 %.omp.iv.021
  store float %call, ptr %arrayidx8, align 4, !tbaa !5, !llvm.access.group !9
  %add9 = add nuw nsw i64 %.omp.iv.021, 1
  %exitcond.not = icmp eq i64 %add9, %N
  br i1 %exitcond.not, label %simd.if.end.loopexit, label %omp.inner.for.body, !llvm.loop !10

simd.if.end.loopexit:                             ; preds = %omp.inner.for.body
  br label %simd.if.end

simd.if.end:                                      ; preds = %simd.if.end.loopexit, %entry
  ret void
}

; Function Attrs: nounwind
define dso_local void @notinbranch1(i64 noundef %N, ptr nocapture noundef writeonly %C, ptr nocapture noundef readonly %A, ptr nocapture noundef readonly %B) local_unnamed_addr #0 {
; CHECK-LABEL: @notinbranch1(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i64 [[N:%.*]], 0
; CHECK-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY_PREHEADER:%.*]], label [[SIMD_IF_END:%.*]]
; CHECK:       omp.inner.for.body.preheader:
; CHECK-NEXT:    [[TMP0:%.*]] = sub i64 -1, [[N]]
; CHECK-NEXT:    [[TMP1:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ult i64 [[TMP0]], [[TMP1]]
; CHECK-NEXT:    br i1 [[TMP2]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[TRIP_COUNT_MINUS_1:%.*]] = sub i64 [[N]], 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <vscale x 1 x i64> poison, i64 [[TRIP_COUNT_MINUS_1]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <vscale x 1 x i64> [[BROADCAST_SPLATINSERT]], <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP4:%.*]] = sub i64 [[N]], [[INDEX]]
; CHECK-NEXT:    [[TMP5:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP4]], i64 2, i64 7)
; CHECK-NEXT:    [[TMP6:%.*]] = trunc i64 [[TMP5]] to i32
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT1:%.*]] = insertelement <vscale x 1 x i64> poison, i64 [[INDEX]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT2:%.*]] = shufflevector <vscale x 1 x i64> [[BROADCAST_SPLATINSERT1]], <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP7:%.*]] = call <vscale x 1 x i64> @llvm.experimental.stepvector.nxv1i64()
; CHECK-NEXT:    [[TMP8:%.*]] = add <vscale x 1 x i64> zeroinitializer, [[TMP7]]
; CHECK-NEXT:    [[VEC_IV:%.*]] = add <vscale x 1 x i64> [[BROADCAST_SPLAT2]], [[TMP8]]
; CHECK-NEXT:    [[TMP9:%.*]] = icmp ule <vscale x 1 x i64> [[VEC_IV]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds float, ptr [[A:%.*]], i64 [[TMP3]]
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds float, ptr [[TMP10]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD:%.*]] = call <vscale x 1 x float> @llvm.vp.load.nxv1f32.p0(ptr [[TMP11]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds float, ptr [[B:%.*]], i64 [[TMP3]]
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds float, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD3:%.*]] = call <vscale x 1 x float> @llvm.vp.load.nxv1f32.p0(ptr [[TMP13]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP14:%.*]] = call <vscale x 1 x float> @_ZGVEMk1vv_foo(<vscale x 1 x float> [[VP_OP_LOAD]], <vscale x 1 x float> [[VP_OP_LOAD3]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]]), !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP15:%.*]] = getelementptr inbounds float, ptr [[C:%.*]], i64 [[TMP3]]
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds float, ptr [[TMP15]], i32 0
; CHECK-NEXT:    call void @llvm.vp.store.nxv1f32.p0(<vscale x 1 x float> [[TMP14]], ptr [[TMP16]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP17:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP17]]
; CHECK-NEXT:    [[TMP18:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[TMP18]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP15:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br i1 true, label [[SIMD_IF_END_LOOPEXIT:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N]], [[MIDDLE_BLOCK]] ], [ 0, [[OMP_INNER_FOR_BODY_PREHEADER]] ]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[DOTOMP_IV_021:%.*]] = phi i64 [ [[ADD9:%.*]], [[OMP_INNER_FOR_BODY]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds float, ptr [[A]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    [[TMP19:%.*]] = load float, ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr inbounds float, ptr [[B]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    [[TMP20:%.*]] = load float, ptr [[ARRAYIDX7]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CALL:%.*]] = tail call float @foo(float noundef [[TMP19]], float noundef [[TMP20]]) #[[ATTR6]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds float, ptr [[C]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    store float [[CALL]], ptr [[ARRAYIDX8]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ADD9]] = add nuw nsw i64 [[DOTOMP_IV_021]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[ADD9]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[SIMD_IF_END_LOOPEXIT]], label [[OMP_INNER_FOR_BODY]], !llvm.loop [[LOOP16:![0-9]+]]
; CHECK:       simd.if.end.loopexit:
; CHECK-NEXT:    br label [[SIMD_IF_END]]
; CHECK:       simd.if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cmp = icmp sgt i64 %N, 0
  br i1 %cmp, label %omp.inner.for.body.preheader, label %simd.if.end

omp.inner.for.body.preheader:                     ; preds = %entry
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body.preheader, %omp.inner.for.body
  %.omp.iv.021 = phi i64 [ %add9, %omp.inner.for.body ], [ 0, %omp.inner.for.body.preheader ]
  %arrayidx = getelementptr inbounds float, ptr %A, i64 %.omp.iv.021
  %0 = load float, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  %arrayidx7 = getelementptr inbounds float, ptr %B, i64 %.omp.iv.021
  %1 = load float, ptr %arrayidx7, align 4, !tbaa !5, !llvm.access.group !9
  %call = tail call float @foo(float noundef %0, float noundef %1) #2, !llvm.access.group !9
  %arrayidx8 = getelementptr inbounds float, ptr %C, i64 %.omp.iv.021
  store float %call, ptr %arrayidx8, align 4, !tbaa !5, !llvm.access.group !9
  %add9 = add nuw nsw i64 %.omp.iv.021, 1
  %exitcond.not = icmp eq i64 %add9, %N
  br i1 %exitcond.not, label %simd.if.end.loopexit, label %omp.inner.for.body, !llvm.loop !10

simd.if.end.loopexit:                             ; preds = %omp.inner.for.body
  br label %simd.if.end

simd.if.end:                                      ; preds = %simd.if.end.loopexit, %entry
  ret void
}

; Function Attrs: nounwind
define dso_local void @notinbranch2(i64 noundef %N, ptr nocapture noundef writeonly %C, ptr nocapture noundef readonly %A, ptr nocapture noundef readonly %B) local_unnamed_addr #0 {
; CHECK-LABEL: @notinbranch2(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i64 [[N:%.*]], 0
; CHECK-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY_PREHEADER:%.*]], label [[SIMD_IF_END:%.*]]
; CHECK:       omp.inner.for.body.preheader:
; CHECK-NEXT:    [[TMP0:%.*]] = sub i64 -1, [[N]]
; CHECK-NEXT:    [[TMP1:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP2:%.*]] = mul i64 [[TMP1]], 2
; CHECK-NEXT:    [[TMP3:%.*]] = icmp ult i64 [[TMP0]], [[TMP2]]
; CHECK-NEXT:    br i1 [[TMP3]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[TRIP_COUNT_MINUS_1:%.*]] = sub i64 [[N]], 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <vscale x 2 x i64> poison, i64 [[TRIP_COUNT_MINUS_1]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <vscale x 2 x i64> [[BROADCAST_SPLATINSERT]], <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP4:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP5:%.*]] = sub i64 [[N]], [[INDEX]]
; CHECK-NEXT:    [[TMP6:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP5]], i64 2, i64 0)
; CHECK-NEXT:    [[TMP7:%.*]] = trunc i64 [[TMP6]] to i32
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT1:%.*]] = insertelement <vscale x 2 x i64> poison, i64 [[INDEX]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT2:%.*]] = shufflevector <vscale x 2 x i64> [[BROADCAST_SPLATINSERT1]], <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP8:%.*]] = call <vscale x 2 x i64> @llvm.experimental.stepvector.nxv2i64()
; CHECK-NEXT:    [[TMP9:%.*]] = add <vscale x 2 x i64> zeroinitializer, [[TMP8]]
; CHECK-NEXT:    [[VEC_IV:%.*]] = add <vscale x 2 x i64> [[BROADCAST_SPLAT2]], [[TMP9]]
; CHECK-NEXT:    [[TMP10:%.*]] = icmp ule <vscale x 2 x i64> [[VEC_IV]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds float, ptr [[A:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds float, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD:%.*]] = call <vscale x 2 x float> @llvm.vp.load.nxv2f32.p0(ptr [[TMP12]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds float, ptr [[B:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds float, ptr [[TMP13]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD3:%.*]] = call <vscale x 2 x float> @llvm.vp.load.nxv2f32.p0(ptr [[TMP14]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP15:%.*]] = call <vscale x 2 x float> @_ZGVEMk2vv_foo(<vscale x 2 x float> [[VP_OP_LOAD]], <vscale x 2 x float> [[VP_OP_LOAD3]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP7]]), !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds float, ptr [[C:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr inbounds float, ptr [[TMP16]], i32 0
; CHECK-NEXT:    call void @llvm.vp.store.nxv2f32.p0(<vscale x 2 x float> [[TMP15]], ptr [[TMP17]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP18:%.*]] = zext i32 [[TMP7]] to i64
; CHECK-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP18]]
; CHECK-NEXT:    [[TMP19:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[TMP19]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP17:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br i1 true, label [[SIMD_IF_END_LOOPEXIT:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N]], [[MIDDLE_BLOCK]] ], [ 0, [[OMP_INNER_FOR_BODY_PREHEADER]] ]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[DOTOMP_IV_021:%.*]] = phi i64 [ [[ADD9:%.*]], [[OMP_INNER_FOR_BODY]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds float, ptr [[A]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    [[TMP20:%.*]] = load float, ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr inbounds float, ptr [[B]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    [[TMP21:%.*]] = load float, ptr [[ARRAYIDX7]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CALL:%.*]] = tail call float @foo(float noundef [[TMP20]], float noundef [[TMP21]]) #[[ATTR6]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds float, ptr [[C]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    store float [[CALL]], ptr [[ARRAYIDX8]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ADD9]] = add nuw nsw i64 [[DOTOMP_IV_021]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[ADD9]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[SIMD_IF_END_LOOPEXIT]], label [[OMP_INNER_FOR_BODY]], !llvm.loop [[LOOP18:![0-9]+]]
; CHECK:       simd.if.end.loopexit:
; CHECK-NEXT:    br label [[SIMD_IF_END]]
; CHECK:       simd.if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cmp = icmp sgt i64 %N, 0
  br i1 %cmp, label %omp.inner.for.body.preheader, label %simd.if.end

omp.inner.for.body.preheader:                     ; preds = %entry
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body.preheader, %omp.inner.for.body
  %.omp.iv.021 = phi i64 [ %add9, %omp.inner.for.body ], [ 0, %omp.inner.for.body.preheader ]
  %arrayidx = getelementptr inbounds float, ptr %A, i64 %.omp.iv.021
  %0 = load float, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  %arrayidx7 = getelementptr inbounds float, ptr %B, i64 %.omp.iv.021
  %1 = load float, ptr %arrayidx7, align 4, !tbaa !5, !llvm.access.group !9
  %call = tail call float @foo(float noundef %0, float noundef %1) #2, !llvm.access.group !9
  %arrayidx8 = getelementptr inbounds float, ptr %C, i64 %.omp.iv.021
  store float %call, ptr %arrayidx8, align 4, !tbaa !5, !llvm.access.group !9
  %add9 = add nuw nsw i64 %.omp.iv.021, 1
  %exitcond.not = icmp eq i64 %add9, %N
  br i1 %exitcond.not, label %simd.if.end.loopexit, label %omp.inner.for.body, !llvm.loop !15

simd.if.end.loopexit:                             ; preds = %omp.inner.for.body
  br label %simd.if.end

simd.if.end:                                      ; preds = %simd.if.end.loopexit, %entry
  ret void
}

; Function Attrs: nounwind
define dso_local void @notinbranch4(i64 noundef %N, ptr nocapture noundef writeonly %C, ptr nocapture noundef readonly %A, ptr nocapture noundef readonly %B) local_unnamed_addr #0 {
; CHECK-LABEL: @notinbranch4(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i64 [[N:%.*]], 0
; CHECK-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY_PREHEADER:%.*]], label [[SIMD_IF_END:%.*]]
; CHECK:       omp.inner.for.body.preheader:
; CHECK-NEXT:    [[TMP0:%.*]] = sub i64 -1, [[N]]
; CHECK-NEXT:    [[TMP1:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP2:%.*]] = mul i64 [[TMP1]], 4
; CHECK-NEXT:    [[TMP3:%.*]] = icmp ult i64 [[TMP0]], [[TMP2]]
; CHECK-NEXT:    br i1 [[TMP3]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[TRIP_COUNT_MINUS_1:%.*]] = sub i64 [[N]], 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <vscale x 4 x i64> poison, i64 [[TRIP_COUNT_MINUS_1]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <vscale x 4 x i64> [[BROADCAST_SPLATINSERT]], <vscale x 4 x i64> poison, <vscale x 4 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP4:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP5:%.*]] = sub i64 [[N]], [[INDEX]]
; CHECK-NEXT:    [[TMP6:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP5]], i64 2, i64 1)
; CHECK-NEXT:    [[TMP7:%.*]] = trunc i64 [[TMP6]] to i32
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT1:%.*]] = insertelement <vscale x 4 x i64> poison, i64 [[INDEX]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT2:%.*]] = shufflevector <vscale x 4 x i64> [[BROADCAST_SPLATINSERT1]], <vscale x 4 x i64> poison, <vscale x 4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP8:%.*]] = call <vscale x 4 x i64> @llvm.experimental.stepvector.nxv4i64()
; CHECK-NEXT:    [[TMP9:%.*]] = add <vscale x 4 x i64> zeroinitializer, [[TMP8]]
; CHECK-NEXT:    [[VEC_IV:%.*]] = add <vscale x 4 x i64> [[BROADCAST_SPLAT2]], [[TMP9]]
; CHECK-NEXT:    [[TMP10:%.*]] = icmp ule <vscale x 4 x i64> [[VEC_IV]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds float, ptr [[A:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds float, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD:%.*]] = call <vscale x 4 x float> @llvm.vp.load.nxv4f32.p0(ptr [[TMP12]], <vscale x 4 x i1> shufflevector (<vscale x 4 x i1> insertelement (<vscale x 4 x i1> poison, i1 true, i32 0), <vscale x 4 x i1> poison, <vscale x 4 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds float, ptr [[B:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds float, ptr [[TMP13]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD3:%.*]] = call <vscale x 4 x float> @llvm.vp.load.nxv4f32.p0(ptr [[TMP14]], <vscale x 4 x i1> shufflevector (<vscale x 4 x i1> insertelement (<vscale x 4 x i1> poison, i1 true, i32 0), <vscale x 4 x i1> poison, <vscale x 4 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP15:%.*]] = call <vscale x 4 x float> @_ZGVEMk4vv_foo(<vscale x 4 x float> [[VP_OP_LOAD]], <vscale x 4 x float> [[VP_OP_LOAD3]], <vscale x 4 x i1> shufflevector (<vscale x 4 x i1> insertelement (<vscale x 4 x i1> poison, i1 true, i32 0), <vscale x 4 x i1> poison, <vscale x 4 x i32> zeroinitializer), i32 [[TMP7]]), !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds float, ptr [[C:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr inbounds float, ptr [[TMP16]], i32 0
; CHECK-NEXT:    call void @llvm.vp.store.nxv4f32.p0(<vscale x 4 x float> [[TMP15]], ptr [[TMP17]], <vscale x 4 x i1> shufflevector (<vscale x 4 x i1> insertelement (<vscale x 4 x i1> poison, i1 true, i32 0), <vscale x 4 x i1> poison, <vscale x 4 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP18:%.*]] = zext i32 [[TMP7]] to i64
; CHECK-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP18]]
; CHECK-NEXT:    [[TMP19:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[TMP19]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP19:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br i1 true, label [[SIMD_IF_END_LOOPEXIT:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N]], [[MIDDLE_BLOCK]] ], [ 0, [[OMP_INNER_FOR_BODY_PREHEADER]] ]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[DOTOMP_IV_021:%.*]] = phi i64 [ [[ADD9:%.*]], [[OMP_INNER_FOR_BODY]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds float, ptr [[A]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    [[TMP20:%.*]] = load float, ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr inbounds float, ptr [[B]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    [[TMP21:%.*]] = load float, ptr [[ARRAYIDX7]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CALL:%.*]] = tail call float @foo(float noundef [[TMP20]], float noundef [[TMP21]]) #[[ATTR6]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds float, ptr [[C]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    store float [[CALL]], ptr [[ARRAYIDX8]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ADD9]] = add nuw nsw i64 [[DOTOMP_IV_021]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[ADD9]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[SIMD_IF_END_LOOPEXIT]], label [[OMP_INNER_FOR_BODY]], !llvm.loop [[LOOP20:![0-9]+]]
; CHECK:       simd.if.end.loopexit:
; CHECK-NEXT:    br label [[SIMD_IF_END]]
; CHECK:       simd.if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cmp = icmp sgt i64 %N, 0
  br i1 %cmp, label %omp.inner.for.body.preheader, label %simd.if.end

omp.inner.for.body.preheader:                     ; preds = %entry
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body.preheader, %omp.inner.for.body
  %.omp.iv.021 = phi i64 [ %add9, %omp.inner.for.body ], [ 0, %omp.inner.for.body.preheader ]
  %arrayidx = getelementptr inbounds float, ptr %A, i64 %.omp.iv.021
  %0 = load float, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  %arrayidx7 = getelementptr inbounds float, ptr %B, i64 %.omp.iv.021
  %1 = load float, ptr %arrayidx7, align 4, !tbaa !5, !llvm.access.group !9
  %call = tail call float @foo(float noundef %0, float noundef %1) #2, !llvm.access.group !9
  %arrayidx8 = getelementptr inbounds float, ptr %C, i64 %.omp.iv.021
  store float %call, ptr %arrayidx8, align 4, !tbaa !5, !llvm.access.group !9
  %add9 = add nuw nsw i64 %.omp.iv.021, 1
  %exitcond.not = icmp eq i64 %add9, %N
  br i1 %exitcond.not, label %simd.if.end.loopexit, label %omp.inner.for.body, !llvm.loop !17

simd.if.end.loopexit:                             ; preds = %omp.inner.for.body
  br label %simd.if.end

simd.if.end:                                      ; preds = %simd.if.end.loopexit, %entry
  ret void
}

; Function Attrs: nounwind
define dso_local void @notinbranch8(i64 noundef %N, ptr nocapture noundef writeonly %C, ptr nocapture noundef readonly %A, ptr nocapture noundef readonly %B) local_unnamed_addr #0 {
; CHECK-LABEL: @notinbranch8(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i64 [[N:%.*]], 0
; CHECK-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY_PREHEADER:%.*]], label [[SIMD_IF_END:%.*]]
; CHECK:       omp.inner.for.body.preheader:
; CHECK-NEXT:    [[TMP0:%.*]] = sub i64 -1, [[N]]
; CHECK-NEXT:    [[TMP1:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP2:%.*]] = mul i64 [[TMP1]], 8
; CHECK-NEXT:    [[TMP3:%.*]] = icmp ult i64 [[TMP0]], [[TMP2]]
; CHECK-NEXT:    br i1 [[TMP3]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[TRIP_COUNT_MINUS_1:%.*]] = sub i64 [[N]], 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <vscale x 8 x i64> poison, i64 [[TRIP_COUNT_MINUS_1]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <vscale x 8 x i64> [[BROADCAST_SPLATINSERT]], <vscale x 8 x i64> poison, <vscale x 8 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP4:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP5:%.*]] = sub i64 [[N]], [[INDEX]]
; CHECK-NEXT:    [[TMP6:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP5]], i64 2, i64 2)
; CHECK-NEXT:    [[TMP7:%.*]] = trunc i64 [[TMP6]] to i32
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT1:%.*]] = insertelement <vscale x 8 x i64> poison, i64 [[INDEX]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT2:%.*]] = shufflevector <vscale x 8 x i64> [[BROADCAST_SPLATINSERT1]], <vscale x 8 x i64> poison, <vscale x 8 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP8:%.*]] = call <vscale x 8 x i64> @llvm.experimental.stepvector.nxv8i64()
; CHECK-NEXT:    [[TMP9:%.*]] = add <vscale x 8 x i64> zeroinitializer, [[TMP8]]
; CHECK-NEXT:    [[VEC_IV:%.*]] = add <vscale x 8 x i64> [[BROADCAST_SPLAT2]], [[TMP9]]
; CHECK-NEXT:    [[TMP10:%.*]] = icmp ule <vscale x 8 x i64> [[VEC_IV]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds float, ptr [[A:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds float, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD:%.*]] = call <vscale x 8 x float> @llvm.vp.load.nxv8f32.p0(ptr [[TMP12]], <vscale x 8 x i1> shufflevector (<vscale x 8 x i1> insertelement (<vscale x 8 x i1> poison, i1 true, i32 0), <vscale x 8 x i1> poison, <vscale x 8 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds float, ptr [[B:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds float, ptr [[TMP13]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD3:%.*]] = call <vscale x 8 x float> @llvm.vp.load.nxv8f32.p0(ptr [[TMP14]], <vscale x 8 x i1> shufflevector (<vscale x 8 x i1> insertelement (<vscale x 8 x i1> poison, i1 true, i32 0), <vscale x 8 x i1> poison, <vscale x 8 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP15:%.*]] = call <vscale x 8 x float> @_ZGVEMk8vv_foo(<vscale x 8 x float> [[VP_OP_LOAD]], <vscale x 8 x float> [[VP_OP_LOAD3]], <vscale x 8 x i1> shufflevector (<vscale x 8 x i1> insertelement (<vscale x 8 x i1> poison, i1 true, i32 0), <vscale x 8 x i1> poison, <vscale x 8 x i32> zeroinitializer), i32 [[TMP7]]), !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds float, ptr [[C:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr inbounds float, ptr [[TMP16]], i32 0
; CHECK-NEXT:    call void @llvm.vp.store.nxv8f32.p0(<vscale x 8 x float> [[TMP15]], ptr [[TMP17]], <vscale x 8 x i1> shufflevector (<vscale x 8 x i1> insertelement (<vscale x 8 x i1> poison, i1 true, i32 0), <vscale x 8 x i1> poison, <vscale x 8 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP18:%.*]] = zext i32 [[TMP7]] to i64
; CHECK-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP18]]
; CHECK-NEXT:    [[TMP19:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[TMP19]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP21:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br i1 true, label [[SIMD_IF_END_LOOPEXIT:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N]], [[MIDDLE_BLOCK]] ], [ 0, [[OMP_INNER_FOR_BODY_PREHEADER]] ]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[DOTOMP_IV_021:%.*]] = phi i64 [ [[ADD9:%.*]], [[OMP_INNER_FOR_BODY]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds float, ptr [[A]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    [[TMP20:%.*]] = load float, ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr inbounds float, ptr [[B]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    [[TMP21:%.*]] = load float, ptr [[ARRAYIDX7]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CALL:%.*]] = tail call float @foo(float noundef [[TMP20]], float noundef [[TMP21]]) #[[ATTR6]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds float, ptr [[C]], i64 [[DOTOMP_IV_021]]
; CHECK-NEXT:    store float [[CALL]], ptr [[ARRAYIDX8]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ADD9]] = add nuw nsw i64 [[DOTOMP_IV_021]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[ADD9]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[SIMD_IF_END_LOOPEXIT]], label [[OMP_INNER_FOR_BODY]], !llvm.loop [[LOOP22:![0-9]+]]
; CHECK:       simd.if.end.loopexit:
; CHECK-NEXT:    br label [[SIMD_IF_END]]
; CHECK:       simd.if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cmp = icmp sgt i64 %N, 0
  br i1 %cmp, label %omp.inner.for.body.preheader, label %simd.if.end

omp.inner.for.body.preheader:                     ; preds = %entry
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body.preheader, %omp.inner.for.body
  %.omp.iv.021 = phi i64 [ %add9, %omp.inner.for.body ], [ 0, %omp.inner.for.body.preheader ]
  %arrayidx = getelementptr inbounds float, ptr %A, i64 %.omp.iv.021
  %0 = load float, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  %arrayidx7 = getelementptr inbounds float, ptr %B, i64 %.omp.iv.021
  %1 = load float, ptr %arrayidx7, align 4, !tbaa !5, !llvm.access.group !9
  %call = tail call float @foo(float noundef %0, float noundef %1) #2, !llvm.access.group !9
  %arrayidx8 = getelementptr inbounds float, ptr %C, i64 %.omp.iv.021
  store float %call, ptr %arrayidx8, align 4, !tbaa !5, !llvm.access.group !9
  %add9 = add nuw nsw i64 %.omp.iv.021, 1
  %exitcond.not = icmp eq i64 %add9, %N
  br i1 %exitcond.not, label %simd.if.end.loopexit, label %omp.inner.for.body, !llvm.loop !19

simd.if.end.loopexit:                             ; preds = %omp.inner.for.body
  br label %simd.if.end

simd.if.end:                                      ; preds = %simd.if.end.loopexit, %entry
  ret void
}

; Function Attrs: nounwind
define dso_local void @inbranch(i64 noundef %N, ptr nocapture noundef %C, ptr nocapture noundef readonly %A, ptr nocapture noundef readonly %B) local_unnamed_addr #0 {
; CHECK-LABEL: @inbranch(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i64 [[N:%.*]], 0
; CHECK-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY_PREHEADER:%.*]], label [[SIMD_IF_END:%.*]]
; CHECK:       omp.inner.for.body.preheader:
; CHECK-NEXT:    [[TMP0:%.*]] = sub i64 -1, [[N]]
; CHECK-NEXT:    [[TMP1:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ult i64 [[TMP0]], [[TMP1]]
; CHECK-NEXT:    br i1 [[TMP2]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[TRIP_COUNT_MINUS_1:%.*]] = sub i64 [[N]], 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <vscale x 1 x i64> poison, i64 [[TRIP_COUNT_MINUS_1]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <vscale x 1 x i64> [[BROADCAST_SPLATINSERT]], <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP4:%.*]] = sub i64 [[N]], [[INDEX]]
; CHECK-NEXT:    [[TMP5:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP4]], i64 2, i64 7)
; CHECK-NEXT:    [[TMP6:%.*]] = trunc i64 [[TMP5]] to i32
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT1:%.*]] = insertelement <vscale x 1 x i64> poison, i64 [[INDEX]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT2:%.*]] = shufflevector <vscale x 1 x i64> [[BROADCAST_SPLATINSERT1]], <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP7:%.*]] = call <vscale x 1 x i64> @llvm.experimental.stepvector.nxv1i64()
; CHECK-NEXT:    [[TMP8:%.*]] = add <vscale x 1 x i64> zeroinitializer, [[TMP7]]
; CHECK-NEXT:    [[VEC_IV:%.*]] = add <vscale x 1 x i64> [[BROADCAST_SPLAT2]], [[TMP8]]
; CHECK-NEXT:    [[TMP9:%.*]] = icmp ule <vscale x 1 x i64> [[VEC_IV]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds float, ptr [[C:%.*]], i64 [[TMP3]]
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds float, ptr [[TMP10]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD:%.*]] = call <vscale x 1 x float> @llvm.vp.load.nxv1f32.p0(ptr [[TMP11]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[VP_OP_FCMP:%.*]] = call <vscale x 1 x i1> @llvm.vp.fcmp.nxv1f32(<vscale x 1 x float> [[VP_OP_LOAD]], <vscale x 1 x float> shufflevector (<vscale x 1 x float> insertelement (<vscale x 1 x float> poison, float 4.200000e+01, i32 0), <vscale x 1 x float> poison, <vscale x 1 x i32> zeroinitializer), metadata !"ogt", <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]])
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds float, ptr [[A:%.*]], i64 [[TMP3]]
; CHECK-NEXT:    [[VP_MASK_SELECT:%.*]] = call <vscale x 1 x i1> @llvm.vp.and.nxv1i1(<vscale x 1 x i1> [[TMP9]], <vscale x 1 x i1> [[VP_OP_FCMP]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]])
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds float, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD3:%.*]] = call <vscale x 1 x float> @llvm.vp.load.nxv1f32.p0(ptr [[TMP13]], <vscale x 1 x i1> [[VP_MASK_SELECT]], i32 [[TMP6]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds float, ptr [[B:%.*]], i64 [[TMP3]]
; CHECK-NEXT:    [[TMP15:%.*]] = getelementptr inbounds float, ptr [[TMP14]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD4:%.*]] = call <vscale x 1 x float> @llvm.vp.load.nxv1f32.p0(ptr [[TMP15]], <vscale x 1 x i1> [[VP_MASK_SELECT]], i32 [[TMP6]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP16:%.*]] = call <vscale x 1 x float> @_ZGVEMk1vv_foo(<vscale x 1 x float> [[VP_OP_LOAD3]], <vscale x 1 x float> [[VP_OP_LOAD4]], <vscale x 1 x i1> [[VP_MASK_SELECT]], i32 [[TMP6]]), !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    call void @llvm.vp.store.nxv1f32.p0(<vscale x 1 x float> [[TMP16]], ptr [[TMP11]], <vscale x 1 x i1> [[VP_MASK_SELECT]], i32 [[TMP6]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP17:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP17]]
; CHECK-NEXT:    [[TMP18:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[TMP18]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP23:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br i1 true, label [[SIMD_IF_END_LOOPEXIT:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N]], [[MIDDLE_BLOCK]] ], [ 0, [[OMP_INNER_FOR_BODY_PREHEADER]] ]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[DOTOMP_IV_025:%.*]] = phi i64 [ [[ADD11:%.*]], [[OMP_INNER_FOR_INC:%.*]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds float, ptr [[C]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP19:%.*]] = load float, ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CMP7:%.*]] = fcmp ogt float [[TMP19]], 4.200000e+01
; CHECK-NEXT:    br i1 [[CMP7]], label [[IF_THEN:%.*]], label [[OMP_INNER_FOR_INC]]
; CHECK:       if.then:
; CHECK-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds float, ptr [[A]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP20:%.*]] = load float, ptr [[ARRAYIDX8]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr inbounds float, ptr [[B]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP21:%.*]] = load float, ptr [[ARRAYIDX9]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CALL:%.*]] = tail call float @foo(float noundef [[TMP20]], float noundef [[TMP21]]) #[[ATTR6]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    store float [[CALL]], ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_INC]]
; CHECK:       omp.inner.for.inc:
; CHECK-NEXT:    [[ADD11]] = add nuw nsw i64 [[DOTOMP_IV_025]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[ADD11]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[SIMD_IF_END_LOOPEXIT]], label [[OMP_INNER_FOR_BODY]], !llvm.loop [[LOOP24:![0-9]+]]
; CHECK:       simd.if.end.loopexit:
; CHECK-NEXT:    br label [[SIMD_IF_END]]
; CHECK:       simd.if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cmp = icmp sgt i64 %N, 0
  br i1 %cmp, label %omp.inner.for.body.preheader, label %simd.if.end

omp.inner.for.body.preheader:                     ; preds = %entry
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body.preheader, %omp.inner.for.inc
  %.omp.iv.025 = phi i64 [ %add11, %omp.inner.for.inc ], [ 0, %omp.inner.for.body.preheader ]
  %arrayidx = getelementptr inbounds float, ptr %C, i64 %.omp.iv.025
  %0 = load float, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  %cmp7 = fcmp ogt float %0, 4.200000e+01
  br i1 %cmp7, label %if.then, label %omp.inner.for.inc

if.then:                                          ; preds = %omp.inner.for.body
  %arrayidx8 = getelementptr inbounds float, ptr %A, i64 %.omp.iv.025
  %1 = load float, ptr %arrayidx8, align 4, !tbaa !5, !llvm.access.group !9
  %arrayidx9 = getelementptr inbounds float, ptr %B, i64 %.omp.iv.025
  %2 = load float, ptr %arrayidx9, align 4, !tbaa !5, !llvm.access.group !9
  %call = tail call float @foo(float noundef %1, float noundef %2) #2, !llvm.access.group !9
  store float %call, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  br label %omp.inner.for.inc

omp.inner.for.inc:                                ; preds = %if.then, %omp.inner.for.body
  %add11 = add nuw nsw i64 %.omp.iv.025, 1
  %exitcond.not = icmp eq i64 %add11, %N
  br i1 %exitcond.not, label %simd.if.end.loopexit, label %omp.inner.for.body, !llvm.loop !10

simd.if.end.loopexit:                             ; preds = %omp.inner.for.inc
  br label %simd.if.end

simd.if.end:                                      ; preds = %simd.if.end.loopexit, %entry
  ret void
}

; Function Attrs: nounwind
define dso_local void @inbranch1(i64 noundef %N, ptr nocapture noundef %C, ptr nocapture noundef readonly %A, ptr nocapture noundef readonly %B) local_unnamed_addr #0 {
; CHECK-LABEL: @inbranch1(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i64 [[N:%.*]], 0
; CHECK-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY_PREHEADER:%.*]], label [[SIMD_IF_END:%.*]]
; CHECK:       omp.inner.for.body.preheader:
; CHECK-NEXT:    [[TMP0:%.*]] = sub i64 -1, [[N]]
; CHECK-NEXT:    [[TMP1:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ult i64 [[TMP0]], [[TMP1]]
; CHECK-NEXT:    br i1 [[TMP2]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[TRIP_COUNT_MINUS_1:%.*]] = sub i64 [[N]], 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <vscale x 1 x i64> poison, i64 [[TRIP_COUNT_MINUS_1]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <vscale x 1 x i64> [[BROADCAST_SPLATINSERT]], <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP4:%.*]] = sub i64 [[N]], [[INDEX]]
; CHECK-NEXT:    [[TMP5:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP4]], i64 2, i64 7)
; CHECK-NEXT:    [[TMP6:%.*]] = trunc i64 [[TMP5]] to i32
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT1:%.*]] = insertelement <vscale x 1 x i64> poison, i64 [[INDEX]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT2:%.*]] = shufflevector <vscale x 1 x i64> [[BROADCAST_SPLATINSERT1]], <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP7:%.*]] = call <vscale x 1 x i64> @llvm.experimental.stepvector.nxv1i64()
; CHECK-NEXT:    [[TMP8:%.*]] = add <vscale x 1 x i64> zeroinitializer, [[TMP7]]
; CHECK-NEXT:    [[VEC_IV:%.*]] = add <vscale x 1 x i64> [[BROADCAST_SPLAT2]], [[TMP8]]
; CHECK-NEXT:    [[TMP9:%.*]] = icmp ule <vscale x 1 x i64> [[VEC_IV]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds float, ptr [[C:%.*]], i64 [[TMP3]]
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds float, ptr [[TMP10]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD:%.*]] = call <vscale x 1 x float> @llvm.vp.load.nxv1f32.p0(ptr [[TMP11]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[VP_OP_FCMP:%.*]] = call <vscale x 1 x i1> @llvm.vp.fcmp.nxv1f32(<vscale x 1 x float> [[VP_OP_LOAD]], <vscale x 1 x float> shufflevector (<vscale x 1 x float> insertelement (<vscale x 1 x float> poison, float 4.200000e+01, i32 0), <vscale x 1 x float> poison, <vscale x 1 x i32> zeroinitializer), metadata !"ogt", <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]])
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds float, ptr [[A:%.*]], i64 [[TMP3]]
; CHECK-NEXT:    [[VP_MASK_SELECT:%.*]] = call <vscale x 1 x i1> @llvm.vp.and.nxv1i1(<vscale x 1 x i1> [[TMP9]], <vscale x 1 x i1> [[VP_OP_FCMP]], <vscale x 1 x i1> shufflevector (<vscale x 1 x i1> insertelement (<vscale x 1 x i1> poison, i1 true, i32 0), <vscale x 1 x i1> poison, <vscale x 1 x i32> zeroinitializer), i32 [[TMP6]])
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds float, ptr [[TMP12]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD3:%.*]] = call <vscale x 1 x float> @llvm.vp.load.nxv1f32.p0(ptr [[TMP13]], <vscale x 1 x i1> [[VP_MASK_SELECT]], i32 [[TMP6]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds float, ptr [[B:%.*]], i64 [[TMP3]]
; CHECK-NEXT:    [[TMP15:%.*]] = getelementptr inbounds float, ptr [[TMP14]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD4:%.*]] = call <vscale x 1 x float> @llvm.vp.load.nxv1f32.p0(ptr [[TMP15]], <vscale x 1 x i1> [[VP_MASK_SELECT]], i32 [[TMP6]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP16:%.*]] = call <vscale x 1 x float> @_ZGVEMk1vv_foo(<vscale x 1 x float> [[VP_OP_LOAD3]], <vscale x 1 x float> [[VP_OP_LOAD4]], <vscale x 1 x i1> [[VP_MASK_SELECT]], i32 [[TMP6]]), !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    call void @llvm.vp.store.nxv1f32.p0(<vscale x 1 x float> [[TMP16]], ptr [[TMP11]], <vscale x 1 x i1> [[VP_MASK_SELECT]], i32 [[TMP6]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP17:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP17]]
; CHECK-NEXT:    [[TMP18:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[TMP18]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP25:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br i1 true, label [[SIMD_IF_END_LOOPEXIT:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N]], [[MIDDLE_BLOCK]] ], [ 0, [[OMP_INNER_FOR_BODY_PREHEADER]] ]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[DOTOMP_IV_025:%.*]] = phi i64 [ [[ADD11:%.*]], [[OMP_INNER_FOR_INC:%.*]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds float, ptr [[C]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP19:%.*]] = load float, ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CMP7:%.*]] = fcmp ogt float [[TMP19]], 4.200000e+01
; CHECK-NEXT:    br i1 [[CMP7]], label [[IF_THEN:%.*]], label [[OMP_INNER_FOR_INC]]
; CHECK:       if.then:
; CHECK-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds float, ptr [[A]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP20:%.*]] = load float, ptr [[ARRAYIDX8]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr inbounds float, ptr [[B]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP21:%.*]] = load float, ptr [[ARRAYIDX9]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CALL:%.*]] = tail call float @foo(float noundef [[TMP20]], float noundef [[TMP21]]) #[[ATTR6]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    store float [[CALL]], ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_INC]]
; CHECK:       omp.inner.for.inc:
; CHECK-NEXT:    [[ADD11]] = add nuw nsw i64 [[DOTOMP_IV_025]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[ADD11]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[SIMD_IF_END_LOOPEXIT]], label [[OMP_INNER_FOR_BODY]], !llvm.loop [[LOOP26:![0-9]+]]
; CHECK:       simd.if.end.loopexit:
; CHECK-NEXT:    br label [[SIMD_IF_END]]
; CHECK:       simd.if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cmp = icmp sgt i64 %N, 0
  br i1 %cmp, label %omp.inner.for.body.preheader, label %simd.if.end

omp.inner.for.body.preheader:                     ; preds = %entry
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body.preheader, %omp.inner.for.inc
  %.omp.iv.025 = phi i64 [ %add11, %omp.inner.for.inc ], [ 0, %omp.inner.for.body.preheader ]
  %arrayidx = getelementptr inbounds float, ptr %C, i64 %.omp.iv.025
  %0 = load float, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  %cmp7 = fcmp ogt float %0, 4.200000e+01
  br i1 %cmp7, label %if.then, label %omp.inner.for.inc

if.then:                                          ; preds = %omp.inner.for.body
  %arrayidx8 = getelementptr inbounds float, ptr %A, i64 %.omp.iv.025
  %1 = load float, ptr %arrayidx8, align 4, !tbaa !5, !llvm.access.group !9
  %arrayidx9 = getelementptr inbounds float, ptr %B, i64 %.omp.iv.025
  %2 = load float, ptr %arrayidx9, align 4, !tbaa !5, !llvm.access.group !9
  %call = tail call float @foo(float noundef %1, float noundef %2) #2, !llvm.access.group !9
  store float %call, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  br label %omp.inner.for.inc

omp.inner.for.inc:                                ; preds = %if.then, %omp.inner.for.body
  %add11 = add nuw nsw i64 %.omp.iv.025, 1
  %exitcond.not = icmp eq i64 %add11, %N
  br i1 %exitcond.not, label %simd.if.end.loopexit, label %omp.inner.for.body, !llvm.loop !10

simd.if.end.loopexit:                             ; preds = %omp.inner.for.inc
  br label %simd.if.end

simd.if.end:                                      ; preds = %simd.if.end.loopexit, %entry
  ret void
}

; Function Attrs: nounwind
define dso_local void @inbranch2(i64 noundef %N, ptr nocapture noundef %C, ptr nocapture noundef readonly %A, ptr nocapture noundef readonly %B) local_unnamed_addr #0 {
; CHECK-LABEL: @inbranch2(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i64 [[N:%.*]], 0
; CHECK-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY_PREHEADER:%.*]], label [[SIMD_IF_END:%.*]]
; CHECK:       omp.inner.for.body.preheader:
; CHECK-NEXT:    [[TMP0:%.*]] = sub i64 -1, [[N]]
; CHECK-NEXT:    [[TMP1:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP2:%.*]] = mul i64 [[TMP1]], 2
; CHECK-NEXT:    [[TMP3:%.*]] = icmp ult i64 [[TMP0]], [[TMP2]]
; CHECK-NEXT:    br i1 [[TMP3]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[TRIP_COUNT_MINUS_1:%.*]] = sub i64 [[N]], 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <vscale x 2 x i64> poison, i64 [[TRIP_COUNT_MINUS_1]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <vscale x 2 x i64> [[BROADCAST_SPLATINSERT]], <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP4:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP5:%.*]] = sub i64 [[N]], [[INDEX]]
; CHECK-NEXT:    [[TMP6:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP5]], i64 2, i64 0)
; CHECK-NEXT:    [[TMP7:%.*]] = trunc i64 [[TMP6]] to i32
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT1:%.*]] = insertelement <vscale x 2 x i64> poison, i64 [[INDEX]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT2:%.*]] = shufflevector <vscale x 2 x i64> [[BROADCAST_SPLATINSERT1]], <vscale x 2 x i64> poison, <vscale x 2 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP8:%.*]] = call <vscale x 2 x i64> @llvm.experimental.stepvector.nxv2i64()
; CHECK-NEXT:    [[TMP9:%.*]] = add <vscale x 2 x i64> zeroinitializer, [[TMP8]]
; CHECK-NEXT:    [[VEC_IV:%.*]] = add <vscale x 2 x i64> [[BROADCAST_SPLAT2]], [[TMP9]]
; CHECK-NEXT:    [[TMP10:%.*]] = icmp ule <vscale x 2 x i64> [[VEC_IV]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds float, ptr [[C:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds float, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD:%.*]] = call <vscale x 2 x float> @llvm.vp.load.nxv2f32.p0(ptr [[TMP12]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[VP_OP_FCMP:%.*]] = call <vscale x 2 x i1> @llvm.vp.fcmp.nxv2f32(<vscale x 2 x float> [[VP_OP_LOAD]], <vscale x 2 x float> shufflevector (<vscale x 2 x float> insertelement (<vscale x 2 x float> poison, float 4.200000e+01, i32 0), <vscale x 2 x float> poison, <vscale x 2 x i32> zeroinitializer), metadata !"ogt", <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP7]])
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds float, ptr [[A:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[VP_MASK_SELECT:%.*]] = call <vscale x 2 x i1> @llvm.vp.and.nxv2i1(<vscale x 2 x i1> [[TMP10]], <vscale x 2 x i1> [[VP_OP_FCMP]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP7]])
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds float, ptr [[TMP13]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD3:%.*]] = call <vscale x 2 x float> @llvm.vp.load.nxv2f32.p0(ptr [[TMP14]], <vscale x 2 x i1> [[VP_MASK_SELECT]], i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP15:%.*]] = getelementptr inbounds float, ptr [[B:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds float, ptr [[TMP15]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD4:%.*]] = call <vscale x 2 x float> @llvm.vp.load.nxv2f32.p0(ptr [[TMP16]], <vscale x 2 x i1> [[VP_MASK_SELECT]], i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP17:%.*]] = call <vscale x 2 x float> @_ZGVEMk2vv_foo(<vscale x 2 x float> [[VP_OP_LOAD3]], <vscale x 2 x float> [[VP_OP_LOAD4]], <vscale x 2 x i1> [[VP_MASK_SELECT]], i32 [[TMP7]]), !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    call void @llvm.vp.store.nxv2f32.p0(<vscale x 2 x float> [[TMP17]], ptr [[TMP12]], <vscale x 2 x i1> [[VP_MASK_SELECT]], i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP18:%.*]] = zext i32 [[TMP7]] to i64
; CHECK-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP18]]
; CHECK-NEXT:    [[TMP19:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[TMP19]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP27:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br i1 true, label [[SIMD_IF_END_LOOPEXIT:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N]], [[MIDDLE_BLOCK]] ], [ 0, [[OMP_INNER_FOR_BODY_PREHEADER]] ]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[DOTOMP_IV_025:%.*]] = phi i64 [ [[ADD11:%.*]], [[OMP_INNER_FOR_INC:%.*]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds float, ptr [[C]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP20:%.*]] = load float, ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CMP7:%.*]] = fcmp ogt float [[TMP20]], 4.200000e+01
; CHECK-NEXT:    br i1 [[CMP7]], label [[IF_THEN:%.*]], label [[OMP_INNER_FOR_INC]]
; CHECK:       if.then:
; CHECK-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds float, ptr [[A]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP21:%.*]] = load float, ptr [[ARRAYIDX8]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr inbounds float, ptr [[B]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP22:%.*]] = load float, ptr [[ARRAYIDX9]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CALL:%.*]] = tail call float @foo(float noundef [[TMP21]], float noundef [[TMP22]]) #[[ATTR6]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    store float [[CALL]], ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_INC]]
; CHECK:       omp.inner.for.inc:
; CHECK-NEXT:    [[ADD11]] = add nuw nsw i64 [[DOTOMP_IV_025]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[ADD11]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[SIMD_IF_END_LOOPEXIT]], label [[OMP_INNER_FOR_BODY]], !llvm.loop [[LOOP28:![0-9]+]]
; CHECK:       simd.if.end.loopexit:
; CHECK-NEXT:    br label [[SIMD_IF_END]]
; CHECK:       simd.if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cmp = icmp sgt i64 %N, 0
  br i1 %cmp, label %omp.inner.for.body.preheader, label %simd.if.end

omp.inner.for.body.preheader:                     ; preds = %entry
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body.preheader, %omp.inner.for.inc
  %.omp.iv.025 = phi i64 [ %add11, %omp.inner.for.inc ], [ 0, %omp.inner.for.body.preheader ]
  %arrayidx = getelementptr inbounds float, ptr %C, i64 %.omp.iv.025
  %0 = load float, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  %cmp7 = fcmp ogt float %0, 4.200000e+01
  br i1 %cmp7, label %if.then, label %omp.inner.for.inc

if.then:                                          ; preds = %omp.inner.for.body
  %arrayidx8 = getelementptr inbounds float, ptr %A, i64 %.omp.iv.025
  %1 = load float, ptr %arrayidx8, align 4, !tbaa !5, !llvm.access.group !9
  %arrayidx9 = getelementptr inbounds float, ptr %B, i64 %.omp.iv.025
  %2 = load float, ptr %arrayidx9, align 4, !tbaa !5, !llvm.access.group !9
  %call = tail call float @foo(float noundef %1, float noundef %2) #2, !llvm.access.group !9
  store float %call, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  br label %omp.inner.for.inc

omp.inner.for.inc:                                ; preds = %if.then, %omp.inner.for.body
  %add11 = add nuw nsw i64 %.omp.iv.025, 1
  %exitcond.not = icmp eq i64 %add11, %N
  br i1 %exitcond.not, label %simd.if.end.loopexit, label %omp.inner.for.body, !llvm.loop !15

simd.if.end.loopexit:                             ; preds = %omp.inner.for.inc
  br label %simd.if.end

simd.if.end:                                      ; preds = %simd.if.end.loopexit, %entry
  ret void
}

; Function Attrs: nounwind
define dso_local void @inbranch4(i64 noundef %N, ptr nocapture noundef %C, ptr nocapture noundef readonly %A, ptr nocapture noundef readonly %B) local_unnamed_addr #0 {
; CHECK-LABEL: @inbranch4(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i64 [[N:%.*]], 0
; CHECK-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY_PREHEADER:%.*]], label [[SIMD_IF_END:%.*]]
; CHECK:       omp.inner.for.body.preheader:
; CHECK-NEXT:    [[TMP0:%.*]] = sub i64 -1, [[N]]
; CHECK-NEXT:    [[TMP1:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP2:%.*]] = mul i64 [[TMP1]], 4
; CHECK-NEXT:    [[TMP3:%.*]] = icmp ult i64 [[TMP0]], [[TMP2]]
; CHECK-NEXT:    br i1 [[TMP3]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[TRIP_COUNT_MINUS_1:%.*]] = sub i64 [[N]], 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <vscale x 4 x i64> poison, i64 [[TRIP_COUNT_MINUS_1]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <vscale x 4 x i64> [[BROADCAST_SPLATINSERT]], <vscale x 4 x i64> poison, <vscale x 4 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP4:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP5:%.*]] = sub i64 [[N]], [[INDEX]]
; CHECK-NEXT:    [[TMP6:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP5]], i64 2, i64 1)
; CHECK-NEXT:    [[TMP7:%.*]] = trunc i64 [[TMP6]] to i32
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT1:%.*]] = insertelement <vscale x 4 x i64> poison, i64 [[INDEX]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT2:%.*]] = shufflevector <vscale x 4 x i64> [[BROADCAST_SPLATINSERT1]], <vscale x 4 x i64> poison, <vscale x 4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP8:%.*]] = call <vscale x 4 x i64> @llvm.experimental.stepvector.nxv4i64()
; CHECK-NEXT:    [[TMP9:%.*]] = add <vscale x 4 x i64> zeroinitializer, [[TMP8]]
; CHECK-NEXT:    [[VEC_IV:%.*]] = add <vscale x 4 x i64> [[BROADCAST_SPLAT2]], [[TMP9]]
; CHECK-NEXT:    [[TMP10:%.*]] = icmp ule <vscale x 4 x i64> [[VEC_IV]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds float, ptr [[C:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds float, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD:%.*]] = call <vscale x 4 x float> @llvm.vp.load.nxv4f32.p0(ptr [[TMP12]], <vscale x 4 x i1> shufflevector (<vscale x 4 x i1> insertelement (<vscale x 4 x i1> poison, i1 true, i32 0), <vscale x 4 x i1> poison, <vscale x 4 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[VP_OP_FCMP:%.*]] = call <vscale x 4 x i1> @llvm.vp.fcmp.nxv4f32(<vscale x 4 x float> [[VP_OP_LOAD]], <vscale x 4 x float> shufflevector (<vscale x 4 x float> insertelement (<vscale x 4 x float> poison, float 4.200000e+01, i32 0), <vscale x 4 x float> poison, <vscale x 4 x i32> zeroinitializer), metadata !"ogt", <vscale x 4 x i1> shufflevector (<vscale x 4 x i1> insertelement (<vscale x 4 x i1> poison, i1 true, i32 0), <vscale x 4 x i1> poison, <vscale x 4 x i32> zeroinitializer), i32 [[TMP7]])
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds float, ptr [[A:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[VP_MASK_SELECT:%.*]] = call <vscale x 4 x i1> @llvm.vp.and.nxv4i1(<vscale x 4 x i1> [[TMP10]], <vscale x 4 x i1> [[VP_OP_FCMP]], <vscale x 4 x i1> shufflevector (<vscale x 4 x i1> insertelement (<vscale x 4 x i1> poison, i1 true, i32 0), <vscale x 4 x i1> poison, <vscale x 4 x i32> zeroinitializer), i32 [[TMP7]])
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds float, ptr [[TMP13]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD3:%.*]] = call <vscale x 4 x float> @llvm.vp.load.nxv4f32.p0(ptr [[TMP14]], <vscale x 4 x i1> [[VP_MASK_SELECT]], i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP15:%.*]] = getelementptr inbounds float, ptr [[B:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds float, ptr [[TMP15]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD4:%.*]] = call <vscale x 4 x float> @llvm.vp.load.nxv4f32.p0(ptr [[TMP16]], <vscale x 4 x i1> [[VP_MASK_SELECT]], i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP17:%.*]] = call <vscale x 4 x float> @_ZGVEMk4vv_foo(<vscale x 4 x float> [[VP_OP_LOAD3]], <vscale x 4 x float> [[VP_OP_LOAD4]], <vscale x 4 x i1> [[VP_MASK_SELECT]], i32 [[TMP7]]), !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    call void @llvm.vp.store.nxv4f32.p0(<vscale x 4 x float> [[TMP17]], ptr [[TMP12]], <vscale x 4 x i1> [[VP_MASK_SELECT]], i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP18:%.*]] = zext i32 [[TMP7]] to i64
; CHECK-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP18]]
; CHECK-NEXT:    [[TMP19:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[TMP19]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP29:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br i1 true, label [[SIMD_IF_END_LOOPEXIT:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N]], [[MIDDLE_BLOCK]] ], [ 0, [[OMP_INNER_FOR_BODY_PREHEADER]] ]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[DOTOMP_IV_025:%.*]] = phi i64 [ [[ADD11:%.*]], [[OMP_INNER_FOR_INC:%.*]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds float, ptr [[C]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP20:%.*]] = load float, ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CMP7:%.*]] = fcmp ogt float [[TMP20]], 4.200000e+01
; CHECK-NEXT:    br i1 [[CMP7]], label [[IF_THEN:%.*]], label [[OMP_INNER_FOR_INC]]
; CHECK:       if.then:
; CHECK-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds float, ptr [[A]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP21:%.*]] = load float, ptr [[ARRAYIDX8]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr inbounds float, ptr [[B]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP22:%.*]] = load float, ptr [[ARRAYIDX9]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CALL:%.*]] = tail call float @foo(float noundef [[TMP21]], float noundef [[TMP22]]) #[[ATTR6]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    store float [[CALL]], ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_INC]]
; CHECK:       omp.inner.for.inc:
; CHECK-NEXT:    [[ADD11]] = add nuw nsw i64 [[DOTOMP_IV_025]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[ADD11]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[SIMD_IF_END_LOOPEXIT]], label [[OMP_INNER_FOR_BODY]], !llvm.loop [[LOOP30:![0-9]+]]
; CHECK:       simd.if.end.loopexit:
; CHECK-NEXT:    br label [[SIMD_IF_END]]
; CHECK:       simd.if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cmp = icmp sgt i64 %N, 0
  br i1 %cmp, label %omp.inner.for.body.preheader, label %simd.if.end

omp.inner.for.body.preheader:                     ; preds = %entry
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body.preheader, %omp.inner.for.inc
  %.omp.iv.025 = phi i64 [ %add11, %omp.inner.for.inc ], [ 0, %omp.inner.for.body.preheader ]
  %arrayidx = getelementptr inbounds float, ptr %C, i64 %.omp.iv.025
  %0 = load float, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  %cmp7 = fcmp ogt float %0, 4.200000e+01
  br i1 %cmp7, label %if.then, label %omp.inner.for.inc

if.then:                                          ; preds = %omp.inner.for.body
  %arrayidx8 = getelementptr inbounds float, ptr %A, i64 %.omp.iv.025
  %1 = load float, ptr %arrayidx8, align 4, !tbaa !5, !llvm.access.group !9
  %arrayidx9 = getelementptr inbounds float, ptr %B, i64 %.omp.iv.025
  %2 = load float, ptr %arrayidx9, align 4, !tbaa !5, !llvm.access.group !9
  %call = tail call float @foo(float noundef %1, float noundef %2) #2, !llvm.access.group !9
  store float %call, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  br label %omp.inner.for.inc

omp.inner.for.inc:                                ; preds = %if.then, %omp.inner.for.body
  %add11 = add nuw nsw i64 %.omp.iv.025, 1
  %exitcond.not = icmp eq i64 %add11, %N
  br i1 %exitcond.not, label %simd.if.end.loopexit, label %omp.inner.for.body, !llvm.loop !17

simd.if.end.loopexit:                             ; preds = %omp.inner.for.inc
  br label %simd.if.end

simd.if.end:                                      ; preds = %simd.if.end.loopexit, %entry
  ret void
}

; Function Attrs: nounwind
define dso_local void @inbranch8(i64 noundef %N, ptr nocapture noundef %C, ptr nocapture noundef readonly %A, ptr nocapture noundef readonly %B) local_unnamed_addr #0 {
; CHECK-LABEL: @inbranch8(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i64 [[N:%.*]], 0
; CHECK-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY_PREHEADER:%.*]], label [[SIMD_IF_END:%.*]]
; CHECK:       omp.inner.for.body.preheader:
; CHECK-NEXT:    [[TMP0:%.*]] = sub i64 -1, [[N]]
; CHECK-NEXT:    [[TMP1:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP2:%.*]] = mul i64 [[TMP1]], 8
; CHECK-NEXT:    [[TMP3:%.*]] = icmp ult i64 [[TMP0]], [[TMP2]]
; CHECK-NEXT:    br i1 [[TMP3]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[TRIP_COUNT_MINUS_1:%.*]] = sub i64 [[N]], 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <vscale x 8 x i64> poison, i64 [[TRIP_COUNT_MINUS_1]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <vscale x 8 x i64> [[BROADCAST_SPLATINSERT]], <vscale x 8 x i64> poison, <vscale x 8 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP4:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP5:%.*]] = sub i64 [[N]], [[INDEX]]
; CHECK-NEXT:    [[TMP6:%.*]] = call i64 @llvm.epi.vsetvl(i64 [[TMP5]], i64 2, i64 2)
; CHECK-NEXT:    [[TMP7:%.*]] = trunc i64 [[TMP6]] to i32
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT1:%.*]] = insertelement <vscale x 8 x i64> poison, i64 [[INDEX]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT2:%.*]] = shufflevector <vscale x 8 x i64> [[BROADCAST_SPLATINSERT1]], <vscale x 8 x i64> poison, <vscale x 8 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP8:%.*]] = call <vscale x 8 x i64> @llvm.experimental.stepvector.nxv8i64()
; CHECK-NEXT:    [[TMP9:%.*]] = add <vscale x 8 x i64> zeroinitializer, [[TMP8]]
; CHECK-NEXT:    [[VEC_IV:%.*]] = add <vscale x 8 x i64> [[BROADCAST_SPLAT2]], [[TMP9]]
; CHECK-NEXT:    [[TMP10:%.*]] = icmp ule <vscale x 8 x i64> [[VEC_IV]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds float, ptr [[C:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds float, ptr [[TMP11]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD:%.*]] = call <vscale x 8 x float> @llvm.vp.load.nxv8f32.p0(ptr [[TMP12]], <vscale x 8 x i1> shufflevector (<vscale x 8 x i1> insertelement (<vscale x 8 x i1> poison, i1 true, i32 0), <vscale x 8 x i1> poison, <vscale x 8 x i32> zeroinitializer), i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[VP_OP_FCMP:%.*]] = call <vscale x 8 x i1> @llvm.vp.fcmp.nxv8f32(<vscale x 8 x float> [[VP_OP_LOAD]], <vscale x 8 x float> shufflevector (<vscale x 8 x float> insertelement (<vscale x 8 x float> poison, float 4.200000e+01, i32 0), <vscale x 8 x float> poison, <vscale x 8 x i32> zeroinitializer), metadata !"ogt", <vscale x 8 x i1> shufflevector (<vscale x 8 x i1> insertelement (<vscale x 8 x i1> poison, i1 true, i32 0), <vscale x 8 x i1> poison, <vscale x 8 x i32> zeroinitializer), i32 [[TMP7]])
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds float, ptr [[A:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[VP_MASK_SELECT:%.*]] = call <vscale x 8 x i1> @llvm.vp.and.nxv8i1(<vscale x 8 x i1> [[TMP10]], <vscale x 8 x i1> [[VP_OP_FCMP]], <vscale x 8 x i1> shufflevector (<vscale x 8 x i1> insertelement (<vscale x 8 x i1> poison, i1 true, i32 0), <vscale x 8 x i1> poison, <vscale x 8 x i32> zeroinitializer), i32 [[TMP7]])
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds float, ptr [[TMP13]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD3:%.*]] = call <vscale x 8 x float> @llvm.vp.load.nxv8f32.p0(ptr [[TMP14]], <vscale x 8 x i1> [[VP_MASK_SELECT]], i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP15:%.*]] = getelementptr inbounds float, ptr [[B:%.*]], i64 [[TMP4]]
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds float, ptr [[TMP15]], i32 0
; CHECK-NEXT:    [[VP_OP_LOAD4:%.*]] = call <vscale x 8 x float> @llvm.vp.load.nxv8f32.p0(ptr [[TMP16]], <vscale x 8 x i1> [[VP_MASK_SELECT]], i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP17:%.*]] = call <vscale x 8 x float> @_ZGVEMk8vv_foo(<vscale x 8 x float> [[VP_OP_LOAD3]], <vscale x 8 x float> [[VP_OP_LOAD4]], <vscale x 8 x i1> [[VP_MASK_SELECT]], i32 [[TMP7]]), !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    call void @llvm.vp.store.nxv8f32.p0(<vscale x 8 x float> [[TMP17]], ptr [[TMP12]], <vscale x 8 x i1> [[VP_MASK_SELECT]], i32 [[TMP7]]), !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[TMP18:%.*]] = zext i32 [[TMP7]] to i64
; CHECK-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP18]]
; CHECK-NEXT:    [[TMP19:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[TMP19]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP31:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br i1 true, label [[SIMD_IF_END_LOOPEXIT:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N]], [[MIDDLE_BLOCK]] ], [ 0, [[OMP_INNER_FOR_BODY_PREHEADER]] ]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[DOTOMP_IV_025:%.*]] = phi i64 [ [[ADD11:%.*]], [[OMP_INNER_FOR_INC:%.*]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds float, ptr [[C]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP20:%.*]] = load float, ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CMP7:%.*]] = fcmp ogt float [[TMP20]], 4.200000e+01
; CHECK-NEXT:    br i1 [[CMP7]], label [[IF_THEN:%.*]], label [[OMP_INNER_FOR_INC]]
; CHECK:       if.then:
; CHECK-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds float, ptr [[A]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP21:%.*]] = load float, ptr [[ARRAYIDX8]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr inbounds float, ptr [[B]], i64 [[DOTOMP_IV_025]]
; CHECK-NEXT:    [[TMP22:%.*]] = load float, ptr [[ARRAYIDX9]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    [[CALL:%.*]] = tail call float @foo(float noundef [[TMP21]], float noundef [[TMP22]]) #[[ATTR6]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    store float [[CALL]], ptr [[ARRAYIDX]], align 4, !tbaa [[TBAA5]], !llvm.access.group [[ACC_GRP9]]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_INC]]
; CHECK:       omp.inner.for.inc:
; CHECK-NEXT:    [[ADD11]] = add nuw nsw i64 [[DOTOMP_IV_025]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[ADD11]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[SIMD_IF_END_LOOPEXIT]], label [[OMP_INNER_FOR_BODY]], !llvm.loop [[LOOP32:![0-9]+]]
; CHECK:       simd.if.end.loopexit:
; CHECK-NEXT:    br label [[SIMD_IF_END]]
; CHECK:       simd.if.end:
; CHECK-NEXT:    ret void
;
entry:
  %cmp = icmp sgt i64 %N, 0
  br i1 %cmp, label %omp.inner.for.body.preheader, label %simd.if.end

omp.inner.for.body.preheader:                     ; preds = %entry
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body.preheader, %omp.inner.for.inc
  %.omp.iv.025 = phi i64 [ %add11, %omp.inner.for.inc ], [ 0, %omp.inner.for.body.preheader ]
  %arrayidx = getelementptr inbounds float, ptr %C, i64 %.omp.iv.025
  %0 = load float, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  %cmp7 = fcmp ogt float %0, 4.200000e+01
  br i1 %cmp7, label %if.then, label %omp.inner.for.inc

if.then:                                          ; preds = %omp.inner.for.body
  %arrayidx8 = getelementptr inbounds float, ptr %A, i64 %.omp.iv.025
  %1 = load float, ptr %arrayidx8, align 4, !tbaa !5, !llvm.access.group !9
  %arrayidx9 = getelementptr inbounds float, ptr %B, i64 %.omp.iv.025
  %2 = load float, ptr %arrayidx9, align 4, !tbaa !5, !llvm.access.group !9
  %call = tail call float @foo(float noundef %1, float noundef %2) #2, !llvm.access.group !9
  store float %call, ptr %arrayidx, align 4, !tbaa !5, !llvm.access.group !9
  br label %omp.inner.for.inc

omp.inner.for.inc:                                ; preds = %if.then, %omp.inner.for.body
  %add11 = add nuw nsw i64 %.omp.iv.025, 1
  %exitcond.not = icmp eq i64 %add11, %N
  br i1 %exitcond.not, label %simd.if.end.loopexit, label %omp.inner.for.body, !llvm.loop !19

simd.if.end.loopexit:                             ; preds = %omp.inner.for.inc
  br label %simd.if.end

simd.if.end:                                      ; preds = %simd.if.end.loopexit, %entry
  ret void
}

declare dso_local float @foo(float noundef, float noundef) local_unnamed_addr #1

declare dso_local <vscale x 1 x float> @_ZGVEMk1vv_foo(<vscale x 1 x float> noundef, <vscale x 1 x float> noundef, <vscale x 1 x i1>, i32 zeroext) local_unnamed_addr #1

declare dso_local <vscale x 2 x float> @_ZGVEMk2vv_foo(<vscale x 2 x float> noundef, <vscale x 2 x float> noundef, <vscale x 2 x i1>, i32 zeroext) local_unnamed_addr #1

declare dso_local <vscale x 4 x float> @_ZGVEMk4vv_foo(<vscale x 4 x float> noundef, <vscale x 4 x float> noundef, <vscale x 4 x i1>, i32 zeroext) local_unnamed_addr #1

declare dso_local <vscale x 8 x float> @_ZGVEMk8vv_foo(<vscale x 8 x float> noundef, <vscale x 8 x float> noundef, <vscale x 8 x i1>, i32 zeroext) local_unnamed_addr #1

attributes #0 = { nounwind "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-features"="+64bit,+a,+c,+d,+f,+m,+zepi,+zve32f,+zve32x,+zve64d,+zve64f,+zve64x,+zvl32b,+zvl64b,-relax,-save-restore" }
attributes #1 = { "_ZGVEMk1vv_foo" "_ZGVEMk2vv_foo" "_ZGVEMk4vv_foo" "_ZGVEMk8vv_foo" "frame-pointer"="none" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-features"="+64bit,+a,+c,+d,+f,+m,+zepi,+zve32f,+zve32x,+zve64d,+zve64f,+zve64x,+zvl32b,+zvl64b,-relax,-save-restore" }
attributes #2 = { nounwind }

!llvm.module.flags = !{!0, !1, !2, !3}
!llvm.ident = !{!4}
!nvvm.annotations = !{}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 1, !"target-abi", !"lp64d"}
!2 = !{i32 7, !"openmp", i32 50}
!3 = !{i32 1, !"SmallDataLimit", i32 8}
!4 = !{!"clang version 15.0.0"}
!5 = !{!6, !6, i64 0}
!6 = !{!"float", !7, i64 0}
!7 = !{!"omnipotent char", !8, i64 0}
!8 = !{!"Simple C/C++ TBAA"}
!9 = distinct !{}
!10 = distinct !{!10, !11, !12, !13, !14}
!11 = !{!"llvm.loop.parallel_accesses", !9}
!12 = !{!"llvm.loop.vectorize.width", i32 1}
!13 = !{!"llvm.loop.vectorize.scalable.enable", i1 true}
!14 = !{!"llvm.loop.vectorize.enable", i1 true}
!15 = distinct !{!15, !11, !16, !13, !14}
!16 = !{!"llvm.loop.vectorize.width", i32 2}
!17 = distinct !{!17, !11, !18, !13, !14}
!18 = !{!"llvm.loop.vectorize.width", i32 4}
!19 = distinct !{!19, !11, !20, !13, !14}
!20 = !{!"llvm.loop.vectorize.width", i32 8}
