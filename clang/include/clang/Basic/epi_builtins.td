//==-- epi-builtins.def - EPI RISCV-V Builtin function database --*- C++ -*-==//
//
//                     The LLVM Compiler Infrastructure
//
// This file is distributed under the University of Illinois Open Source
// License. See LICENSE.TXT for details.
//
//===----------------------------------------------------------------------===//
//
// This file defines builtins from EPI.
//
//===----------------------------------------------------------------------===//

// Each record of the class EPIBuiltin defines a collection of builtins (i.e.
// "def vadd : EPIBuiltin" will be used to define things like "vadd_1xi64",
// "vadd_2xi32", etc).
//
// The elements of this collection are defined by an instantiation process the
// range of which is specified by cross product of the LMUL attribute and every
// element in the attribute TypeRange. By default builtins have LMUL = [1, 2,
// 4, 8] so the process is repeated four times.
//
// LMUL represents the fact that the types of values used by that builtin are
// values generated by instructions that are executed under that LMUL. However,
// this does not mean the builtin is necessarily lowered into an instruction
// that executes under the specified LMUL. An example where this happens are
// loads and stores of masks. A mask like `__epi_8xi1` can be generated, for
// instance, by comparing two `__epi_8xi8` (this is LMUL=1) or comparing two
// `__epi_8xi16` (this is LMUL=2). The actual load or store, however, will be
// performed under LMUL=1 because mask registers are not grouped.
//
// TypeRange is a non-empty sequence of basic types:
//
//   c: signed char (8-bit)
//   s: short (16-bit)
//   i: int (32-bit)
//   l: long (64-bit)
//   f: float (32-bit)
//   d: double (64-bit)
//
// This way, given an LMUL, a record with a TypeRange "sil" will cause the
// definition of 3 builtins. Each type "t" in the TypeRange (in this example
// they are short, int, long) is used as a parameter that drives
// the definition of that particular builtin (for the given LMUL).
//
// During the instantiation, types can be transformed or modified using type
// transformers. Given a type "t" the following primitive type transformers can
// be applied to it to yield another type.
//
//   e: type of "t" as is (identity)
//   v: computes a vector type whose element type is "t" for the current LMUL
//   w: computes a vector type identical to what 'v' computes except for the
//      element type which is twice as wide as the element type of 'v'
//   m: computes a vector type identical to what 'v' computes except for the
//      element type which is bool
//   0: void type, ignores "t"
//   u: unsigned long, ignores "t"
//   s: signed long, ignores "t"
//
// So for instance if t is "i", i.e. int, then "e" will yield int again. "v"
// will yield an EPI vector type (assume LMUL=1), so __epi_2xi32. Accordingly
// "w" would yield __epi_2xi64.
//
// A type transformer can be prefixed by other non-primitive type transformers.
//
//   P: constructs a pointer to the current type
//   C: adds const to the type
//   K: requires the integer type to be a constant expression
//   U: given an integer type, computes its unsigned variant
//   I: given a vector type, compute the vector type with integer type
//      elements of the same width
//   F: given a vector type, compute the vector type with floating-point type
//      elements of the same width
//   T: given a vector type, compute a tuple type with a single element of
//      of the vector type. Given a tuple type, add an additional element to
//      the tuple, of the same type as the existing one. A tuple of a single
//      element (e.g Tv) is not valid, so the minimum valid tuple must have two
//      elements (e.g. TTv)
//
// Following with the example above, if t is "i", then "Ue" will yield unsigned
// int and "Fv" will yield __epi_2xf32 (again assuming LMUL=1), Fw would
// yield __epi_2xf64, etc.
//
// Each builtin is then defined by applying each type in TypeRange against the
// sequence of type transformers described in Suffix and Prototype.
//
// The name of the builtin is defined by the Name attribute (which defaults to
// the name of the class) appended (separated with an underscore) the Suffix
// attribute. For instance with Name="foo", Suffix = "v" and TypeRange = "il",
// the builtin generated will be __builtin_epi_foo_2xi32 and
// __builtin_epi_foo_1xi64 (under LMUL=1). If Suffix contains more than one
// type transformer (say "vv") each of the types is separated with an
// underscore as in "__builtin_epi_foo_1xi32_1xi32".
//
// The C/C++ prototype of the builtin is defined by the Prototype attribute.
// Prototype is a non-empty sequence of type transformers, the first of which
// is the return type of the builtin and the rest are the parameters of the
// builtin, in order. For instance if Prototype is "wvv" and TypeRange is "si"
// a first builtin will have type __epi_4xi32 (__epi_4xi16, __epi_4xi16) and the
// second builtin will have type __epi_2xi64 (__epi_2xi32, __epi_2xi32) (again
// under LMUL=1).
//
// There are a number of attributes that are used to constraint the number and
// shape of the builtins generated. Refer to the comments below for them.
class EPIBuiltin<string suffix, string prototype,
                 string type_range>
{
  // Base name that will be prepended __builtin_epi_ and appended the computed
  // Suffix.
  string Name = NAME;
  // If not empty, each instantiated builtin will have this appended after an
  // underscore (_). Suffix is instantiated like Prototype.
  string Suffix = suffix;
  // For each type described in TypeRange we instantiate this Prototype.
  string Prototype = prototype;
  // The different variants of the builtin, parameterised with a type.
  string TypeRange = type_range;

  // This builtin has a masked form.
  bit HasMask = 1;
  // If HasMask == 1, this flag states that this builtin has a first merge
  // operand.
  bit HasMergeOperand = 1;
  // This builtin has a granted vector length parameter in the last position.
  bit HasVL = 1;

  // Reads or writes "memory".
  bit HasSideEffects = 0;

  // This builtin is valid for the given LMUL.
  list<int> LMUL = [1, 2, 4, 8];

  // Means that we won't emit automatic clang CodeGen code for this builtin
  // and it will have to be provided manually. See IntrinsicTypes below.
  bit HasManualCodegen = 1;

  // The default lowering of clang codegen is an error diagnostic saying
  // that this builtin not supported.
  code ManualCodegen = [{ CGM.ErrorUnsupported(E, "EPI builtin");
                          return llvm::UndefValue::get(ResultType); }];
  code ManualCodegenMask = [{ CGM.ErrorUnsupported(E, "EPI builtin");
                              return llvm::UndefValue::get(ResultType); }];

  // We always assign to the ID variable the LLVM intrinsic identifier value.
  // This allows sharing manual code between builtins. In the case this is not
  // ideal (e.g. the code sets a different value unconditionally and a
  // compiler diagnoses a warning for this automatically emitted assignment)
  // setting this to zero will disable emitting the assignment.
  bit CodegenSetID = 1;

  // If HasManualCodegen = 0 then we emit automatic clang codegen. It describes
  // what types we have to use to obtain the specific LLVM intrinsic.
  //
  // -1 means the return type,
  // -2 the mask operand (only meaningful if HasMask)
  // otherwise, k >= 0 meaning the k-th operand (counting from zero) of the
  // codegen'd parameter of the unmasked version. k can't be the mask operand's
  // position.
  list<int> IntrinsicTypes = [];

  // If these names are not empty, this is the ID of the LLVM intrinsic
  // we want to lower to.
  string IntrinsicName = NAME;
  string IntrinsicNameMask = NAME # "_mask";

  // In order to create the compatibility header, the generating script needs to
  // know in which way the instruction can be mapped to the upstream one
  string CompatibilityCode = "";
  string CompatibilityCodeMasked = "";

  // If True, the builtin(s) must be included in the compatibility header
  bit EPIRVVHeader = 0;
}

//===----------------------------------------------------------------------===//
// Basic classes with automatic codegen.
//===----------------------------------------------------------------------===//
class EPIBinBuiltin<string suffix, string prototype, string type_range>
                   : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1, 1, -2];
}

class EPIWidenBinBuiltin<string suffix, string prototype, string type_range>
                       : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1, 0, 1, -2];
}

class EPIBinMaskInBuiltin<string suffix, string prototype, string type_range>
                         : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1, 1, 2];
}

class EPIRelBuiltin<string suffix, string prototype, string type_range>
                   : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1, 0, 1];
}

class EPITerBuiltin<string suffix, string prototype, string type_range>
                   : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1, 1, -2];
}

class EPIWidenTerBuiltin<string suffix, string prototype, string type_range>
                   : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1, 0, 1, -2];
}


class EPIUnaBuiltin<string suffix, string prototype, string type_range>
                   : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1, 0, -2];
}

class EPIMaskUnaBuiltin<string suffix, string prototype, string type_range>
                         : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1];
}

class EPIMaskToIntBuiltin<string suffix, string prototype, string type_range>
                         : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1, 0];
}

class EPIMaskToScalarBuiltin<string suffix, string prototype, string type_range>
                            : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [0];
}

class EPIVecScalarBuiltin<string suffix, string prototype, string type_range>
                         : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1, 1, -2];
}

class EPIScalarToVecBuiltin<string suffix, string prototype,
                            string type_range>
                           : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1, 0];
}

class EPIScalarToScalarVecBuiltin<string suffix, string prototype,
                                  string type_range>
                                 : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1, 1];
}

class EPIVecToScalarBuiltin<string suffix, string prototype,
                            string type_range>
                           : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1, 0];
}

class EPINulBuiltin<string suffix, string prototype, string type_range>
                   : EPIBuiltin<suffix, prototype, type_range>
{
  let HasManualCodegen = 0;
  let IntrinsicTypes = [-1, -2];
}

//===----------------------------------------------------------------------===//
// Builtin definitions.
//===----------------------------------------------------------------------===//
let HasVL = 0, HasMask = 0, HasSideEffects = 1, LMUL = [1],
    ManualCodegen = [{}] in
{
  let EPIRVVHeader = 1,
      CompatibilityCode = [{#define __builtin_epi_${FullName}(rvl, sew, lmul) \
        __builtin_epi_${FullName}_compat(rvl, sew, lmul)

static inline __attribute__((__always_inline__))
  unsigned long int __builtin_epi_${FullName}_compat(
    unsigned long int rvl, unsigned long int sew, unsigned long int lmul) {
  switch (sew) {
  // __epi_e8
  case 0: {
    switch (lmul) {
    // __epi_m1
    case 0:
      return (unsigned long int)vsetvl_e8m1((size_t)rvl);
    // __epi_m2
    case 1:
      return (unsigned long int)vsetvl_e8m2((size_t)rvl);
    // __epi_m4
    case 2:
      return (unsigned long int)vsetvl_e8m4((size_t)rvl);
    // __epi_m8
    case 3:
      return (unsigned long int)vsetvl_e8m8((size_t)rvl);
    }
    break;
  }
  // __epi_e16
  case 1: {
    switch (lmul) {
    // __epi_m1
    case 0:
      return (unsigned long int)vsetvl_e16m1((size_t)rvl);
    // __epi_m2
    case 1:
      return (unsigned long int)vsetvl_e16m2((size_t)rvl);
    // __epi_m4
    case 2:
      return (unsigned long int)vsetvl_e16m4((size_t)rvl);
    // __epi_m8
    case 3:
      return (unsigned long int)vsetvl_e16m8((size_t)rvl);
    }
    break;
  }
  // __epi_e32
  case 2: {
    switch (lmul) {
    // __epi_m1
    case 0:
      return (unsigned long int)vsetvl_e32m1((size_t)rvl);
    // __epi_m2
    case 1:
      return (unsigned long int)vsetvl_e32m2((size_t)rvl);
    // __epi_m4
    case 2:
      return (unsigned long int)vsetvl_e32m4((size_t)rvl);
    // __epi_m8
    case 3:
      return (unsigned long int)vsetvl_e32m8((size_t)rvl);
    }
    break;
  }
  // __epi_e64
  case 3: {
    switch (lmul) {
    // __epi_m1
    case 0:
      return (unsigned long int)vsetvl_e64m1((size_t)rvl);
    // __epi_m2
    case 1:
      return (unsigned long int)vsetvl_e64m2((size_t)rvl);
    // __epi_m4
    case 2:
      return (unsigned long int)vsetvl_e64m4((size_t)rvl);
    // __epi_m8
    case 3:
      return (unsigned long int)vsetvl_e64m8((size_t)rvl);
    }
    break;
  }
  }
  __builtin_trap();
}
}] in
  def vsetvl : EPIBuiltin<"", "UeUeKUeKUe", "l">;

  let EPIRVVHeader = 1,
      CompatibilityCode = [{#define __builtin_epi_${FullName}(sew, lmul) \
        __builtin_epi_${FullName}_compat(sew, lmul)

static inline __attribute__((__always_inline__))
  unsigned long int __builtin_epi_${FullName}_compat(
    unsigned long int sew, unsigned long int lmul) {
  switch (sew) {
  // __epi_e8
  case 0: {
    switch (lmul) {
    // __epi_m1
    case 0:
      return (unsigned long int)vsetvlmax_e8m1();
    // __epi_m2
    case 1:
      return (unsigned long int)vsetvlmax_e8m2();
    // __epi_m4
    case 2:
      return (unsigned long int)vsetvlmax_e8m4();
    // __epi_m8
    case 3:
      return (unsigned long int)vsetvlmax_e8m8();
    }
    break;
  }
  // __epi_e16
  case 1: {
    switch (lmul) {
    // __epi_m1
    case 0:
      return (unsigned long int)vsetvlmax_e16m1();
    // __epi_m2
    case 1:
      return (unsigned long int)vsetvlmax_e16m2();
    // __epi_m4
    case 2:
      return (unsigned long int)vsetvlmax_e16m4();
    // __epi_m8
    case 3:
      return (unsigned long int)vsetvlmax_e16m8();
    }
    break;
  }
  // __epi_e32
  case 2: {
    switch (lmul) {
    // __epi_m1
    case 0:
      return (unsigned long int)vsetvlmax_e32m1();
    // __epi_m2
    case 1:
      return (unsigned long int)vsetvlmax_e32m2();
    // __epi_m4
    case 2:
      return (unsigned long int)vsetvlmax_e32m4();
    // __epi_m8
    case 3:
      return (unsigned long int)vsetvlmax_e32m8();
    }
    break;
  }
  // __epi_e64
  case 3: {
    switch (lmul) {
    // __epi_m1
    case 0:
      return (unsigned long int)vsetvlmax_e64m1();
    // __epi_m2
    case 1:
      return (unsigned long int)vsetvlmax_e64m2();
    // __epi_m4
    case 2:
      return (unsigned long int)vsetvlmax_e64m4();
    // __epi_m8
    case 3:
      return (unsigned long int)vsetvlmax_e64m8();
    }
    break;
  }
  }
  __builtin_trap();
}
}] in
  def vsetvlmax : EPIBuiltin<"", "UeKUeKUe", "l">;
}

let ManualCodegen = [{
  IntrinsicTypes = {ResultType};
  Ops[0] = Builder.CreateBitCast(Ops[0],
      llvm::PointerType::getUnqual(ResultType));
}], ManualCodegenMask = [{
  IntrinsicTypes = {ResultType, Ops[2]->getType()};
  Ops[1] = Builder.CreateBitCast(Ops[1],
      llvm::PointerType::getUnqual(ResultType));
}] in
{
  let EPIRVVHeader = 1,
      CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, vl) \
        vle${Size}_v_${Type}${LMul}((addr), (vl))}],
      CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, addr, mask, vl) \
        vle${Size}_v_${Type}${LMul}_m ((mask), (addr), (vl))}] in
  def vload : EPIBuiltin<"v", "vPCe", "csilfd">;

  def vload_nt : EPIBuiltin<"v", "vPCe", "csilfd">;

  let IntrinsicName = "vload", IntrinsicNameMask = "vload_mask", EPIRVVHeader = 1,
      CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(vle${Size}_v_${UType}${LMul}((addr), (vl)))}],
      CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, addr, mask, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(vle${Size}_v_${UType}${LMul}_m ((mask), (addr), (vl)))}] in
  def vload_unsigned : EPIBuiltin<"v", "vPCUe", "csil">;

  let IntrinsicName = "vload_nt", IntrinsicNameMask = "vload_nt_mask" in
  def vload_nt_unsigned : EPIBuiltin<"v", "vPCUe", "csil">;
}

let ManualCodegen = [{
  IntrinsicTypes = {ResultType};
  Ops[0] = Builder.CreateBitCast(Ops[0],
      llvm::PointerType::getUnqual(ResultType));
}], ManualCodegenMask = [{
  IntrinsicTypes = {ResultType, Ops[3]->getType()};
  Ops[1] = Builder.CreateBitCast(Ops[1],
      llvm::PointerType::getUnqual(ResultType));
}] in
{
  def vload_ext : EPIBuiltin<"v", "vPCeu", "csilfd">;
  let IntrinsicName = "vload_ext", IntrinsicNameMask = "vload_ext_mask" in
    def vload_ext_unsigned : EPIBuiltin<"v", "vPCUeu", "csil">;
}

let ManualCodegen = [{
  IntrinsicTypes = {ResultType};
  Ops[0] = Builder.CreateBitCast(Ops[0],
      llvm::PointerType::getUnqual(ResultType));
}], ManualCodegenMask = [{
  IntrinsicTypes = {ResultType, Ops[3]->getType()};
  Ops[1] = Builder.CreateBitCast(Ops[1],
      llvm::PointerType::getUnqual(ResultType));
}] in
{
  let EPIRVVHeader = 1,
      CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, stride, vl) \
        vlse${Size}_v_${Type}${LMul}((addr), (stride), (vl))}],
      CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, addr, stride, mask, vl) \
        vlse${Size}_v_${Type}${LMul}_m((mask), (addr), (stride), (vl))}] in
  def vload_strided : EPIBuiltin<"v", "vPCes", "csilfd">;

  def vload_nt_strided : EPIBuiltin<"v", "vPCes", "csilfd">;

  let IntrinsicName = "vload_strided",
      IntrinsicNameMask = "vload_strided_mask",
      EPIRVVHeader = 1,
      CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, stride, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(vlse${Size}_v_${UType}${LMul}((addr), (stride), (vl)))}],
      CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, addr, stride, mask, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(vlse${Size}_v_${UType}${LMul}_m((mask), (addr), (stride), (vl)))}] in
  def vload_strided_unsigned : EPIBuiltin<"v", "vPCUes", "csil">;

  let IntrinsicName = "vload_nt_strided",
      IntrinsicNameMask = "vload_nt_strided_mask" in
  def vload_nt_strided_unsigned : EPIBuiltin<"v", "vPCUes", "csil">;
}

let ManualCodegen = [{
  IntrinsicTypes = {ResultType};
  Ops[0] = Builder.CreateBitCast(Ops[0],
      llvm::PointerType::getUnqual(ResultType));
}], ManualCodegenMask = [{
  IntrinsicTypes = {ResultType, Ops[4]->getType()};
  Ops[1] = Builder.CreateBitCast(Ops[1],
      llvm::PointerType::getUnqual(ResultType));
}] in
{
  def vload_ext_strided : EPIBuiltin<"v", "vPCesu", "csilfd">;
  let IntrinsicName = "vload_ext_strided",
      IntrinsicNameMask = "vload_ext_strided_mask" in
    def vload_ext_strided_unsigned : EPIBuiltin<"v", "vPCUesu", "csil">;
}

let ManualCodegen = [{
  IntrinsicTypes = {ResultType, Ops[1]->getType()};
  Ops[0] = Builder.CreateBitCast(Ops[0],
      llvm::PointerType::getUnqual(ResultType));
}], ManualCodegenMask = [{
  IntrinsicTypes = {ResultType, Ops[2]->getType(), Ops[3]->getType()};
  Ops[1] = Builder.CreateBitCast(Ops[1],
      llvm::PointerType::getUnqual(ResultType));
}] in
{
  let EPIRVVHeader = 1,
      CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, index, vl) \
        vluxei${Size}_v_${Type}${LMul}((addr), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(index), (vl))}],
      CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, addr, index, mask, vl) \
        vluxei${Size}_v_${Type}${LMul}_m((mask), (addr), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(index), (vl))}] in
  def vload_indexed : EPIBuiltin<"v", "vPCeIv", "csilfd">;

  def vload_nt_indexed : EPIBuiltin<"v", "vPCeIv", "csilfd">;

  let IntrinsicName = "vload_indexed",
      IntrinsicNameMask = "vload_indexed_mask",
      EPIRVVHeader = 1,
      CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, index, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(vluxei${Size}_v_${UType}${LMul}((addr), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(index), (vl)))}],
      CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, addr, index, mask, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(vluxei${Size}_v_${UType}${LMul}_m((mask), (addr), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(index), (vl)))}] in
  def vload_indexed_unsigned : EPIBuiltin<"v", "vPCUeIv", "csil">;

  let IntrinsicName = "vload_nt_indexed",
      IntrinsicNameMask = "vload_nt_indexed_mask" in
  def vload_nt_indexed_unsigned : EPIBuiltin<"v", "vPCUeIv", "csil">;
}

let ManualCodegen = [{
  IntrinsicTypes = {ResultType, Ops[1]->getType()};
  Ops[0] = Builder.CreateBitCast(Ops[0],
      llvm::PointerType::getUnqual(ResultType));
}], ManualCodegenMask = [{
  IntrinsicTypes = {ResultType, Ops[2]->getType(), Ops[4]->getType()};
  Ops[1] = Builder.CreateBitCast(Ops[1],
      llvm::PointerType::getUnqual(ResultType));
}] in
{
  def vload_ext_indexed : EPIBuiltin<"v", "vPCeIvu", "csilfd">;
  let IntrinsicName = "vload_ext_indexed",
      IntrinsicNameMask = "vload_ext_indexed_mask" in
    def vload_ext_indexed_unsigned : EPIBuiltin<"v", "vPCUeIvu", "csil">;
}

// Load mask.
let Name = "vload", IntrinsicName = "", HasVL = 0, HasMask = 0, LMUL = [1],
    ManualCodegen = [{ {
        clang::CharUnits Align =
            CGM.getNaturalPointeeTypeAlignment(E->getArg(0)->getType());
        llvm::Type *MemType = ConvertTypeForMem(E->getType());
        Ops[0] = Builder.CreateBitCast(Ops[0],
                                       llvm::PointerType::getUnqual(MemType));
        llvm::Value *Load = Builder.CreateAlignedLoad(ResultType, Ops[0], Align);
        return Load;
    } }] in
def vload_mask : EPIBuiltin<"m", "mPCUe", "csil">;

let HasMergeOperand = 0 in
{
  let ManualCodegen = [{
    assert(Ops.size() >= 2);
    std::swap(Ops[0], Ops[1]);
    Ops[1] = Builder.CreateBitCast(Ops[1],
        llvm::PointerType::getUnqual(Ops[0]->getType()));
    IntrinsicTypes = {Ops[0]->getType()};
  }], ManualCodegenMask = [{
    assert(Ops.size() >= 2);
    std::swap(Ops[0], Ops[1]);
    Ops[1] = Builder.CreateBitCast(Ops[1],
        llvm::PointerType::getUnqual(Ops[0]->getType()));
    IntrinsicTypes = {Ops[0]->getType(), Ops[2]->getType()};
  }] in
  {
    let EPIRVVHeader = 1,
        CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, value, vl) \
        vse${Size}_v_${Type}${LMul}((addr), (value), (vl))}],
        CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(addr, value, mask, vl) \
        vse${Size}_v_${Type}${LMul}_m((mask), (addr), (value), (vl))}] in
    def vstore : EPIBuiltin<"v", "0Pev", "csilfd">;

    def vstore_nt : EPIBuiltin<"v", "0Pev", "csilfd">;

    let IntrinsicName = "vstore", IntrinsicNameMask = "vstore_mask",
      EPIRVVHeader = 1,
      CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, value, vl) \
        vse${Size}_v_${UType}${LMul}((addr), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(value), (vl))}],
      CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(addr, value, mask, vl) \
        vse${Size}_v_${UType}${LMul}_m((mask), (addr), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(value), (vl))}] in
    def vstore_unsigned : EPIBuiltin<"v", "0PUev", "csil">;

    let IntrinsicName = "vstore_nt", IntrinsicNameMask = "vstore_nt_mask" in
    def vstore_nt_unsigned : EPIBuiltin<"v", "0PUev", "csil">;
  }

  let ManualCodegen = [{
    assert(Ops.size() >= 2);
    std::swap(Ops[0], Ops[1]);
    Ops[1] = Builder.CreateBitCast(Ops[1],
        llvm::PointerType::getUnqual(Ops[0]->getType()));
    IntrinsicTypes = {Ops[0]->getType()};
  }], ManualCodegenMask = [{
    assert(Ops.size() >= 2);
    std::swap(Ops[0], Ops[1]);
    Ops[1] = Builder.CreateBitCast(Ops[1],
        llvm::PointerType::getUnqual(Ops[0]->getType()));
    IntrinsicTypes = {Ops[0]->getType(), Ops[3]->getType()};
  }] in
  {
    def vstore_ext : EPIBuiltin<"v", "0Pevu", "csilfd">;
    let IntrinsicName = "vstore_ext", IntrinsicNameMask = "vstore_ext_mask" in
      def vstore_ext_unsigned : EPIBuiltin<"v", "0PUevu", "csil">;
  }

  let ManualCodegen = [{
    assert(Ops.size() >= 2);
    std::swap(Ops[0], Ops[1]);
    Ops[1] = Builder.CreateBitCast(Ops[1],
        llvm::PointerType::getUnqual(Ops[0]->getType()));
    IntrinsicTypes = {Ops[0]->getType()};
  }], ManualCodegenMask = [{
    assert(Ops.size() >= 2);
    std::swap(Ops[0], Ops[1]);
    Ops[1] = Builder.CreateBitCast(Ops[1],
        llvm::PointerType::getUnqual(Ops[0]->getType()));
    IntrinsicTypes = {Ops[0]->getType(), Ops[3]->getType()};
  }] in
  {
    let EPIRVVHeader = 1,
        CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, value, stride, vl) \
        vsse${Size}_v_${Type}${LMul}((addr), (stride), (value), (vl))}],
        CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(addr, value, stride, mask, vl) \
        vsse${Size}_v_${Type}${LMul}_m((mask), (addr), (stride), (value), (vl))}] in
    def vstore_strided : EPIBuiltin<"v", "0Pevs", "csilfd">;
    
    def vstore_nt_strided : EPIBuiltin<"v", "0Pevs", "csilfd">;

    let IntrinsicName = "vstore_strided",
        IntrinsicNameMask = "vstore_strided_mask",
        EPIRVVHeader = 1,
        CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, value, stride, vl) \
        vsse${Size}_v_${UType}${LMul}((addr), (stride), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(value), (vl))}],
        CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(addr, value, stride, mask, vl) \
        vsse${Size}_v_${UType}${LMul}_m((mask), (addr), (stride), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(value), (vl))}] in
    def vstore_strided_unsigned : EPIBuiltin<"v", "0PUevs", "csil">;

    let IntrinsicName = "vstore_nt_strided",
        IntrinsicNameMask = "vstore_nt_strided_mask" in
    def vstore_nt_strided_unsigned : EPIBuiltin<"v", "0PUevs", "csil">;
  }

  let ManualCodegen = [{
    assert(Ops.size() >= 2);
    std::swap(Ops[0], Ops[1]);
    Ops[1] = Builder.CreateBitCast(Ops[1],
        llvm::PointerType::getUnqual(Ops[0]->getType()));
    IntrinsicTypes = {Ops[0]->getType()};
  }], ManualCodegenMask = [{
    assert(Ops.size() >= 2);
    std::swap(Ops[0], Ops[1]);
    Ops[1] = Builder.CreateBitCast(Ops[1],
        llvm::PointerType::getUnqual(Ops[0]->getType()));
    IntrinsicTypes = {Ops[0]->getType(), Ops[4]->getType()};
  }] in
  {
    def vstore_ext_strided : EPIBuiltin<"v", "0Pevsu", "csilfd">;
    let IntrinsicName = "vstore_ext_strided",
        IntrinsicNameMask = "vstore_ext_strided_mask" in
      def vstore_ext_strided_unsigned : EPIBuiltin<"v", "0PUevsu", "csil">;
  }

  let ManualCodegen = [{
    assert(Ops.size() >= 2);
    std::swap(Ops[0], Ops[1]);
    Ops[1] = Builder.CreateBitCast(Ops[1],
        llvm::PointerType::getUnqual(Ops[0]->getType()));
    IntrinsicTypes = {Ops[0]->getType(), Ops[2]->getType()};
  }], ManualCodegenMask = [{
    assert(Ops.size() >= 2);
    std::swap(Ops[0], Ops[1]);
    Ops[1] = Builder.CreateBitCast(Ops[1],
        llvm::PointerType::getUnqual(Ops[0]->getType()));
    IntrinsicTypes = {Ops[0]->getType(), Ops[2]->getType(), Ops[3]->getType()};
  }] in
  {
    let EPIRVVHeader = 1,
        CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, value, indexes, vl) \
        vsuxei${Size}_v_${Type}${LMul}((addr), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(indexes), (value), (vl))}],
        CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(addr, value, indexes, mask, vl) \
        vsuxei${Size}_v_${Type}${LMul}_m((mask), (addr), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(indexes), (value), (vl))}] in
    def vstore_indexed : EPIBuiltin<"v", "0PevIv", "csilfd">;

    def vstore_nt_indexed : EPIBuiltin<"v", "0PevIv", "csilfd">;

    let IntrinsicName = "vstore_indexed",
        IntrinsicNameMask = "vstore_indexed_mask",
        EPIRVVHeader = 1,
        CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, value, indexes, vl) \
        vsuxei${Size}_v_${UType}${LMul}((addr), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(indexes), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(value), (vl))}],
        CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(addr, value, indexes, mask, vl) \
        vsuxei${Size}_v_${UType}${LMul}_m((mask), (addr), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(indexes), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(value), (vl))}] in
    def vstore_indexed_unsigned : EPIBuiltin<"v", "0PUevIv", "csil">;

    let IntrinsicName = "vstore_nt_indexed",
        IntrinsicNameMask = "vstore_nt_indexed_mask" in
    def vstore_nt_indexed_unsigned : EPIBuiltin<"v", "0PUevIv", "csil">;
  }

  let ManualCodegen = [{
    assert(Ops.size() >= 2);
    std::swap(Ops[0], Ops[1]);
    Ops[1] = Builder.CreateBitCast(Ops[1],
        llvm::PointerType::getUnqual(Ops[0]->getType()));
    IntrinsicTypes = {Ops[0]->getType(), Ops[2]->getType()};
  }], ManualCodegenMask = [{
    assert(Ops.size() >= 2);
    std::swap(Ops[0], Ops[1]);
    Ops[1] = Builder.CreateBitCast(Ops[1],
        llvm::PointerType::getUnqual(Ops[0]->getType()));
    IntrinsicTypes = {Ops[0]->getType(), Ops[2]->getType(), Ops[4]->getType()};
  }] in
  {
    def vstore_ext_indexed : EPIBuiltin<"v", "0PevIvu", "csilfd">;
    let IntrinsicName = "vstore_ext_indexed",
        IntrinsicNameMask = "vstore_ext_indexed_mask" in
      def vstore_ext_indexed_unsigned : EPIBuiltin<"v", "0PUevIvu", "csil">;
  }

  // Store mask.
  let Name = "vstore", IntrinsicName = "", HasVL = 0, HasMask = 0, LMUL = [1],
  ManualCodegen = [{ {
    assert(Ops.size() == 2);
    clang::CharUnits Align =
      CGM.getNaturalPointeeTypeAlignment(E->getArg(0)->getType());
    llvm::Type *MemType = ConvertTypeForMem(E->getArg(1)->getType());
    std::swap(Ops[0], Ops[1]);
    // Ops[0] = Value
    // Ops[1] = Address
    Ops[1] = Builder.CreateBitCast(Ops[1],
        llvm::PointerType::getUnqual(MemType));
    return Builder.CreateAlignedStore(Ops[0], Ops[1], Align);
  } }] in
  def vstore_mask : EPIBuiltin<"m", "0PUem", "csil">;
}

/* Segmented load/stores */
let LMUL = [1] in {
let ManualCodegen = [{
{
IntrinsicTypes = { cast<StructType>(ResultType)->elements()[0] };

llvm::Function *F = CGM.getIntrinsic(ID, IntrinsicTypes);
llvm::Value *CallValue = Builder.CreateCall(F, Ops, "");
llvm::Value *V = llvm::UndefValue::get(ResultType);
for (unsigned I = 0, E = cast<StructType>(ResultType)->getNumElements();
     I != E; I++) {
  V = Builder.CreateInsertValue(V,
       Builder.CreateExtractValue(CallValue, {I}),
       {I});
}
if (ReturnValue.isNull())
  return V;
else
  return Builder.CreateStore(V, ReturnValue.getValue());
}
}], ManualCodegenMask = [{
{
IntrinsicTypes = { cast<StructType>(ResultType)->elements()[0],
                   Ops[2]->getType() };

// The merge argument needs unpacking.
llvm::SmallVector<Value*, 4> FlatOps;
for (unsigned I = 0, E = cast<StructType>(Ops[0]->getType())->getNumElements();
     I != E; I++) {
  FlatOps.push_back(Builder.CreateExtractValue(Ops[0], {I}));
}
FlatOps.append(Ops.begin() + 1, Ops.end());

llvm::Function *F = CGM.getIntrinsic(ID, IntrinsicTypes);
llvm::Value *CallValue = Builder.CreateCall(F, FlatOps, "");
llvm::Value *V = llvm::UndefValue::get(ResultType);
for (unsigned I = 0, E = cast<StructType>(ResultType)->getNumElements();
     I != E; I++) {
  V = Builder.CreateInsertValue(V,
       Builder.CreateExtractValue(CallValue, {I}),
       {I});
}
if (ReturnValue.isNull())
  return V;
else
  return Builder.CreateStore(V, ReturnValue.getValue());
}
}],
  CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, vl) \
        ${Name}e${Size}_v_${Type}${LMul}x${Tuple}((addr), (vl))}],
  CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, addr, mask, vl) \
        ${Name}e${Size}_v_${Type}${LMul}x${Tuple}_m((mask), (merge), (addr), (vl))}] in {
def vlseg2 : EPIBuiltin<"TTv", "TTvPCe", "csilfd">;
def vlseg3 : EPIBuiltin<"TTTv", "TTTvPCe", "csilfd">;
def vlseg4 : EPIBuiltin<"TTTTv", "TTTTvPCe", "csilfd">;
def vlseg5 : EPIBuiltin<"TTTTTv", "TTTTTvPCe", "csilfd">;
def vlseg6 : EPIBuiltin<"TTTTTTv", "TTTTTTvPCe", "csilfd">;
def vlseg7 : EPIBuiltin<"TTTTTTTv", "TTTTTTTvPCe", "csilfd">;
def vlseg8 : EPIBuiltin<"TTTTTTTTv", "TTTTTTTTvPCe", "csilfd">;
}

let ManualCodegen = [{
{
IntrinsicTypes = { cast<StructType>(ResultType)->elements()[0] };

llvm::Function *F = CGM.getIntrinsic(ID, IntrinsicTypes);
llvm::Value *CallValue = Builder.CreateCall(F, Ops, "");
llvm::Value *V = llvm::UndefValue::get(ResultType);
for (unsigned I = 0, E = cast<StructType>(ResultType)->getNumElements();
     I != E; I++) {
  V = Builder.CreateInsertValue(V,
       Builder.CreateExtractValue(CallValue, {I}),
       {I});
}
if (ReturnValue.isNull())
  return V;
else
  return Builder.CreateStore(V, ReturnValue.getValue());
}
}], ManualCodegenMask = [{
{
IntrinsicTypes = { cast<StructType>(ResultType)->elements()[0],
                   Ops[3]->getType() };

// The merge argument needs unpacking.
llvm::SmallVector<Value*, 4> FlatOps;
for (unsigned I = 0, E = cast<StructType>(Ops[0]->getType())->getNumElements();
     I != E; I++) {
  FlatOps.push_back(Builder.CreateExtractValue(Ops[0], {I}));
}
FlatOps.append(Ops.begin() + 1, Ops.end());

llvm::Function *F = CGM.getIntrinsic(ID, IntrinsicTypes);
llvm::Value *CallValue = Builder.CreateCall(F, FlatOps, "");
llvm::Value *V = llvm::UndefValue::get(ResultType);
for (unsigned I = 0, E = cast<StructType>(ResultType)->getNumElements();
     I != E; I++) {
  V = Builder.CreateInsertValue(V,
       Builder.CreateExtractValue(CallValue, {I}),
       {I});
}
if (ReturnValue.isNull())
  return V;
else
  return Builder.CreateStore(V, ReturnValue.getValue());
}
}],
  CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, stride, vl) \
        vlsseg${Tuple}e${Size}_v_${Type}${LMul}x${Tuple}((addr), (stride), (vl))}],
  CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, addr, stride, mask, vl) \
        vlsseg${Tuple}e${Size}_v_${Type}${LMul}x${Tuple}_m((mask), (merge), (addr), (stride), (vl))}] in {
def vlseg2_strided : EPIBuiltin<"TTv", "TTvPCes", "csilfd">;
def vlseg3_strided : EPIBuiltin<"TTTv", "TTTvPCes", "csilfd">;
def vlseg4_strided : EPIBuiltin<"TTTTv", "TTTTvPCes", "csilfd">;
def vlseg5_strided : EPIBuiltin<"TTTTTv", "TTTTTvPCes", "csilfd">;
def vlseg6_strided : EPIBuiltin<"TTTTTTv", "TTTTTTvPCes", "csilfd">;
def vlseg7_strided : EPIBuiltin<"TTTTTTTv", "TTTTTTTvPCes", "csilfd">;
def vlseg8_strided : EPIBuiltin<"TTTTTTTTv", "TTTTTTTTvPCes", "csilfd">;
}

let ManualCodegen = [{
{
IntrinsicTypes = { cast<StructType>(ResultType)->elements()[0],
                   Ops[1]->getType() };

llvm::Function *F = CGM.getIntrinsic(ID, IntrinsicTypes);
llvm::Value *CallValue = Builder.CreateCall(F, Ops, "");
llvm::Value *V = llvm::UndefValue::get(ResultType);
for (unsigned I = 0, E = cast<StructType>(ResultType)->getNumElements();
     I != E; I++) {
  V = Builder.CreateInsertValue(V,
       Builder.CreateExtractValue(CallValue, {I}),
       {I});
}
if (ReturnValue.isNull())
  return V;
else
  return Builder.CreateStore(V, ReturnValue.getValue());
}
}], ManualCodegenMask = [{
{
IntrinsicTypes = { cast<StructType>(ResultType)->elements()[0],
                   Ops[2]->getType(), Ops[3]->getType() };

// The merge argument needs unpacking.
llvm::SmallVector<Value*, 4> FlatOps;
for (unsigned I = 0, E = cast<StructType>(Ops[0]->getType())->getNumElements();
     I != E; I++) {
  FlatOps.push_back(Builder.CreateExtractValue(Ops[0], {I}));
}
FlatOps.append(Ops.begin() + 1, Ops.end());

llvm::Function *F = CGM.getIntrinsic(ID, IntrinsicTypes);
llvm::Value *CallValue = Builder.CreateCall(F, FlatOps, "");
llvm::Value *V = llvm::UndefValue::get(ResultType);
for (unsigned I = 0, E = cast<StructType>(ResultType)->getNumElements();
     I != E; I++) {
  V = Builder.CreateInsertValue(V,
       Builder.CreateExtractValue(CallValue, {I}),
       {I});
}
if (ReturnValue.isNull())
  return V;
else
  return Builder.CreateStore(V, ReturnValue.getValue());
}
}],
  CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, index, vl) \
        vluxseg${Tuple}ei${Size}_v_${Type}${LMul}x${Tuple}((addr), (index), (vl))}],
  CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, addr, index, mask, vl) \
        vluxseg${Tuple}ei${Size}_v_${Type}${LMul}x${Tuple}_m((mask), (merge), (addr), (index), (vl))}] in {
def vlseg2_indexed : EPIBuiltin<"TTv", "TTvPCeIv", "csilfd">;
def vlseg3_indexed : EPIBuiltin<"TTTv", "TTTvPCeIv", "csilfd">;
def vlseg4_indexed : EPIBuiltin<"TTTTv", "TTTTvPCeIv", "csilfd">;
def vlseg5_indexed : EPIBuiltin<"TTTTTv", "TTTTTvPCeIv", "csilfd">;
def vlseg6_indexed : EPIBuiltin<"TTTTTTv", "TTTTTTvPCeIv", "csilfd">;
def vlseg7_indexed : EPIBuiltin<"TTTTTTTv", "TTTTTTTvPCeIv", "csilfd">;
def vlseg8_indexed : EPIBuiltin<"TTTTTTTTv", "TTTTTTTTvPCeIv", "csilfd">;
}

let HasMergeOperand = 0 in
{

let ManualCodegen = [{
{
IntrinsicTypes = { cast<StructType>(Ops[1]->getType())->elements()[0] };

llvm::SmallVector<Value*, 4> FlatOps;
for (unsigned I = 0, E = cast<StructType>(Ops[1]->getType())->getNumElements();
     I != E; I++) {
  FlatOps.push_back(Builder.CreateExtractValue(Ops[1], {I}));
}
FlatOps.push_back(Ops[0]);
FlatOps.append(Ops.begin() + 2, Ops.end());

std::swap(Ops, FlatOps);
}
}],
ManualCodegenMask = [{
{
IntrinsicTypes = { cast<StructType>(Ops[1]->getType())->elements()[0],
                   Ops[2]->getType() };

llvm::SmallVector<Value*, 4> FlatOps;
for (unsigned I = 0, E = cast<StructType>(Ops[1]->getType())->getNumElements();
     I != E; I++) {
  FlatOps.push_back(Builder.CreateExtractValue(Ops[1], {I}));
}
FlatOps.push_back(Ops[0]);
FlatOps.append(Ops.begin() + 2, Ops.end());

std::swap(Ops, FlatOps);
}
}],
  CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, value, vl) \
        ${Name}e${Size}_v_${Type}${LMul}x{$Tuple}((addr), (value), (vl))}],
  CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(addr, value, mask, vl) \
        ${Name}e${Size}_v_${Type}${LMul}x{$Tuple}_m((mask), (addr), (value), (vl))}] in {
def vsseg2 : EPIBuiltin<"TTv", "0PeTTv", "csilfd">;
def vsseg3 : EPIBuiltin<"TTTv", "0PeTTTv", "csilfd">;
def vsseg4 : EPIBuiltin<"TTTTv", "0PeTTTTv", "csilfd">;
def vsseg5 : EPIBuiltin<"TTTTTv", "0PeTTTTTv", "csilfd">;
def vsseg6 : EPIBuiltin<"TTTTTTv", "0PeTTTTTTv", "csilfd">;
def vsseg7 : EPIBuiltin<"TTTTTTTv", "0PeTTTTTTTv", "csilfd">;
def vsseg8 : EPIBuiltin<"TTTTTTTTv", "0PeTTTTTTTTv", "csilfd">;
}

let ManualCodegen = [{
{
IntrinsicTypes = { cast<StructType>(Ops[1]->getType())->elements()[0] };

llvm::SmallVector<Value*, 4> FlatOps;
for (unsigned I = 0, E = cast<StructType>(Ops[1]->getType())->getNumElements();
     I != E; I++) {
  FlatOps.push_back(Builder.CreateExtractValue(Ops[1], {I}));
}
FlatOps.push_back(Ops[0]);
FlatOps.append(Ops.begin() + 2, Ops.end());

std::swap(Ops, FlatOps);
}
}],
ManualCodegenMask = [{
{
IntrinsicTypes = { cast<StructType>(Ops[1]->getType())->elements()[0],
                   Ops[3]->getType() };

llvm::SmallVector<Value*, 4> FlatOps;
for (unsigned I = 0, E = cast<StructType>(Ops[1]->getType())->getNumElements();
     I != E; I++) {
  FlatOps.push_back(Builder.CreateExtractValue(Ops[1], {I}));
}
FlatOps.push_back(Ops[0]);
FlatOps.append(Ops.begin() + 2, Ops.end());

std::swap(Ops, FlatOps);
}
}],
  CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, value, stride, vl) \
        vssseg${Tuple}e${Size}_v_${Type}${LMul}x${Tuple}((addr), (stride), (value), (vl))}],
  CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(addr, value, stride, mask, vl) \
        vssseg${Tuple}e${Size}_v_${Type}${LMul}x${Tuple}_m((mask), (addr), (stride), (value), (vl))}] in {
def vsseg2_strided : EPIBuiltin<"TTv", "0PeTTvs", "csilfd">;
def vsseg3_strided : EPIBuiltin<"TTTv", "0PeTTTvs", "csilfd">;
def vsseg4_strided : EPIBuiltin<"TTTTv", "0PeTTTTvs", "csilfd">;
def vsseg5_strided : EPIBuiltin<"TTTTTv", "0PeTTTTTvs", "csilfd">;
def vsseg6_strided : EPIBuiltin<"TTTTTTv", "0PeTTTTTTvs", "csilfd">;
def vsseg7_strided : EPIBuiltin<"TTTTTTTv", "0PeTTTTTTTvs", "csilfd">;
def vsseg8_strided : EPIBuiltin<"TTTTTTTTv", "0PeTTTTTTTTvs", "csilfd">;
}

let ManualCodegen = [{
{
IntrinsicTypes = { cast<StructType>(Ops[1]->getType())->elements()[0],
                   Ops[2]->getType() };

llvm::SmallVector<Value*, 4> FlatOps;
for (unsigned I = 0, E = cast<StructType>(Ops[1]->getType())->getNumElements();
     I != E; I++) {
  FlatOps.push_back(Builder.CreateExtractValue(Ops[1], {I}));
}
FlatOps.push_back(Ops[0]);
FlatOps.append(Ops.begin() + 2, Ops.end());

std::swap(Ops, FlatOps);
}
}],
ManualCodegenMask = [{
{
IntrinsicTypes = { cast<StructType>(Ops[1]->getType())->elements()[0],
                   Ops[2]->getType(), Ops[3]->getType() };

llvm::SmallVector<Value*, 4> FlatOps;
for (unsigned I = 0, E = cast<StructType>(Ops[1]->getType())->getNumElements();
     I != E; I++) {
  FlatOps.push_back(Builder.CreateExtractValue(Ops[1], {I}));
}
FlatOps.push_back(Ops[0]);
FlatOps.append(Ops.begin() + 2, Ops.end());

std::swap(Ops, FlatOps);
}
}],
  CompatibilityCode = [{#define __builtin_epi_${FullName}(addr, value, index, vl) \
        vsuxseg${Tuple}ei${Size}_v_${Type}${LMul}x${Tuple}((addr), (index), (value), (vl))}],
  CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(addr, value, index, mask, vl) \
        vsuxseg${Tuple}ei${Size}_v_${Type}${LMul}x${Tuple}_m((mask), (addr), (index), (value), (vl))}] in {
def vsseg2_indexed : EPIBuiltin<"TTv", "0PeTTvIv", "csilfd">;
def vsseg3_indexed : EPIBuiltin<"TTTv", "0PeTTTvIv", "csilfd">;
def vsseg4_indexed : EPIBuiltin<"TTTTv", "0PeTTTTvIv", "csilfd">;
def vsseg5_indexed : EPIBuiltin<"TTTTTv", "0PeTTTTTvIv", "csilfd">;
def vsseg6_indexed : EPIBuiltin<"TTTTTTv", "0PeTTTTTTvIv", "csilfd">;
def vsseg7_indexed : EPIBuiltin<"TTTTTTTv", "0PeTTTTTTTvIv", "csilfd">;
def vsseg8_indexed : EPIBuiltin<"TTTTTTTTv", "0PeTTTTTTTTvIv", "csilfd">;
}

} // HasMergeOperand = 0

} // segmented loads/stores

def vrsub : EPIBinBuiltin<"v", "vve", "csil">;

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${Name}_vv_${Type}${LMul}((a), (b), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        ${Name}_vv_${Type}${LMul}_m((mask), (a), (b), (vl))}] in {
def vadd : EPIBinBuiltin<"v", "vvv", "csil">;
def vsub : EPIBinBuiltin<"v", "vvv", "csil">;

def vand : EPIBinBuiltin<"v", "vvv", "csil">;
def vor : EPIBinBuiltin<"v", "vvv", "csil">;
def vxor : EPIBinBuiltin<"v", "vvv", "csil">;


def vmin : EPIBinBuiltin<"v", "vvv", "csil">;
def vmax : EPIBinBuiltin<"v", "vvv", "csil">;

def vmul : EPIBinBuiltin<"v", "vvv", "csil">;
def vmulh : EPIBinBuiltin<"v", "vvv", "csil">;

def vdiv : EPIBinBuiltin<"v", "vvv", "csil">;
def vrem : EPIBinBuiltin<"v", "vvv", "csil">;

def vfadd : EPIBinBuiltin<"v", "vvv", "fd">;
def vfsub : EPIBinBuiltin<"v", "vvv", "fd">;

def vfmul : EPIBinBuiltin<"v", "vvv", "fd">;
def vfdiv : EPIBinBuiltin<"v", "vvv", "fd">;

def vfmin : EPIBinBuiltin<"v", "vvv", "fd">;
def vfmax : EPIBinBuiltin<"v", "vvv", "fd">;

def vfsgnj : EPIBinBuiltin<"v", "vvv", "fd">;
def vfsgnjn : EPIBinBuiltin<"v", "vvv", "fd">;
def vfsgnjx : EPIBinBuiltin<"v", "vvv", "fd">;

}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${Name}_vv_${Type}${LMul}((a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        ${Name}_vv_${Type}${LMul}_m((mask), (a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl))}] in {
def vsll : EPIBinBuiltin<"v", "vvv", "csil">;
def vsra : EPIBinBuiltin<"v", "vvv", "csil">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(${Name}_vv_${UType}${LMul}(vreinterpret_v_${Type}${LMul}_${UType}${LMul}(a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl)))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(${Name}_vv_${UType}${LMul}_m((mask), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl)))}] in {
def vsrl : EPIBinBuiltin<"v", "vvv", "csil">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${Name}_vv_${Type}${LMul}((a), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(b), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        ${Name}_vv_${Type}${LMul}_m((mask), (a), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(b), (vl))}] in {
def vmulhsu : EPIBinBuiltin<"v", "vvv", "csil">;
def vrgather : EPIBinBuiltin<"v", "vvIv", "csilfd">;
}

let EPIRVVHeader = 1, IntrinsicName = "vrgather", IntrinsicNameMask = "vrgather_mask",
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        vrgather_vx_${Type}${LMul}((a), (b), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        vrgather_vx_${Type}${LMul}_m((mask), (a), (b), (vl))}] in {
def vsplat : EPIVecScalarBuiltin<"v", "vvu", "csilfd">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${Name}_vv_${WidenedType}${WidenedLMul}((a), (b), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        ${Name}_vv_${WidenedType}${WidenedLMul}_m((mask), (a), (b), (vl))}] in {
def vwadd : EPIWidenBinBuiltin<"w", "wvv", "csi">;
def vwsub : EPIWidenBinBuiltin<"w", "wvv", "csi">;
def vwmul : EPIWidenBinBuiltin<"w", "wvv", "csi">;

def vfwadd : EPIWidenBinBuiltin<"w", "wvv", "f">;
def vfwsub : EPIWidenBinBuiltin<"w", "wvv", "f">;
def vfwmul : EPIWidenBinBuiltin<"w", "wvv", "f">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${Name}_vv_${WidenedType}${WidenedLMul} (a, vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), vl)}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        ${Name}_vv_${WidenedType}${WidenedLMul}_m((mask), (a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl))}] in {
def vwmulsu : EPIWidenBinBuiltin<"w", "wvv", "csi">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        vreinterpret_v_${WidenedUType}${WidenedLMul}_${WidenedType}${WidenedLMul}(${Name}_vv_${WidenedUType}${WidenedLMul}(vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(a), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(b), (vl)))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        vreinterpret_v_${WidenedUType}${WidenedLMul}_${WidenedType}${WidenedLMul}(${Name}_vv_${WidenedUType}${WidenedLMul}_m((mask), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(a), vreinterpret_v_i${Size}${LMul}_${UType}${LMul}(b), (vl)))}] in {
def vwaddu : EPIWidenBinBuiltin<"w", "wvv", "csi">;
def vwsubu : EPIWidenBinBuiltin<"w", "wvv", "csi">;
def vwmulu : EPIWidenBinBuiltin<"w", "wvv", "csi">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${Name}v_${WidenedType}${WidenedLMul}((a), (b), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        ${Name}v_${WidenedType}${WidenedLMul}_m((mask), (a), (b), (vl))}] in {
def vwadd_w : EPIBinBuiltin<"w", "wwv", "csi">;
def vwsub_w : EPIBinBuiltin<"w", "wwv", "csi">;

def vfwadd_w : EPIBinBuiltin<"w", "wwv", "f">;
def vfwsub_w : EPIBinBuiltin<"w", "wwv", "f">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        vreinterpret_v_${WidenedUType}${WidenedLMul}_${WidenedType}${WidenedLMul}(${Name}v_${WidenedUType}${WidenedLMul}(vreinterpret_v_${WidenedType}${WidenedLMul}_${WidenedUType}${WidenedLMul}(a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl)))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        vreinterpret_v_${WidenedUType}${WidenedLMul}_${WidenedType}${WidenedLMul}(${Name}v_${WidenedUType}${WidenedLMul}_m((mask), vreinterpret_v_${WidenedType}${WidenedLMul}_${WidenedUType}${WidenedLMul}(a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl)))}] in {
def vwaddu_w : EPIBinBuiltin<"w", "wwv", "csi">;
def vwsubu_w : EPIBinBuiltin<"w", "wwv", "csi">;
}

let HasMask = 0, EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, in, vl) \
        ${Name}_vvm_${Type}${LMul}((a), (b), (in), (vl))}] in {
def vadc : EPIBinMaskInBuiltin<"v", "vvvm", "csil">;
def vsbc : EPIBinMaskInBuiltin<"v", "vvvm", "csil">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${Name}_vv_${Type}${LMul}_b${Boolean}((a), (b), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        ${Name}_vv_${Type}${LMul}_b${Boolean}_m((mask), (a), (b), (vl))}] in {
  let HasMask = 0 in {
    def vmadc : EPIRelBuiltin<"v", "mvv", "csil">;
    def vmsbc : EPIRelBuiltin<"v", "mvv", "csil">;
  }
def vmseq : EPIRelBuiltin<"v", "mvv", "csil">;
def vmsne : EPIRelBuiltin<"v", "mvv", "csil">;
def vmslt : EPIRelBuiltin<"v", "mvv", "csil">;
def vmsle : EPIRelBuiltin<"v", "mvv", "csil">;
def vmsgt : EPIRelBuiltin<"v", "mvv", "csil">;

def vmfeq : EPIRelBuiltin<"v", "mvv", "fd">;
def vmfne : EPIRelBuiltin<"v", "mvv", "fd">;
def vmflt : EPIRelBuiltin<"v", "mvv", "fd">;
def vmfle : EPIRelBuiltin<"v", "mvv", "fd">;
def vmfgt : EPIRelBuiltin<"v", "mvv", "fd">;
def vmfge : EPIRelBuiltin<"v", "mvv", "fd">;
}

let HasMask = 0, EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, in, vl) \
        vmadc_vvm_${Type}${LMul}_b${Boolean}((a), (b), (in), (vl))}] in
def vmadc_carry_in : EPIRelBuiltin<"v", "mvvm", "csil">;

let HasMask = 0, EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, in, vl) \
        vmsbc_vvm_${Type}${LMul}_b${Boolean}((a), (b), (in), (vl))}] in
def vmsbc_borrow_in : EPIRelBuiltin<"v", "mvvm", "csil">;

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(${Name}_vv_${UType}${LMul}(vreinterpret_v_${Type}${LMul}_${UType}${LMul}(a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl)))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(${Name}_vv_${UType}${LMul}_m((mask), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl)))}] in {
def vminu : EPIBinBuiltin<"v", "vvv", "csil">;
def vmaxu : EPIBinBuiltin<"v", "vvv", "csil">;
def vmulhu : EPIBinBuiltin<"v", "vvv", "csil">;

def vdivu : EPIBinBuiltin<"v", "vvv", "csil">;
def vremu : EPIBinBuiltin<"v", "vvv", "csil">;
}

// These do narrowing but typewise they are like their widen counterparts
let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${Name}_wv_${Type}${LMul}((a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        ${Name}_wv_${Type}${LMul}_m((mask), (a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl))}] in {
def vnsra : EPIWidenBinBuiltin<"v", "vwv", "csi">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(${Name}_wv_${UType}${LMul}(vreinterpret_v_${WidenedType}${WidenedLMul}_${WidenedUType}${WidenedLMul}(a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl)))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(${Name}_wv_${UType}${LMul}_m((mask), vreinterpret_v_${WidenedType}${WidenedLMul}_${WidenedUType}${WidenedLMul}(a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl)))}] in {
def vnsrl : EPIWidenBinBuiltin<"v", "vwv", "csi">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${Name}_vv_${UType}${LMul}_b${Boolean}(vreinterpret_v_${Type}${LMul}_${UType}${LMul}(a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        ${Name}_vv_${UType}${LMul}_b${Boolean}_m((mask), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(a), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(b), (vl))}] in {
def vmsltu : EPIRelBuiltin<"v", "mvv", "csil">;
def vmsleu : EPIRelBuiltin<"v", "mvv", "csil">;
def vmsgtu : EPIRelBuiltin<"v", "mvv", "csil">;
}

let HasMergeOperand = 0 in
{
  def vmacc : EPIBinBuiltin<"v", "vvvv", "csil">;
  def vnmsac : EPIBinBuiltin<"v", "vvvv", "csil">;
  def vmadd : EPIBinBuiltin<"v", "vvvv", "csil">;
  def vnmsub : EPIBinBuiltin<"v", "vvvv", "csil">;

  def vwmaccu : EPIWidenTerBuiltin<"w", "wvvw", "csi">;
  def vwmacc : EPIWidenTerBuiltin<"w", "wvvw", "csi">;
  def vwmsacu : EPIWidenTerBuiltin<"w", "wvvw", "csi">;
  def vwmsac : EPIWidenTerBuiltin<"w", "wvvw", "csi">;

  def vwsmaccu : EPIWidenTerBuiltin<"w", "wvvw", "csi">;
  def vwsmacc : EPIWidenTerBuiltin<"w", "wvvw", "csi">;
  def vwsmsacu : EPIWidenTerBuiltin<"w", "wvvw", "csi">;
  def vwsmsac : EPIWidenTerBuiltin<"w", "wvvw", "csi">;
}

let HasMask = 0, EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, mask, vl) \
        vmerge_vvm_${Type}${LMul}((a), (b), (mask), (vl))}] in {
def vmerge : EPIBinMaskInBuiltin<"v", "vvvm", "csil">;
def vfmerge : EPIBinMaskInBuiltin<"v", "vvvm", "fd">;
}

def vsaddu : EPIBinBuiltin<"v", "vvv", "csil">;
def vsadd : EPIBinBuiltin<"v", "vvv", "csil">;
def vssub : EPIBinBuiltin<"v", "vvv", "csil">;
def vssubu : EPIBinBuiltin<"v", "vvv", "csil">;

def vaadd : EPIBinBuiltin<"v", "vvv", "csil">;
def vasub : EPIBinBuiltin<"v", "vvv", "csil">;

def vsmul : EPIBinBuiltin<"v", "vvv", "csil">;

def vssrl : EPIBinBuiltin<"v", "vvv", "csil">;
def vssra : EPIBinBuiltin<"v", "vvv", "csil">;

def vnclipu : EPIBuiltin<"v", "vww", "csi">;
def vnclip : EPIBuiltin<"v", "vww", "csi">;

let HasMergeOperand = 0 in
{
  let EPIRVVHeader = 1,
      CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, c, vl) \
        ${Name}_vv_${Type}${LMul}((a), (b), (c), (vl))}],
      CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(a, b, c, mask, vl) \
        ${Name}_vv_${Type}${LMul}_m((mask), (a), (b), (c), (vl))}] in {
  def vfmadd : EPITerBuiltin<"v", "vvvv", "fd">;
  def vfnmadd : EPITerBuiltin<"v", "vvvv", "fd">;
  def vfmsub : EPITerBuiltin<"v", "vvvv", "fd">;
  def vfnmsub : EPITerBuiltin<"v", "vvvv", "fd">;
  def vfmacc : EPITerBuiltin<"v", "vvvv", "fd">;
  def vfnmacc : EPITerBuiltin<"v", "vvvv", "fd">;
  def vfmsac : EPITerBuiltin<"v", "vvvv", "fd">;
  def vfnmsac : EPITerBuiltin<"v", "vvvv", "fd">;
  }

  let EPIRVVHeader = 1,
      CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, c, vl) \
        ${Name}_vv_${WidenedType}${WidenedLMul}((c), (a), (b), (vl))}],
      CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(a, b, c, mask, vl) \
        ${Name}_vv_${WidenedType}${WidenedLMul}_m((mask), (c), (a), (b), (vl))}] in {
  def vfwmacc : EPIWidenTerBuiltin<"w", "wvvw", "f">;
  def vfwnmacc : EPIWidenTerBuiltin<"w", "wvvw", "f">;
  def vfwmsac : EPIWidenTerBuiltin<"w", "wvvw", "f">;
  def vfwnmsac : EPIWidenTerBuiltin<"w", "wvvw", "f">;
  }
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_v_${Type}${LMul}((a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        ${Name}_v_${Type}${LMul}_m((mask), (a), (vl))}] in 
def vfsqrt : EPIUnaBuiltin<"v", "vv", "fd">;

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        vreinterpret_v_${UType}${LMul}_i${Size}${LMul}(${Name}_v_${UType}${LMul}((a), (vl)))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        vreinterpret_v_${UType}${LMul}_i${Size}${LMul}(${Name}_v_${UType}${LMul}_m((mask), (a), (vl)))}] in {
def vfcvt_xu_f : EPIUnaBuiltin<"Ivv", "Ivv", "fd">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_v_i${Size}${LMul}((a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        ${Name}_v_i${Size}${LMul}_m((mask), (a), (vl))}] in {
def vfcvt_x_f : EPIUnaBuiltin<"Ivv", "Ivv", "fd">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_v_f${Size}${LMul}(vreinterpret_v_${Type}${LMul}_${UType}${LMul}(a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        ${Name}_v_f${Size}${LMul}_m((mask), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(a), (vl))}] in {
def vfcvt_f_xu : EPIUnaBuiltin<"Fvv", "Fvv", "il">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_v_f${Size}${LMul}((a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        ${Name}_v_f${Size}${LMul}_m((mask), (a), (vl))}] in {
def vfcvt_f_x : EPIUnaBuiltin<"Fvv", "Fvv", "il">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        vreinterpret_v_${WidenedUType}${WidenedLMul}_i${WidenedSize}${WidenedLMul}(${Name}_v_${WidenedUType}${WidenedLMul}((a), (vl)))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        vreinterpret_v_${WidenedUType}${WidenedLMul}_i${WidenedSize}${WidenedLMul}(${Name}_v_${WidenedUType}${WidenedLMul}_m((mask), (a), (vl)))}] in {
def vfwcvt_xu_f : EPIUnaBuiltin<"Iwv", "Iwv", "f">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_v_i${WidenedSize}${WidenedLMul}((a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        ${Name}_v_i${WidenedSize}${WidenedLMul}_m((mask), (a), (vl))}] in {
def vfwcvt_x_f : EPIUnaBuiltin<"Iwv", "Iwv", "f">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_v_f${WidenedSize}${WidenedLMul}((a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        ${Name}_v_f${WidenedSize}${WidenedLMul}_m((mask), (a), (vl))}] in {
def vfwcvt_f_x : EPIUnaBuiltin<"Fwv", "Fwv", "si">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_v_f${WidenedSize}${WidenedLMul}(vreinterpret_v_${Type}${LMul}_${UType}${LMul}(a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        ${Name}_v_f${WidenedSize}${WidenedLMul}_m((mask), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(a), (vl))}] in {
def vfwcvt_f_xu : EPIUnaBuiltin<"Fwv", "Fwv", "si">;
}

// Note that we use "vFw" + "si" here because "Ivw" + "f" would miss f32→i16
// We have no way to represent f16 in the TypeRange yet.
let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(${Name}_w_${UType}${LMul}((a), (vl)))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(${Name}_w_${UType}${LMul}_m((mask), (a), (vl)))}] in {
def vfncvt_xu_f : EPIUnaBuiltin<"vFw", "vFw", "si">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_w_${Type}${LMul}((a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        ${Name}_w_${Type}${LMul}_m((mask), (a), (vl))}] in {
def vfncvt_x_f : EPIUnaBuiltin<"vFw", "vFw", "si">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_w_f${Size}${LMul}((a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        ${Name}_w_f${Size}${LMul}_m((mask), (a), (vl))}] in {
def vfncvt_f_x : EPIUnaBuiltin<"Fvw", "Fvw", "i">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_w_f${Size}${LMul}(vreinterpret_v_${WidenedType}${WidenedLMul}_${WidenedUType}${WidenedLMul}(a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        ${Name}_w_f${Size}${LMul}_m((mask), vreinterpret_v_${WidenedType}${WidenedLMul}_${WidenedUType}${WidenedLMul}(a), (vl))}] in {
def vfncvt_f_xu : EPIUnaBuiltin<"Fvw", "Fvw", "i">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_v_${WidenedType}${WidenedLMul}((a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        ${Name}_v_${WidenedType}${WidenedLMul}_m((mask), (a), (vl))}] in {
def vfwcvt_f_f : EPIUnaBuiltin<"wv", "wv", "f">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_w_${Type}${LMul}((a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        ${Name}_w_${Type}${LMul}_m((mask), (a), (vl))}] in {
def vfncvt_f_f : EPIUnaBuiltin<"vw", "vw", "f">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${LMulExt}${Name}_vs_${Type}${LMul}_${Type}m1((a), ${LMulTrunc}(b)${End}, (vl))${End} }],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        ${LMulExt}${Name}_vs_${Type}${LMul}_${Type}m1_m((mask), (a), ${LMulTrunc}(b)${End}, (vl))${End} }] in {
def vredsum : EPIBinBuiltin<"v", "vvv", "csil">;
def vredmax : EPIBinBuiltin<"v", "vvv", "csil">;
def vredmin : EPIBinBuiltin<"v", "vvv", "csil">;
def vredand : EPIBinBuiltin<"v", "vvv", "csil">;
def vredor : EPIBinBuiltin<"v", "vvv", "csil">;
def vredxor : EPIBinBuiltin<"v", "vvv", "csil">;

def vfredosum : EPIBinBuiltin<"v", "vvv", "fd">;
def vfredmax : EPIBinBuiltin<"v", "vvv", "fd">;
def vfredmin : EPIBinBuiltin<"v", "vvv", "fd">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${LMulExt}vfredusum_vs_${Type}${LMul}_${Type}m1((a), ${LMulTrunc}(b)${End}, (vl))${End} }],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        ${LMulExt}vfredusum_vs_${Type}${LMul}_${Type}m1_m((mask), (a), ${LMulTrunc}(b)${End}, (vl))${End} }] in
def vfredsum : EPIBinBuiltin<"v", "vvv", "fd">;

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${LMulExt}vreinterpret_v_${UType}m1_${Type}m1(${Name}_vs_${UType}${LMul}_${UType}m1(vreinterpret_v_${Type}${LMul}_${UType}${LMul}(a), vreinterpret_v_${Type}m1_${UType}m1(${LMulTrunc}(b)${End}), (vl)))${End} }],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        ${LMulExt}vreinterpret_v_${UType}m1_${Type}m1(${Name}_vs_${UType}${LMul}_${UType}m1_m((mask), vreinterpret_v_${Type}${LMul}_${UType}${LMul}(a), vreinterpret_v_${Type}m1_${UType}m1(${LMulTrunc}(b)${End}), (vl)))${End} }] in {
def vredmaxu : EPIBinBuiltin<"v", "vvv", "csil">;
def vredminu : EPIBinBuiltin<"v", "vvv", "csil">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        vlmul_ext_v_${WidenedType}m1_${WidenedType}${WidenedLMul}(${Name}_vs_${Type}${LMul}_${WidenedType}m1((a), vlmul_trunc_v_${WidenedType}${WidenedLMul}_${WidenedType}m1(b), (vl)))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        vlmul_ext_v_${WidenedType}m1_${WidenedType}${WidenedLMul}(${Name}_vs_${Type}${LMul}_${WidenedType}m1_m((mask), (a), vlmul_trunc_v_${WidenedType}${WidenedLMul}_${WidenedType}m1(b), (vl)))}] in {
def vwredsum : EPIWidenBinBuiltin<"w", "wvw", "csi">;

def vfwredosum : EPIWidenBinBuiltin<"w", "wvw", "f">;
}
let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        vlmul_ext_v_${WidenedType}m1_${WidenedType}${WidenedLMul}(vfwredusum_vs_${Type}${LMul}_${WidenedType}m1((a), vlmul_trunc_v_${WidenedType}${WidenedLMul}_${WidenedType}m1(b), (vl)))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, b, mask, vl) \
        vlmul_ext_v_${WidenedType}m1_${WidenedType}${WidenedLMul}(vfwredusum_vs_${Type}${LMul}_${WidenedType}m1_m((mask), (a), vlmul_trunc_v_${WidenedType}${WidenedLMul}_${WidenedType}m1(b), (vl)))}] in
def vfwredsum : EPIWidenBinBuiltin<"w", "wvw", "f">;

// FIXME: add compatibility code for vwredsumu
def vwredsumu : EPIWidenBinBuiltin<"w", "wvw", "csi">;

let HasMask = 0, EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${Name}_mm_b${Boolean}((a), (b), (vl))}] in
{
  def vmand : EPIBinBuiltin<"m", "mmm", "csil">;
  def vmnand : EPIBinBuiltin<"m", "mmm", "csil">;
  let CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
    vmandn_mm_b${Boolean}((a), (b), (vl))}] in
  def vmandnot : EPIBinBuiltin<"m", "mmm", "csil">;
  def vmxor : EPIBinBuiltin<"m", "mmm", "csil">;
  def vmor : EPIBinBuiltin<"m", "mmm", "csil">;
  def vmnor : EPIBinBuiltin<"m", "mmm", "csil">;
  let CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
    vmorn_mm_b${Boolean}((a), (b), (vl))}] in
  def vmornot : EPIBinBuiltin<"m", "mmm", "csil">;
  def vmxnor : EPIBinBuiltin<"m", "mmm", "csil">;
}

let HasMergeOperand = 0, EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_m_b${Boolean}((a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(a, mask, vl) \
        ${Name}_m_b${Boolean}_m((mask), (a), (vl))}] in
  def vfirst : EPIMaskToScalarBuiltin<"m", "sm", "csil">;

let HasMergeOperand = 0, EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        vcpop_m_b${Boolean}((a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(a, mask, vl) \
        vcpop_m_b${Boolean}_m((mask), (a), (vl))}] in
  def vpopc : EPIMaskToScalarBuiltin<"m", "sm", "csil">;

let HasMergeOperand = 0, EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_m_b${Boolean}((a), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(a, mask, vl) \
        ${Name}_m_b${Boolean}_m((mask), (a), (vl))}] in
{
def vmsbf : EPIMaskUnaBuiltin<"m", "mm", "csil">;
def vmsif : EPIMaskUnaBuiltin<"m", "mm", "csil">;
def vmsof : EPIMaskUnaBuiltin<"m", "mm", "csil">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(${Name}_m_${UType}${LMul}((a), (vl)))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, mask, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(${Name}_m_${UType}${LMul}_m((mask), (a), (vl)))}] in
def viota : EPIMaskToIntBuiltin<"v", "vm", "csil">;

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(${Name}_v_${UType}${LMul}((vl)))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, mask, vl) \
        vreinterpret_v_${UType}${LMul}_${Type}${LMul}(${Name}_v_${UType}${LMul}_m((mask), (vl)))}] in
def vid : EPINulBuiltin<"v", "v", "csil">;

let HasMask = 0, EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, b, vl) \
        ${Name}_${Type}${LMul}((b), (vl))}] in {
def vmv_s_x : EPIScalarToScalarVecBuiltin<"v", "vve", "csil">;
def vfmv_s_f : EPIScalarToScalarVecBuiltin<"v", "vve", "fd">;
}

let HasMask = 0, HasVL = 0, EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a) \
        ${Name}_${Type}${LMul}_${Type}((a))}] in {
def vmv_x_s : EPIVecToScalarBuiltin<"v", "ev", "csil">;
def vfmv_f_s : EPIVecToScalarBuiltin<"v", "ev", "fd">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, off, vl) \
        ${Name}_vx_${Type}${LMul}(vundefined_${Type}${LMul}(), (a), (off), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, off, mask, vl) \
        ${Name}_vx_${Type}${LMul}_m((mask), (merge), (a), (off), (vl))}] in {
def vslideup : EPIVecScalarBuiltin<"v", "vvu", "csilfd">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, off, vl) \
        ${Name}_vx_${Type}${LMul}((a), (off), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, off, mask, vl) \
        ${Name}_vx_${Type}${LMul}_m((mask), (a), (off), (vl))}] in {
def vslidedown : EPIVecScalarBuiltin<"v", "vvu", "csilfd">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, v, vl) \
        v${ifFloat}slide1up_v${Reg}_${Type}${LMul}((a), (v), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, v, mask, vl) \
        v${ifFloat}slide1up_v${Reg}_${Type}${LMul}_m((mask), (a), (v), (vl))}] in {
def vslide1up : EPIVecScalarBuiltin<"v", "vvu", "csilfd">;
}

let EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, v, vl) \
        v${ifFloat}slide1down_v${Reg}_${Type}${LMul}((a), (v), (vl))}],
    CompatibilityCodeMasked = [{#define __builtin_epi_${FullName}(merge, a, v, mask, vl) \
        v${ifFloat}slide1down_v${Reg}_${Type}${LMul}_m((mask), (a), (v), (vl))}] in {
def vslide1down : EPIVecScalarBuiltin<"v", "vvu", "csilfd">;
}

let HasMask = 0, EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, mask, vl) \
        ${Name}_vm_${Type}${LMul}((a), (mask), (vl))}] in {
def vcompress : EPIBinBuiltin<"v", "vvm", "csilfd">;
}

// FIXME EDIV intrinsics disabled
//def vdot : EPIBinBuiltin<"v", "vvv", "csil">;
//def vdotu : EPIBinBuiltin<"v", "vvv", "csil">;
//def vfdot : EPIBinBuiltin<"v", "vvv", "fd">;

let HasMask = 0, EPIRVVHeader = 1,
    CompatibilityCode = [{#define __builtin_epi_${FullName}(a, vl) \
        ${Name}_${Type}${LMul}((a), (vl))}] in {
def vmv_v_x : EPIScalarToVecBuiltin<"v", "ve", "csil">;
def vfmv_v_f : EPIScalarToVecBuiltin<"v", "ve", "fd">;
}

let LMUL = [1], HasMask = 0, HasVL = 0, Name = "cast", IntrinsicName = "" in
{
  let ManualCodegen = [{ {
      return Builder.CreateTrunc(Ops[0], ResultType);
  } }] in
  def cast_to_mask : EPIBuiltin<"mv", "mv", "csil">;

  let ManualCodegen = [{ {
      return Builder.CreateZExt(Ops[0], ResultType);
  } }] in
  def cast_from_mask : EPIBuiltin<"vm", "vm", "csil">;
}

// EPI experimental extensions
let LMUL = [1], HasMask = 0,
    ManualCodegen = [{
{
IntrinsicTypes = { Ops[0]->getType() };

llvm::Function *F = CGM.getIntrinsic(ID, IntrinsicTypes);
llvm::Value *CallValue = Builder.CreateCall(F, Ops, "");
llvm::Value *V = Builder.CreateInsertValue(
     llvm::UndefValue::get(ResultType),
     Builder.CreateExtractValue(CallValue, {0}),
     {0});
V = Builder.CreateInsertValue(
     V,
     Builder.CreateExtractValue(CallValue, {1}),
     {1});
if (ReturnValue.isNull())
  return V;
else
  return Builder.CreateStore(V, ReturnValue.getValue());
}
}]
in {

let IntrinsicName = "vzip2" in
def vzip2 : EPIBuiltin<"TTv", "TTvvv", "csildf">;

let IntrinsicName = "vunzip2" in
def vunzip2 : EPIBuiltin<"TTv", "TTvvv", "csildf">;

// Like a zip but first zip the elements in even-numbered positions and
// then the elements in odd-numbered positions.
let IntrinsicName = "vtrn" in
def vtrn : EPIBuiltin<"TTv", "TTvvv", "csildf">;

}
