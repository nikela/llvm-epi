// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang --target=riscv64-unknown-linux-gnu -mepi -S -emit-llvm -O2 -o - %s \
// RUN:       | FileCheck --check-prefix=CHECK-O2 %s

// CHECK-O2-LABEL: @vzip2i64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nxv1i64(ptr [[IN_A0:%.*]], i64 [[GVL:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nxv1i64(ptr [[IN_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP2:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vzip2.nxv1i64(<vscale x 1 x i64> [[TMP0]], <vscale x 1 x i64> [[TMP1]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP2]], 0
// CHECK-O2-NEXT:    [[TMP4:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP2]], 1
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1i64(<vscale x 1 x i64> [[TMP3]], ptr [[OUT_A0:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1i64(<vscale x 1 x i64> [[TMP4]], ptr [[OUT_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    ret void
//
void vzip2i64(long *in_a0, long *in_a1, long *out_a0, long *out_a1, long gvl) {
  __epi_1xi64 v0 = __builtin_epi_vload_1xi64(in_a0, gvl);
  __epi_1xi64 v1 = __builtin_epi_vload_1xi64(in_a1, gvl);

  __epi_1xi64x2 va;
  va = __builtin_epi_vzip2_1xi64x2(v0, v1, gvl);
  __builtin_epi_vstore_1xi64(out_a0, va.v0, gvl);
  __builtin_epi_vstore_1xi64(out_a1, va.v1, gvl);
}

// CHECK-O2-LABEL: @vunzip2i64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nxv1i64(ptr [[IN_A0:%.*]], i64 [[GVL:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nxv1i64(ptr [[IN_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP2:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vunzip2.nxv1i64(<vscale x 1 x i64> [[TMP0]], <vscale x 1 x i64> [[TMP1]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP2]], 0
// CHECK-O2-NEXT:    [[TMP4:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP2]], 1
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1i64(<vscale x 1 x i64> [[TMP3]], ptr [[OUT_A0:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1i64(<vscale x 1 x i64> [[TMP4]], ptr [[OUT_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    ret void
//
void vunzip2i64(long *in_a0, long *in_a1, long *out_a0, long *out_a1, long gvl) {
  __epi_1xi64 v0 = __builtin_epi_vload_1xi64(in_a0, gvl);
  __epi_1xi64 v1 = __builtin_epi_vload_1xi64(in_a1, gvl);

  __epi_1xi64x2 va;
  va = __builtin_epi_vunzip2_1xi64x2(v0, v1, gvl);
  __builtin_epi_vstore_1xi64(out_a0, va.v0, gvl);
  __builtin_epi_vstore_1xi64(out_a1, va.v1, gvl);
}

// CHECK-O2-LABEL: @vtrni64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nxv1i64(ptr [[IN_A0:%.*]], i64 [[GVL:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nxv1i64(ptr [[IN_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP2:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vtrn.nxv1i64(<vscale x 1 x i64> [[TMP0]], <vscale x 1 x i64> [[TMP1]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP2]], 0
// CHECK-O2-NEXT:    [[TMP4:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP2]], 1
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1i64(<vscale x 1 x i64> [[TMP3]], ptr [[OUT_A0:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1i64(<vscale x 1 x i64> [[TMP4]], ptr [[OUT_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    ret void
//
void vtrni64(long *in_a0, long *in_a1, long *out_a0, long *out_a1, long gvl) {
  __epi_1xi64 v0 = __builtin_epi_vload_1xi64(in_a0, gvl);
  __epi_1xi64 v1 = __builtin_epi_vload_1xi64(in_a1, gvl);

  __epi_1xi64x2 va;
  va = __builtin_epi_vtrn_1xi64x2(v0, v1, gvl);
  __builtin_epi_vstore_1xi64(out_a0, va.v0, gvl);
  __builtin_epi_vstore_1xi64(out_a1, va.v1, gvl);
}

// CHECK-O2-LABEL: @vzip2i32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nxv2i32(ptr [[IN_A0:%.*]], i64 [[GVL:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nxv2i32(ptr [[IN_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP2:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vzip2.nxv2i32(<vscale x 2 x i32> [[TMP0]], <vscale x 2 x i32> [[TMP1]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP2]], 0
// CHECK-O2-NEXT:    [[TMP4:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP2]], 1
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i32(<vscale x 2 x i32> [[TMP3]], ptr [[OUT_A0:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i32(<vscale x 2 x i32> [[TMP4]], ptr [[OUT_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    ret void
//
void vzip2i32(int *in_a0, int *in_a1, int *out_a0, int *out_a1, long gvl) {
  __epi_2xi32 v0 = __builtin_epi_vload_2xi32(in_a0, gvl);
  __epi_2xi32 v1 = __builtin_epi_vload_2xi32(in_a1, gvl);

  __epi_2xi32x2 va;
  va = __builtin_epi_vzip2_2xi32x2(v0, v1, gvl);
  __builtin_epi_vstore_2xi32(out_a0, va.v0, gvl);
  __builtin_epi_vstore_2xi32(out_a1, va.v1, gvl);
}

// CHECK-O2-LABEL: @vunzip2i32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nxv2i32(ptr [[IN_A0:%.*]], i64 [[GVL:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nxv2i32(ptr [[IN_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP2:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vunzip2.nxv2i32(<vscale x 2 x i32> [[TMP0]], <vscale x 2 x i32> [[TMP1]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP2]], 0
// CHECK-O2-NEXT:    [[TMP4:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP2]], 1
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i32(<vscale x 2 x i32> [[TMP3]], ptr [[OUT_A0:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i32(<vscale x 2 x i32> [[TMP4]], ptr [[OUT_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    ret void
//
void vunzip2i32(int *in_a0, int *in_a1, int *out_a0, int *out_a1, long gvl) {
  __epi_2xi32 v0 = __builtin_epi_vload_2xi32(in_a0, gvl);
  __epi_2xi32 v1 = __builtin_epi_vload_2xi32(in_a1, gvl);

  __epi_2xi32x2 va;
  va = __builtin_epi_vunzip2_2xi32x2(v0, v1, gvl);
  __builtin_epi_vstore_2xi32(out_a0, va.v0, gvl);
  __builtin_epi_vstore_2xi32(out_a1, va.v1, gvl);
}

// CHECK-O2-LABEL: @vtrni32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nxv2i32(ptr [[IN_A0:%.*]], i64 [[GVL:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nxv2i32(ptr [[IN_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP2:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vtrn.nxv2i32(<vscale x 2 x i32> [[TMP0]], <vscale x 2 x i32> [[TMP1]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP2]], 0
// CHECK-O2-NEXT:    [[TMP4:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP2]], 1
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i32(<vscale x 2 x i32> [[TMP3]], ptr [[OUT_A0:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i32(<vscale x 2 x i32> [[TMP4]], ptr [[OUT_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    ret void
//
void vtrni32(int *in_a0, int *in_a1, int *out_a0, int *out_a1, long gvl) {
  __epi_2xi32 v0 = __builtin_epi_vload_2xi32(in_a0, gvl);
  __epi_2xi32 v1 = __builtin_epi_vload_2xi32(in_a1, gvl);

  __epi_2xi32x2 va;
  va = __builtin_epi_vtrn_2xi32x2(v0, v1, gvl);
  __builtin_epi_vstore_2xi32(out_a0, va.v0, gvl);
  __builtin_epi_vstore_2xi32(out_a1, va.v1, gvl);
}

// CHECK-O2-LABEL: @vzip2f64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nxv1f64(ptr [[IN_A0:%.*]], i64 [[GVL:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nxv1f64(ptr [[IN_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP2:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vzip2.nxv1f64(<vscale x 1 x double> [[TMP0]], <vscale x 1 x double> [[TMP1]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP2]], 0
// CHECK-O2-NEXT:    [[TMP4:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP2]], 1
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1f64(<vscale x 1 x double> [[TMP3]], ptr [[OUT_A0:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1f64(<vscale x 1 x double> [[TMP4]], ptr [[OUT_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    ret void
//
void vzip2f64(double *in_a0, double *in_a1, double *out_a0, double *out_a1, long gvl) {
  __epi_1xf64 v0 = __builtin_epi_vload_1xf64(in_a0, gvl);
  __epi_1xf64 v1 = __builtin_epi_vload_1xf64(in_a1, gvl);

  __epi_1xf64x2 va;
  va = __builtin_epi_vzip2_1xf64x2(v0, v1, gvl);
  __builtin_epi_vstore_1xf64(out_a0, va.v0, gvl);
  __builtin_epi_vstore_1xf64(out_a1, va.v1, gvl);
}

// CHECK-O2-LABEL: @vunzip2f64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nxv1f64(ptr [[IN_A0:%.*]], i64 [[GVL:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nxv1f64(ptr [[IN_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP2:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vunzip2.nxv1f64(<vscale x 1 x double> [[TMP0]], <vscale x 1 x double> [[TMP1]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP2]], 0
// CHECK-O2-NEXT:    [[TMP4:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP2]], 1
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1f64(<vscale x 1 x double> [[TMP3]], ptr [[OUT_A0:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1f64(<vscale x 1 x double> [[TMP4]], ptr [[OUT_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    ret void
//
void vunzip2f64(double *in_a0, double *in_a1, double *out_a0, double *out_a1, long gvl) {
  __epi_1xf64 v0 = __builtin_epi_vload_1xf64(in_a0, gvl);
  __epi_1xf64 v1 = __builtin_epi_vload_1xf64(in_a1, gvl);

  __epi_1xf64x2 va;
  va = __builtin_epi_vunzip2_1xf64x2(v0, v1, gvl);
  __builtin_epi_vstore_1xf64(out_a0, va.v0, gvl);
  __builtin_epi_vstore_1xf64(out_a1, va.v1, gvl);
}

// CHECK-O2-LABEL: @vtrnf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nxv1f64(ptr [[IN_A0:%.*]], i64 [[GVL:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nxv1f64(ptr [[IN_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP2:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vtrn.nxv1f64(<vscale x 1 x double> [[TMP0]], <vscale x 1 x double> [[TMP1]], i64 [[GVL]])
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP2]], 0
// CHECK-O2-NEXT:    [[TMP4:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP2]], 1
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1f64(<vscale x 1 x double> [[TMP3]], ptr [[OUT_A0:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1f64(<vscale x 1 x double> [[TMP4]], ptr [[OUT_A1:%.*]], i64 [[GVL]])
// CHECK-O2-NEXT:    ret void
//
void vtrnf64(double *in_a0, double *in_a1, double *out_a0, double *out_a1, long gvl) {
  __epi_1xf64 v0 = __builtin_epi_vload_1xf64(in_a0, gvl);
  __epi_1xf64 v1 = __builtin_epi_vload_1xf64(in_a1, gvl);

  __epi_1xf64x2 va;
  va = __builtin_epi_vtrn_1xf64x2(v0, v1, gvl);
  __builtin_epi_vstore_1xf64(out_a0, va.v0, gvl);
  __builtin_epi_vstore_1xf64(out_a1, va.v1, gvl);
}
