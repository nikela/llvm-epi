// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang --target=riscv64-unknown-linux-gnu -mepi -S -emit-llvm -O2 -o - %s \
// RUN:       | FileCheck --check-prefix=CHECK-O2 %s

// CHECK-O2-LABEL: @test_cast_8xi8_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = zext <vscale x 8 x i1> [[ARG_0:%.*]] to <vscale x 8 x i8>
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_cast_8xi8_8xi1(__epi_8xi1 arg_0)
{
    return __builtin_epi_cast_8xi8_8xi1(arg_0);
}

// CHECK-O2-LABEL: @test_cast_4xi16_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = zext <vscale x 4 x i1> [[ARG_0:%.*]] to <vscale x 4 x i16>
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_cast_4xi16_4xi1(__epi_4xi1 arg_0)
{
    return __builtin_epi_cast_4xi16_4xi1(arg_0);
}

// CHECK-O2-LABEL: @test_cast_2xi32_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = zext <vscale x 2 x i1> [[ARG_0:%.*]] to <vscale x 2 x i32>
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_cast_2xi32_2xi1(__epi_2xi1 arg_0)
{
    return __builtin_epi_cast_2xi32_2xi1(arg_0);
}

// CHECK-O2-LABEL: @test_cast_1xi64_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = zext <vscale x 1 x i1> [[ARG_0:%.*]] to <vscale x 1 x i64>
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_cast_1xi64_1xi1(__epi_1xi1 arg_0)
{
    return __builtin_epi_cast_1xi64_1xi1(arg_0);
}

// CHECK-O2-LABEL: @test_cast_8xi1_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = trunc <vscale x 8 x i8> [[ARG_0:%.*]] to <vscale x 8 x i1>
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_cast_8xi1_8xi8(__epi_8xi8 arg_0)
{
    return __builtin_epi_cast_8xi1_8xi8(arg_0);
}

// CHECK-O2-LABEL: @test_cast_4xi1_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = trunc <vscale x 4 x i16> [[ARG_0:%.*]] to <vscale x 4 x i1>
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_cast_4xi1_4xi16(__epi_4xi16 arg_0)
{
    return __builtin_epi_cast_4xi1_4xi16(arg_0);
}

// CHECK-O2-LABEL: @test_cast_2xi1_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = trunc <vscale x 2 x i32> [[ARG_0:%.*]] to <vscale x 2 x i1>
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_cast_2xi1_2xi32(__epi_2xi32 arg_0)
{
    return __builtin_epi_cast_2xi1_2xi32(arg_0);
}

// CHECK-O2-LABEL: @test_cast_1xi1_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = trunc <vscale x 1 x i64> [[ARG_0:%.*]] to <vscale x 1 x i1>
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_cast_1xi1_1xi64(__epi_1xi64 arg_0)
{
    return __builtin_epi_cast_1xi1_1xi64(arg_0);
}

// CHECK-O2-LABEL: @test_vaadd_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vaadd.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vaadd_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vaadd.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vaadd_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vaadd.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vaadd_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vaadd.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vaadd_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vaadd.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vaadd_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vaadd.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vaadd_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vaadd.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vaadd_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vaadd.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vaadd_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vaadd.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vaadd_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vaadd.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vaadd_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vaadd.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vaadd_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vaadd.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vaadd_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vaadd.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vaadd_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vaadd.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vaadd_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vaadd.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vaadd_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vaadd.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vaadd_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vaadd.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vaadd_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vaadd.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vaadd_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vaadd.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vaadd_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vaadd.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vaadd_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vaadd.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vaadd_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vaadd.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vaadd_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vaadd_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vaadd.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vaadd_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vaadd_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vaadd_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vaadd.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vaadd_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vaadd_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadc_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vadc.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vadc_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vadc_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vadc_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vadc.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vadc_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vadc_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vadc_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vadc.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vadc_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vadc_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vadc_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vadc.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vadc_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vadc_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vadc_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vadc.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vadc_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vadc_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vadc_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vadc.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vadc_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vadc_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vadc_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vadc.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vadc_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vadc_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vadc_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vadc.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vadc_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vadc_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vadc_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vadc.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vadc_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vadc_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vadc_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vadc.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vadc_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vadc_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vadc_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vadc.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vadc_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vadc_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vadc_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vadc.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vadc_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vadc_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vadd_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vadd.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vadd_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vadd.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vadd_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vadd.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vadd_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vadd.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vadd_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vadd.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vadd_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vadd.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vadd_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vadd.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vadd_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vadd.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vadd_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vadd.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vadd_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vadd.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vadd_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vadd.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vadd_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vadd.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vadd_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vadd.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vadd_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vadd.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vadd_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vadd.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vadd_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vadd.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vadd_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vadd.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vadd_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vadd.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vadd_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vadd.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vadd_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vadd.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vadd_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vadd.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vadd_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vadd.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vadd_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vadd_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vadd.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vadd_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vadd_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vadd_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vadd.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vadd_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vadd_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vand.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vand_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vand.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vand_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vand.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vand_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vand.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vand_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vand.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vand_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vand.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vand_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vand.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vand_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vand.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vand_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vand.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vand_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vand.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vand_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vand.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vand_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vand.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vand_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vand.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vand_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vand.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vand_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vand.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vand_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vand.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vand_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vand.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vand_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vand.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vand_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vand.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vand_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vand.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vand_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vand.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vand_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vand.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vand_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vand_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vand.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vand_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vand_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vand_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vand.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vand_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vand_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vasub.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vasub_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vasub.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vasub_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vasub.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vasub_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vasub.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vasub_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vasub.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vasub_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vasub.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vasub_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vasub.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vasub_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vasub.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vasub_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vasub.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vasub_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vasub.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vasub_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vasub.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vasub_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vasub.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vasub_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vasub.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vasub_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vasub.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vasub_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vasub.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vasub_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vasub.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vasub_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vasub.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vasub_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vasub.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vasub_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vasub.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vasub_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vasub.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vasub_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vasub.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vasub_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vasub.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vasub_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vasub_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vasub.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vasub_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vasub_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vasub_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vasub.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vasub_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vasub_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vcompress_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vcompress.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vcompress_8xi8(__epi_8xi8 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vcompress.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vcompress_4xi16(__epi_4xi16 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vcompress.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vcompress_2xi32(__epi_2xi32 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vcompress.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vcompress_1xi64(__epi_1xi64 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vcompress.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vcompress_2xf32(__epi_2xf32 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vcompress.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vcompress_1xf64(__epi_1xf64 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vcompress.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vcompress_16xi8(__epi_16xi8 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vcompress.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vcompress_8xi16(__epi_8xi16 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vcompress.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vcompress_4xi32(__epi_4xi32 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vcompress.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vcompress_2xi64(__epi_2xi64 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vcompress.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vcompress_4xf32(__epi_4xf32 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vcompress.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vcompress_2xf64(__epi_2xf64 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vcompress.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vcompress_32xi8(__epi_32xi8 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vcompress.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vcompress_16xi16(__epi_16xi16 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vcompress.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vcompress_8xi32(__epi_8xi32 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vcompress.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vcompress_4xi64(__epi_4xi64 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vcompress.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vcompress_8xf32(__epi_8xf32 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vcompress_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vcompress.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vcompress_4xf64(__epi_4xf64 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vcompress_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vdiv.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vdiv_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vdiv.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vdiv_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vdiv.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vdiv_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vdiv.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vdiv_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vdiv.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vdiv_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vdiv.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vdiv_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vdiv.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vdiv_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vdiv.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vdiv_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vdiv.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vdiv_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vdiv.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vdiv_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vdiv.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vdiv_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vdiv.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vdiv_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vdiv.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vdiv_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vdiv.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vdiv_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vdiv.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vdiv_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vdiv.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vdiv_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vdiv.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vdiv_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vdiv.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vdiv_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vdiv.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vdiv_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vdiv.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vdiv_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vdiv.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vdiv_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vdiv.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vdiv_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdiv_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vdiv.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vdiv_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdiv_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdiv_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vdiv.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vdiv_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdiv_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vdivu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vdivu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vdivu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vdivu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vdivu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vdivu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vdivu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vdivu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vdivu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vdivu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vdivu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vdivu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vdivu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vdivu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vdivu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vdivu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vdivu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vdivu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vdivu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vdivu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vdivu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vdivu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vdivu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vdivu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vdivu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vdivu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vdivu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vdivu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vdivu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vdivu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vdivu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vdivu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vdivu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vdivu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vdivu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vdivu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vdivu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vdivu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vdivu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vdivu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vdivu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vdivu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vdivu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vdivu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vdivu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vdivu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vdivu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vdivu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vdivu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vdivu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vdivu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vdivu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfadd_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfadd.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfadd_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfadd_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfadd_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfadd.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfadd_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfadd_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfadd_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfadd.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfadd_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfadd_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfadd_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfadd.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfadd_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfadd_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfadd_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfadd.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfadd_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfadd_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfadd_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfadd.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfadd_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfadd_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfadd_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfadd.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfadd_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfadd_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfadd_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfadd.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfadd_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfadd_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfadd_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfadd.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfadd_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfadd_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfadd_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfadd.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfadd_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfadd_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfadd_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfadd.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfadd_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfadd_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfadd_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfadd.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfadd_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfadd_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_2xf32_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfcvt.f.x.nxv2f32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfcvt_f_x_2xf32_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_x_2xf32_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_2xf32_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfcvt.f.x.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfcvt_f_x_2xf32_2xi32_mask(__epi_2xf32 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_x_2xf32_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_1xf64_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfcvt.f.x.nxv1f64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfcvt_f_x_1xf64_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_x_1xf64_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_1xf64_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfcvt.f.x.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfcvt_f_x_1xf64_1xi64_mask(__epi_1xf64 arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_x_1xf64_1xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_4xf32_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfcvt.f.x.nxv4f32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfcvt_f_x_4xf32_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_x_4xf32_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_4xf32_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfcvt.f.x.mask.nxv4f32.nxv4i32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfcvt_f_x_4xf32_4xi32_mask(__epi_4xf32 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_x_4xf32_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_2xf64_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfcvt.f.x.nxv2f64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfcvt_f_x_2xf64_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_x_2xf64_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_2xf64_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfcvt.f.x.mask.nxv2f64.nxv2i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfcvt_f_x_2xf64_2xi64_mask(__epi_2xf64 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_x_2xf64_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_8xf32_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfcvt.f.x.nxv8f32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfcvt_f_x_8xf32_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_x_8xf32_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_8xf32_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfcvt.f.x.mask.nxv8f32.nxv8i32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfcvt_f_x_8xf32_8xi32_mask(__epi_8xf32 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_x_8xf32_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_4xf64_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfcvt.f.x.nxv4f64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfcvt_f_x_4xf64_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_x_4xf64_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_x_4xf64_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfcvt.f.x.mask.nxv4f64.nxv4i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfcvt_f_x_4xf64_4xi64_mask(__epi_4xf64 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_x_4xf64_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_2xf32_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfcvt.f.xu.nxv2f32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfcvt_f_xu_2xf32_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_xu_2xf32_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_2xf32_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfcvt.f.xu.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfcvt_f_xu_2xf32_2xi32_mask(__epi_2xf32 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_xu_2xf32_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_1xf64_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfcvt.f.xu.nxv1f64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfcvt_f_xu_1xf64_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_xu_1xf64_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_1xf64_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfcvt.f.xu.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfcvt_f_xu_1xf64_1xi64_mask(__epi_1xf64 arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_xu_1xf64_1xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_4xf32_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfcvt.f.xu.nxv4f32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfcvt_f_xu_4xf32_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_xu_4xf32_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_4xf32_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfcvt.f.xu.mask.nxv4f32.nxv4i32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfcvt_f_xu_4xf32_4xi32_mask(__epi_4xf32 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_xu_4xf32_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_2xf64_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfcvt.f.xu.nxv2f64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfcvt_f_xu_2xf64_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_xu_2xf64_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_2xf64_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfcvt.f.xu.mask.nxv2f64.nxv2i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfcvt_f_xu_2xf64_2xi64_mask(__epi_2xf64 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_xu_2xf64_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_8xf32_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfcvt.f.xu.nxv8f32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfcvt_f_xu_8xf32_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_xu_8xf32_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_8xf32_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfcvt.f.xu.mask.nxv8f32.nxv8i32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfcvt_f_xu_8xf32_8xi32_mask(__epi_8xf32 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_xu_8xf32_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_4xf64_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfcvt.f.xu.nxv4f64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfcvt_f_xu_4xf64_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_f_xu_4xf64_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_f_xu_4xf64_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfcvt.f.xu.mask.nxv4f64.nxv4i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfcvt_f_xu_4xf64_4xi64_mask(__epi_4xf64 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_f_xu_4xf64_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_2xi32_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfcvt.x.f.nxv2i32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfcvt_x_f_2xi32_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_x_f_2xi32_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_2xi32_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfcvt.x.f.mask.nxv2i32.nxv2f32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfcvt_x_f_2xi32_2xf32_mask(__epi_2xi32 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_x_f_2xi32_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_1xi64_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vfcvt.x.f.nxv1i64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vfcvt_x_f_1xi64_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_x_f_1xi64_1xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_1xi64_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vfcvt.x.f.mask.nxv1i64.nxv1f64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vfcvt_x_f_1xi64_1xf64_mask(__epi_1xi64 arg_0, __epi_1xf64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_x_f_1xi64_1xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_4xi32_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfcvt.x.f.nxv4i32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfcvt_x_f_4xi32_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_x_f_4xi32_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_4xi32_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfcvt.x.f.mask.nxv4i32.nxv4f32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfcvt_x_f_4xi32_4xf32_mask(__epi_4xi32 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_x_f_4xi32_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_2xi64_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfcvt.x.f.nxv2i64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfcvt_x_f_2xi64_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_x_f_2xi64_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_2xi64_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfcvt.x.f.mask.nxv2i64.nxv2f64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfcvt_x_f_2xi64_2xf64_mask(__epi_2xi64 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_x_f_2xi64_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_8xi32_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfcvt.x.f.nxv8i32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfcvt_x_f_8xi32_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_x_f_8xi32_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_8xi32_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfcvt.x.f.mask.nxv8i32.nxv8f32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfcvt_x_f_8xi32_8xf32_mask(__epi_8xi32 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_x_f_8xi32_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_4xi64_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfcvt.x.f.nxv4i64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfcvt_x_f_4xi64_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_x_f_4xi64_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_x_f_4xi64_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfcvt.x.f.mask.nxv4i64.nxv4f64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfcvt_x_f_4xi64_4xf64_mask(__epi_4xi64 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_x_f_4xi64_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_2xi32_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfcvt.xu.f.nxv2i32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfcvt_xu_f_2xi32_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_xu_f_2xi32_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_2xi32_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfcvt.xu.f.mask.nxv2i32.nxv2f32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfcvt_xu_f_2xi32_2xf32_mask(__epi_2xi32 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_xu_f_2xi32_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_1xi64_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vfcvt.xu.f.nxv1i64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vfcvt_xu_f_1xi64_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_xu_f_1xi64_1xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_1xi64_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vfcvt.xu.f.mask.nxv1i64.nxv1f64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vfcvt_xu_f_1xi64_1xf64_mask(__epi_1xi64 arg_0, __epi_1xf64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_xu_f_1xi64_1xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_4xi32_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfcvt.xu.f.nxv4i32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfcvt_xu_f_4xi32_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_xu_f_4xi32_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_4xi32_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfcvt.xu.f.mask.nxv4i32.nxv4f32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfcvt_xu_f_4xi32_4xf32_mask(__epi_4xi32 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_xu_f_4xi32_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_2xi64_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfcvt.xu.f.nxv2i64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfcvt_xu_f_2xi64_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_xu_f_2xi64_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_2xi64_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfcvt.xu.f.mask.nxv2i64.nxv2f64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfcvt_xu_f_2xi64_2xf64_mask(__epi_2xi64 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_xu_f_2xi64_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_8xi32_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfcvt.xu.f.nxv8i32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfcvt_xu_f_8xi32_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_xu_f_8xi32_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_8xi32_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfcvt.xu.f.mask.nxv8i32.nxv8f32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfcvt_xu_f_8xi32_8xf32_mask(__epi_8xi32 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_xu_f_8xi32_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_4xi64_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfcvt.xu.f.nxv4i64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfcvt_xu_f_4xi64_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfcvt_xu_f_4xi64_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfcvt_xu_f_4xi64_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfcvt.xu.f.mask.nxv4i64.nxv4f64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfcvt_xu_f_4xi64_4xf64_mask(__epi_4xi64 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfcvt_xu_f_4xi64_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfdiv_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfdiv.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfdiv_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdiv_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdiv_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfdiv.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfdiv_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdiv_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdiv_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfdiv.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfdiv_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdiv_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdiv_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfdiv.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfdiv_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdiv_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdiv_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfdiv.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfdiv_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdiv_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdiv_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfdiv.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfdiv_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdiv_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdiv_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfdiv.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfdiv_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdiv_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdiv_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfdiv.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfdiv_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdiv_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdiv_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfdiv.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfdiv_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdiv_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdiv_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfdiv.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfdiv_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdiv_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfdiv_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfdiv.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfdiv_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfdiv_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfdiv_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfdiv.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfdiv_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfdiv_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfirst_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vfirst.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vfirst_8xi1(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfirst_8xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfirst_8xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vfirst.mask.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vfirst_8xi1_mask(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfirst_8xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfirst_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vfirst.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vfirst_4xi1(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfirst_4xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfirst_4xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vfirst.mask.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vfirst_4xi1_mask(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfirst_4xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfirst_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vfirst.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vfirst_2xi1(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfirst_2xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfirst_2xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vfirst.mask.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vfirst_2xi1_mask(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfirst_2xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfirst_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vfirst.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vfirst_1xi1(__epi_1xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfirst_1xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfirst_1xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vfirst.mask.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vfirst_1xi1_mask(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfirst_1xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfirst_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vfirst.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vfirst_16xi1(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfirst_16xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfirst_16xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vfirst.mask.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vfirst_16xi1_mask(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfirst_16xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfirst_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vfirst.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vfirst_32xi1(__epi_32xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfirst_32xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfirst_32xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vfirst.mask.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vfirst_32xi1_mask(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfirst_32xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmacc_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmacc.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmacc_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmacc_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmacc_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmacc.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmacc_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmacc_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmacc_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmacc.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmacc_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmacc_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmacc_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmacc.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmacc_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmacc_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmacc_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmacc.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmacc_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmacc_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmacc_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmacc.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmacc_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmacc_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmacc_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmacc.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmacc_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmacc_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmacc_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmacc.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmacc_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmacc_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmacc_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmacc.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmacc_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmacc_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmacc_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmacc.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmacc_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmacc_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmacc_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmacc.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmacc_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmacc_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmacc_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmacc.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmacc_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmacc_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmadd_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmadd.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmadd_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmadd_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmadd_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmadd.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmadd_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmadd_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmadd_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmadd.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmadd_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmadd_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmadd_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmadd.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmadd_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmadd_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmadd_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmadd.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmadd_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmadd_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmadd_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmadd.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmadd_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmadd_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmadd_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmadd.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmadd_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmadd_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmadd_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmadd.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmadd_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmadd_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmadd_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmadd.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmadd_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmadd_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmadd_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmadd.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmadd_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmadd_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmadd_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmadd.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmadd_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmadd_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmadd_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmadd.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmadd_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmadd_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmax_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmax.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmax_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmax_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmax_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmax.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmax_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmax_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmax_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmax.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmax_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmax_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmax_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmax.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmax_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmax_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmax_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmax.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmax_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmax_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmax_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmax.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmax_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmax_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmax_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmax.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmax_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmax_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmax_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmax.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmax_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmax_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmax_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmax.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmax_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmax_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmax_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmax.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmax_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmax_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmax_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmax.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmax_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmax_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmax_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmax.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmax_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmax_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmerge_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmerge.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmerge_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmerge_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmerge_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmerge.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmerge_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmerge_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmerge_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmerge.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmerge_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmerge_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmerge_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmerge.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmerge_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmerge_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmerge_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmerge.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmerge_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmerge_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmerge_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmerge.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmerge_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmerge_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmin_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmin.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmin_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmin_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmin_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmin.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmin_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmin_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmin_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmin.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmin_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmin_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmin_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmin.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmin_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmin_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmin_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmin.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmin_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmin_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmin_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmin.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmin_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmin_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmin_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmin.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmin_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmin_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmin_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmin.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmin_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmin_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmin_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmin.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmin_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmin_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmin_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmin.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmin_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmin_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmin_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmin.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmin_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmin_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmin_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmin.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmin_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmin_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsac_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmsac.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmsac_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsac_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsac_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmsac.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmsac_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsac_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsac_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmsac.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmsac_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsac_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsac_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmsac.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmsac_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsac_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsac_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmsac.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmsac_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsac_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsac_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmsac.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmsac_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsac_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsac_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmsac.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmsac_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsac_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsac_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmsac.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmsac_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsac_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsac_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmsac.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmsac_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsac_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsac_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmsac.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmsac_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsac_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsac_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmsac.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmsac_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsac_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsac_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmsac.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmsac_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsac_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsub_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmsub.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmsub_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsub_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsub_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmsub.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmsub_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsub_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsub_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmsub.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmsub_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsub_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsub_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmsub.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmsub_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsub_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsub_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmsub.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmsub_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsub_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsub_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmsub.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmsub_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsub_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsub_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmsub.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmsub_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsub_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsub_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmsub.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmsub_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsub_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsub_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmsub.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmsub_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsub_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsub_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmsub.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmsub_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsub_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmsub_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmsub.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmsub_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfmsub_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfmsub_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmsub.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmsub_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmsub_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmul_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmul.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmul_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmul_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmul_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmul.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmul_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmul_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmul_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmul.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmul_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmul_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmul_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmul.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmul_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmul_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmul_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmul.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmul_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmul_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmul_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmul.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmul_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmul_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmul_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmul.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmul_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmul_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmul_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmul.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmul_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmul_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmul_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmul.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmul_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmul_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmul_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmul.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmul_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmul_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmul_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmul.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmul_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmul_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmul_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmul.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmul_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfmul_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfmv_f_s_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call float @llvm.epi.vfmv.f.s.f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret float [[TMP0]]
//
float test_vfmv_f_s_2xf32(__epi_2xf32 arg_0)
{
    return __builtin_epi_vfmv_f_s_2xf32(arg_0);
}

// CHECK-O2-LABEL: @test_vfmv_f_s_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call double @llvm.epi.vfmv.f.s.f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret double [[TMP0]]
//
double test_vfmv_f_s_1xf64(__epi_1xf64 arg_0)
{
    return __builtin_epi_vfmv_f_s_1xf64(arg_0);
}

// CHECK-O2-LABEL: @test_vfmv_f_s_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call float @llvm.epi.vfmv.f.s.f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret float [[TMP0]]
//
float test_vfmv_f_s_4xf32(__epi_4xf32 arg_0)
{
    return __builtin_epi_vfmv_f_s_4xf32(arg_0);
}

// CHECK-O2-LABEL: @test_vfmv_f_s_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call double @llvm.epi.vfmv.f.s.f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret double [[TMP0]]
//
double test_vfmv_f_s_2xf64(__epi_2xf64 arg_0)
{
    return __builtin_epi_vfmv_f_s_2xf64(arg_0);
}

// CHECK-O2-LABEL: @test_vfmv_f_s_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call float @llvm.epi.vfmv.f.s.f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret float [[TMP0]]
//
float test_vfmv_f_s_8xf32(__epi_8xf32 arg_0)
{
    return __builtin_epi_vfmv_f_s_8xf32(arg_0);
}

// CHECK-O2-LABEL: @test_vfmv_f_s_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call double @llvm.epi.vfmv.f.s.f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret double [[TMP0]]
//
double test_vfmv_f_s_4xf64(__epi_4xf64 arg_0)
{
    return __builtin_epi_vfmv_f_s_4xf64(arg_0);
}

// CHECK-O2-LABEL: @test_vfmv_s_f_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmv.s.f.nxv2f32.f32(<vscale x 2 x float> [[ARG_0:%.*]], float [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmv_s_f_2xf32(__epi_2xf32 arg_0, float arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmv_s_f_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmv_s_f_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmv.s.f.nxv1f64.f64(<vscale x 1 x double> [[ARG_0:%.*]], double [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmv_s_f_1xf64(__epi_1xf64 arg_0, double arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmv_s_f_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmv_s_f_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmv.s.f.nxv4f32.f32(<vscale x 4 x float> [[ARG_0:%.*]], float [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmv_s_f_4xf32(__epi_4xf32 arg_0, float arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmv_s_f_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmv_s_f_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmv.s.f.nxv2f64.f64(<vscale x 2 x double> [[ARG_0:%.*]], double [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmv_s_f_2xf64(__epi_2xf64 arg_0, double arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmv_s_f_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmv_s_f_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmv.s.f.nxv8f32.f32(<vscale x 8 x float> [[ARG_0:%.*]], float [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmv_s_f_8xf32(__epi_8xf32 arg_0, float arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmv_s_f_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmv_s_f_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmv.s.f.nxv4f64.f64(<vscale x 4 x double> [[ARG_0:%.*]], double [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmv_s_f_4xf64(__epi_4xf64 arg_0, double arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfmv_s_f_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfmv_v_f_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfmv.v.f.nxv2f32.f32(float [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfmv_v_f_2xf32(float arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfmv_v_f_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfmv_v_f_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfmv.v.f.nxv1f64.f64(double [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfmv_v_f_1xf64(double arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfmv_v_f_1xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfmv_v_f_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfmv.v.f.nxv4f32.f32(float [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfmv_v_f_4xf32(float arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfmv_v_f_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfmv_v_f_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfmv.v.f.nxv2f64.f64(double [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfmv_v_f_2xf64(double arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfmv_v_f_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfmv_v_f_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfmv.v.f.nxv8f32.f32(float [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfmv_v_f_8xf32(float arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfmv_v_f_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfmv_v_f_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfmv.v.f.nxv4f64.f64(double [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfmv_v_f_4xf64(double arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfmv_v_f_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_f_2xf32_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfncvt.f.f.nxv2f32.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfncvt_f_f_2xf32_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_f_2xf32_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_f_2xf32_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfncvt.f.f.mask.nxv2f32.nxv2f64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfncvt_f_f_2xf32_2xf64_mask(__epi_2xf32 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_f_2xf32_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_f_4xf32_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfncvt.f.f.nxv4f32.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfncvt_f_f_4xf32_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_f_4xf32_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_f_4xf32_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfncvt.f.f.mask.nxv4f32.nxv4f64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfncvt_f_f_4xf32_4xf64_mask(__epi_4xf32 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_f_4xf32_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_f_8xf32_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfncvt.f.f.nxv8f32.nxv8f64(<vscale x 8 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfncvt_f_f_8xf32_8xf64(__epi_8xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_f_8xf32_8xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_f_8xf32_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfncvt.f.f.mask.nxv8f32.nxv8f64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfncvt_f_f_8xf32_8xf64_mask(__epi_8xf32 arg_0, __epi_8xf64 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_f_8xf32_8xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_x_2xf32_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfncvt.f.x.nxv2f32.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfncvt_f_x_2xf32_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_x_2xf32_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_x_2xf32_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfncvt.f.x.mask.nxv2f32.nxv2i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfncvt_f_x_2xf32_2xi64_mask(__epi_2xf32 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_x_2xf32_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_x_4xf32_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfncvt.f.x.nxv4f32.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfncvt_f_x_4xf32_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_x_4xf32_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_x_4xf32_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfncvt.f.x.mask.nxv4f32.nxv4i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfncvt_f_x_4xf32_4xi64_mask(__epi_4xf32 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_x_4xf32_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_x_8xf32_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfncvt.f.x.nxv8f32.nxv8i64(<vscale x 8 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfncvt_f_x_8xf32_8xi64(__epi_8xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_x_8xf32_8xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_x_8xf32_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfncvt.f.x.mask.nxv8f32.nxv8i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfncvt_f_x_8xf32_8xi64_mask(__epi_8xf32 arg_0, __epi_8xi64 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_x_8xf32_8xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_xu_2xf32_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfncvt.f.xu.nxv2f32.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfncvt_f_xu_2xf32_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_xu_2xf32_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_xu_2xf32_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfncvt.f.xu.mask.nxv2f32.nxv2i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfncvt_f_xu_2xf32_2xi64_mask(__epi_2xf32 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_xu_2xf32_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_xu_4xf32_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfncvt.f.xu.nxv4f32.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfncvt_f_xu_4xf32_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_xu_4xf32_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_xu_4xf32_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfncvt.f.xu.mask.nxv4f32.nxv4i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfncvt_f_xu_4xf32_4xi64_mask(__epi_4xf32 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_xu_4xf32_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_f_xu_8xf32_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfncvt.f.xu.nxv8f32.nxv8i64(<vscale x 8 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfncvt_f_xu_8xf32_8xi64(__epi_8xi64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_f_xu_8xf32_8xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_f_xu_8xf32_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfncvt.f.xu.mask.nxv8f32.nxv8i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfncvt_f_xu_8xf32_8xi64_mask(__epi_8xf32 arg_0, __epi_8xi64 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_f_xu_8xf32_8xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_4xi16_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vfncvt.x.f.nxv4i16.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vfncvt_x_f_4xi16_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_x_f_4xi16_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_4xi16_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vfncvt.x.f.mask.nxv4i16.nxv4f32.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vfncvt_x_f_4xi16_4xf32_mask(__epi_4xi16 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_x_f_4xi16_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_2xi32_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfncvt.x.f.nxv2i32.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfncvt_x_f_2xi32_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_x_f_2xi32_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_2xi32_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfncvt.x.f.mask.nxv2i32.nxv2f64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfncvt_x_f_2xi32_2xf64_mask(__epi_2xi32 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_x_f_2xi32_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_8xi16_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vfncvt.x.f.nxv8i16.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vfncvt_x_f_8xi16_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_x_f_8xi16_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_8xi16_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vfncvt.x.f.mask.nxv8i16.nxv8f32.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vfncvt_x_f_8xi16_8xf32_mask(__epi_8xi16 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_x_f_8xi16_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_4xi32_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfncvt.x.f.nxv4i32.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfncvt_x_f_4xi32_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_x_f_4xi32_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_4xi32_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfncvt.x.f.mask.nxv4i32.nxv4f64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfncvt_x_f_4xi32_4xf64_mask(__epi_4xi32 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_x_f_4xi32_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_16xi16_16xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vfncvt.x.f.nxv16i16.nxv16f32(<vscale x 16 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vfncvt_x_f_16xi16_16xf32(__epi_16xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_x_f_16xi16_16xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_16xi16_16xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vfncvt.x.f.mask.nxv16i16.nxv16f32.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x float> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vfncvt_x_f_16xi16_16xf32_mask(__epi_16xi16 arg_0, __epi_16xf32 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_x_f_16xi16_16xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_8xi32_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfncvt.x.f.nxv8i32.nxv8f64(<vscale x 8 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfncvt_x_f_8xi32_8xf64(__epi_8xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_x_f_8xi32_8xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_x_f_8xi32_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfncvt.x.f.mask.nxv8i32.nxv8f64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfncvt_x_f_8xi32_8xf64_mask(__epi_8xi32 arg_0, __epi_8xf64 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_x_f_8xi32_8xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_4xi16_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vfncvt.xu.f.nxv4i16.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vfncvt_xu_f_4xi16_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_xu_f_4xi16_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_4xi16_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vfncvt.xu.f.mask.nxv4i16.nxv4f32.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vfncvt_xu_f_4xi16_4xf32_mask(__epi_4xi16 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_xu_f_4xi16_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_2xi32_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfncvt.xu.f.nxv2i32.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfncvt_xu_f_2xi32_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_xu_f_2xi32_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_2xi32_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vfncvt.xu.f.mask.nxv2i32.nxv2f64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vfncvt_xu_f_2xi32_2xf64_mask(__epi_2xi32 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_xu_f_2xi32_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_8xi16_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vfncvt.xu.f.nxv8i16.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vfncvt_xu_f_8xi16_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_xu_f_8xi16_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_8xi16_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vfncvt.xu.f.mask.nxv8i16.nxv8f32.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vfncvt_xu_f_8xi16_8xf32_mask(__epi_8xi16 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_xu_f_8xi16_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_4xi32_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfncvt.xu.f.nxv4i32.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfncvt_xu_f_4xi32_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_xu_f_4xi32_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_4xi32_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vfncvt.xu.f.mask.nxv4i32.nxv4f64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vfncvt_xu_f_4xi32_4xf64_mask(__epi_4xi32 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_xu_f_4xi32_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_16xi16_16xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vfncvt.xu.f.nxv16i16.nxv16f32(<vscale x 16 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vfncvt_xu_f_16xi16_16xf32(__epi_16xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_xu_f_16xi16_16xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_16xi16_16xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vfncvt.xu.f.mask.nxv16i16.nxv16f32.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x float> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vfncvt_xu_f_16xi16_16xf32_mask(__epi_16xi16 arg_0, __epi_16xf32 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_xu_f_16xi16_16xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_8xi32_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfncvt.xu.f.nxv8i32.nxv8f64(<vscale x 8 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfncvt_xu_f_8xi32_8xf64(__epi_8xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfncvt_xu_f_8xi32_8xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfncvt_xu_f_8xi32_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vfncvt.xu.f.mask.nxv8i32.nxv8f64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vfncvt_xu_f_8xi32_8xf64_mask(__epi_8xi32 arg_0, __epi_8xf64 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfncvt_xu_f_8xi32_8xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmacc.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmacc_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmacc_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmacc.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmacc_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmacc_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmacc_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmacc.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmacc_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmacc_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmacc.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmacc_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmacc_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmacc_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmacc.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmacc_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmacc_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmacc.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmacc_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmacc_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmacc_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmacc.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmacc_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmacc_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmacc.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmacc_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmacc_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmacc_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmacc.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmacc_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmacc_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmacc.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmacc_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmacc_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmacc_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmacc.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmacc_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmacc_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmacc_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmacc.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmacc_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmacc_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmadd_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmadd.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmadd_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmadd_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmadd_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmadd.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmadd_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmadd_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmadd_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmadd.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmadd_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmadd_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmadd_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmadd.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmadd_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmadd_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmadd_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmadd.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmadd_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmadd_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmadd_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmadd.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmadd_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmadd_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmadd_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmadd.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmadd_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmadd_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmadd_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmadd.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmadd_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmadd_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmadd_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmadd.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmadd_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmadd_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmadd_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmadd.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmadd_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmadd_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmadd_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmadd.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmadd_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmadd_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmadd_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmadd.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmadd_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmadd_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsac_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmsac.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmsac_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsac_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsac_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmsac.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmsac_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsac_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsac_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmsac.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmsac_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsac_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsac_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmsac.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmsac_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsac_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsac_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmsac.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmsac_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsac_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsac_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmsac.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmsac_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsac_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsac_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmsac.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmsac_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsac_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsac_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmsac.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmsac_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsac_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsac_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmsac.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmsac_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsac_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsac_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmsac.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmsac_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsac_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsac_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmsac.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmsac_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsac_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsac_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmsac.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmsac_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsac_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsub_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmsub.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmsub_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsub_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsub_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfnmsub.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfnmsub_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsub_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsub_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmsub.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmsub_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsub_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsub_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfnmsub.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfnmsub_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsub_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsub_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmsub.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmsub_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsub_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsub_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfnmsub.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfnmsub_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsub_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsub_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmsub.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmsub_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsub_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsub_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfnmsub.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfnmsub_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsub_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsub_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmsub.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmsub_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsub_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsub_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfnmsub.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfnmsub_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsub_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfnmsub_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmsub.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmsub_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfnmsub_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfnmsub_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfnmsub.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfnmsub_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfnmsub_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmax_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredmax.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredmax_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmax_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmax_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredmax.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredmax_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmax_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmax_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredmax.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredmax_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmax_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmax_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredmax.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredmax_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmax_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmax_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredmax.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredmax_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmax_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmax_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredmax.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredmax_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmax_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmax_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredmax.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredmax_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmax_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmax_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredmax.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredmax_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmax_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmax_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredmax.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredmax_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmax_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmax_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredmax.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredmax_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmax_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmax_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredmax.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredmax_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmax_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmax_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredmax.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredmax_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmax_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmin_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredmin.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredmin_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmin_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmin_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredmin.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredmin_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmin_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmin_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredmin.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredmin_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmin_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmin_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredmin.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredmin_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmin_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmin_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredmin.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredmin_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmin_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmin_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredmin.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredmin_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmin_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmin_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredmin.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredmin_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmin_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmin_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredmin.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredmin_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmin_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmin_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredmin.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredmin_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmin_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmin_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredmin.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredmin_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmin_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredmin_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredmin.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredmin_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredmin_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredmin_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredmin.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredmin_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredmin_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredosum_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredosum.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredosum_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredosum_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredosum_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredosum.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredosum_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredosum_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredosum_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredosum.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredosum_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredosum_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredosum_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredosum.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredosum_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredosum_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredosum_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredosum.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredosum_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredosum_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredosum_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredosum.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredosum_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredosum_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredosum_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredosum.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredosum_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredosum_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredosum_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredosum.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredosum_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredosum_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredosum_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredosum.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredosum_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredosum_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredosum_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredosum.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredosum_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredosum_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredosum_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredosum.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredosum_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredosum_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredosum_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredosum.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredosum_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredosum_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredsum_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredsum.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredsum_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredsum_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredsum_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfredsum.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfredsum_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredsum_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredsum_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredsum.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredsum_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredsum_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredsum_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfredsum.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfredsum_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredsum_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredsum_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredsum.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredsum_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredsum_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredsum_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfredsum.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfredsum_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredsum_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredsum_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredsum.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredsum_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredsum_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredsum_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfredsum.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfredsum_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredsum_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredsum_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredsum.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredsum_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredsum_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredsum_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfredsum.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfredsum_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredsum_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfredsum_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredsum.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredsum_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfredsum_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfredsum_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfredsum.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfredsum_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfredsum_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnj_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsgnj.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsgnj_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnj_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnj_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsgnj.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsgnj_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnj_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnj_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsgnj.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsgnj_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnj_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnj_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsgnj.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsgnj_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnj_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnj_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsgnj.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsgnj_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnj_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnj_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsgnj.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsgnj_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnj_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnj_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsgnj.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsgnj_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnj_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnj_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsgnj.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsgnj_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnj_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnj_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsgnj.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsgnj_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnj_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnj_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsgnj.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsgnj_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnj_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnj_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsgnj.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsgnj_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnj_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnj_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsgnj.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsgnj_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnj_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjn_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsgnjn.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsgnjn_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjn_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjn_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsgnjn.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsgnjn_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjn_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjn_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsgnjn.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsgnjn_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjn_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjn_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsgnjn.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsgnjn_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjn_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjn_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsgnjn.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsgnjn_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjn_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjn_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsgnjn.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsgnjn_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjn_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjn_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsgnjn.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsgnjn_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjn_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjn_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsgnjn.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsgnjn_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjn_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjn_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsgnjn.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsgnjn_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjn_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjn_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsgnjn.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsgnjn_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjn_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjn_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsgnjn.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsgnjn_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjn_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjn_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsgnjn.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsgnjn_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjn_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjx_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsgnjx.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsgnjx_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjx_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjx_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsgnjx.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsgnjx_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjx_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjx_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsgnjx.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsgnjx_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjx_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjx_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsgnjx.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsgnjx_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjx_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjx_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsgnjx.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsgnjx_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjx_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjx_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsgnjx.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsgnjx_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjx_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjx_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsgnjx.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsgnjx_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjx_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjx_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsgnjx.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsgnjx_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjx_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjx_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsgnjx.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsgnjx_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjx_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjx_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsgnjx.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsgnjx_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjx_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsgnjx_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsgnjx.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsgnjx_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsgnjx_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsgnjx_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsgnjx.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsgnjx_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsgnjx_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsqrt_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsqrt.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsqrt_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfsqrt_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfsqrt_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsqrt.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsqrt_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfsqrt_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfsqrt_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsqrt.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsqrt_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfsqrt_1xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfsqrt_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsqrt.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsqrt_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfsqrt_1xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfsqrt_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsqrt.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsqrt_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfsqrt_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfsqrt_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsqrt.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsqrt_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfsqrt_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfsqrt_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsqrt.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsqrt_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfsqrt_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfsqrt_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsqrt.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsqrt_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfsqrt_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfsqrt_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsqrt.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsqrt_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfsqrt_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfsqrt_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsqrt.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsqrt_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfsqrt_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfsqrt_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsqrt.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsqrt_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfsqrt_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfsqrt_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsqrt.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsqrt_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfsqrt_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfsub_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsub.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsub_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsub_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsub_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vfsub.mask.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vfsub_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsub_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsub_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsub.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsub_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsub_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsub_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vfsub.mask.nxv1f64.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vfsub_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsub_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsub_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsub.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsub_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsub_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsub_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfsub.mask.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfsub_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsub_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsub_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsub.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsub_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsub_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsub_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfsub.mask.nxv2f64.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfsub_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsub_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsub_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsub.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsub_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsub_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsub_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfsub.mask.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfsub_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsub_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfsub_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsub.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsub_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfsub_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfsub_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfsub.mask.nxv4f64.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfsub_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfsub_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwadd_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwadd.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwadd_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwadd_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwadd_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwadd.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwadd_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwadd_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwadd_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwadd.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwadd_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwadd_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwadd_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwadd.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwadd_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwadd_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwadd_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwadd.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwadd_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwadd_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwadd_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwadd.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwadd_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwadd_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwadd_w_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwadd.w.nxv2f64.nxv2f32(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwadd_w_2xf64(__epi_2xf64 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwadd_w_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwadd_w_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwadd.w.mask.nxv2f64.nxv2f32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwadd_w_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwadd_w_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwadd_w_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwadd.w.nxv4f64.nxv4f32(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwadd_w_4xf64(__epi_4xf64 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwadd_w_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwadd_w_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwadd.w.mask.nxv4f64.nxv4f32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwadd_w_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwadd_w_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwadd_w_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwadd.w.nxv8f64.nxv8f32(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwadd_w_8xf64(__epi_8xf64 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwadd_w_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwadd_w_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwadd.w.mask.nxv8f64.nxv8f32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwadd_w_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf64 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwadd_w_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_f_2xf64_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwcvt.f.f.nxv2f64.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwcvt_f_f_2xf64_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_f_2xf64_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_f_2xf64_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwcvt.f.f.mask.nxv2f64.nxv2f32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwcvt_f_f_2xf64_2xf32_mask(__epi_2xf64 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_f_2xf64_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_f_4xf64_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwcvt.f.f.nxv4f64.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwcvt_f_f_4xf64_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_f_4xf64_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_f_4xf64_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwcvt.f.f.mask.nxv4f64.nxv4f32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwcvt_f_f_4xf64_4xf32_mask(__epi_4xf64 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_f_4xf64_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_f_8xf64_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwcvt.f.f.nxv8f64.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwcvt_f_f_8xf64_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_f_8xf64_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_f_8xf64_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwcvt.f.f.mask.nxv8f64.nxv8f32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwcvt_f_f_8xf64_8xf32_mask(__epi_8xf64 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_f_8xf64_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_4xf32_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfwcvt.f.x.nxv4f32.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfwcvt_f_x_4xf32_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_x_4xf32_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_4xf32_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfwcvt.f.x.mask.nxv4f32.nxv4i16.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfwcvt_f_x_4xf32_4xi16_mask(__epi_4xf32 arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_x_4xf32_4xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_2xf64_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwcvt.f.x.nxv2f64.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwcvt_f_x_2xf64_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_x_2xf64_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_2xf64_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwcvt.f.x.mask.nxv2f64.nxv2i32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwcvt_f_x_2xf64_2xi32_mask(__epi_2xf64 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_x_2xf64_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_8xf32_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfwcvt.f.x.nxv8f32.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfwcvt_f_x_8xf32_8xi16(__epi_8xi16 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_x_8xf32_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_8xf32_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfwcvt.f.x.mask.nxv8f32.nxv8i16.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfwcvt_f_x_8xf32_8xi16_mask(__epi_8xf32 arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_x_8xf32_8xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_4xf64_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwcvt.f.x.nxv4f64.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwcvt_f_x_4xf64_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_x_4xf64_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_4xf64_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwcvt.f.x.mask.nxv4f64.nxv4i32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwcvt_f_x_4xf64_4xi32_mask(__epi_4xf64 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_x_4xf64_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_16xf32_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x float> @llvm.epi.vfwcvt.f.x.nxv16f32.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x float> [[TMP0]]
//
__epi_16xf32 test_vfwcvt_f_x_16xf32_16xi16(__epi_16xi16 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_x_16xf32_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_16xf32_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x float> @llvm.epi.vfwcvt.f.x.mask.nxv16f32.nxv16i16.nxv16i1(<vscale x 16 x float> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x float> [[TMP0]]
//
__epi_16xf32 test_vfwcvt_f_x_16xf32_16xi16_mask(__epi_16xf32 arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_x_16xf32_16xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_8xf64_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwcvt.f.x.nxv8f64.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwcvt_f_x_8xf64_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_x_8xf64_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_x_8xf64_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwcvt.f.x.mask.nxv8f64.nxv8i32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwcvt_f_x_8xf64_8xi32_mask(__epi_8xf64 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_x_8xf64_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_4xf32_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfwcvt.f.xu.nxv4f32.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfwcvt_f_xu_4xf32_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_xu_4xf32_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_4xf32_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vfwcvt.f.xu.mask.nxv4f32.nxv4i16.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vfwcvt_f_xu_4xf32_4xi16_mask(__epi_4xf32 arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_xu_4xf32_4xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_2xf64_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwcvt.f.xu.nxv2f64.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwcvt_f_xu_2xf64_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_xu_2xf64_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_2xf64_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwcvt.f.xu.mask.nxv2f64.nxv2i32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwcvt_f_xu_2xf64_2xi32_mask(__epi_2xf64 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_xu_2xf64_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_8xf32_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfwcvt.f.xu.nxv8f32.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfwcvt_f_xu_8xf32_8xi16(__epi_8xi16 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_xu_8xf32_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_8xf32_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vfwcvt.f.xu.mask.nxv8f32.nxv8i16.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vfwcvt_f_xu_8xf32_8xi16_mask(__epi_8xf32 arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_xu_8xf32_8xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_4xf64_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwcvt.f.xu.nxv4f64.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwcvt_f_xu_4xf64_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_xu_4xf64_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_4xf64_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwcvt.f.xu.mask.nxv4f64.nxv4i32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwcvt_f_xu_4xf64_4xi32_mask(__epi_4xf64 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_xu_4xf64_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_16xf32_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x float> @llvm.epi.vfwcvt.f.xu.nxv16f32.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x float> [[TMP0]]
//
__epi_16xf32 test_vfwcvt_f_xu_16xf32_16xi16(__epi_16xi16 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_xu_16xf32_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_16xf32_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x float> @llvm.epi.vfwcvt.f.xu.mask.nxv16f32.nxv16i16.nxv16i1(<vscale x 16 x float> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x float> [[TMP0]]
//
__epi_16xf32 test_vfwcvt_f_xu_16xf32_16xi16_mask(__epi_16xf32 arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_xu_16xf32_16xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_8xf64_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwcvt.f.xu.nxv8f64.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwcvt_f_xu_8xf64_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_f_xu_8xf64_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_f_xu_8xf64_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwcvt.f.xu.mask.nxv8f64.nxv8i32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwcvt_f_xu_8xf64_8xi32_mask(__epi_8xf64 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_f_xu_8xf64_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_x_f_2xi64_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfwcvt.x.f.nxv2i64.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfwcvt_x_f_2xi64_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_x_f_2xi64_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_x_f_2xi64_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfwcvt.x.f.mask.nxv2i64.nxv2f32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfwcvt_x_f_2xi64_2xf32_mask(__epi_2xi64 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_x_f_2xi64_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_x_f_4xi64_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfwcvt.x.f.nxv4i64.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfwcvt_x_f_4xi64_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_x_f_4xi64_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_x_f_4xi64_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfwcvt.x.f.mask.nxv4i64.nxv4f32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfwcvt_x_f_4xi64_4xf32_mask(__epi_4xi64 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_x_f_4xi64_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_x_f_8xi64_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vfwcvt.x.f.nxv8i64.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vfwcvt_x_f_8xi64_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_x_f_8xi64_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_x_f_8xi64_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vfwcvt.x.f.mask.nxv8i64.nxv8f32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vfwcvt_x_f_8xi64_8xf32_mask(__epi_8xi64 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_x_f_8xi64_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_xu_f_2xi64_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfwcvt.xu.f.nxv2i64.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfwcvt_xu_f_2xi64_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_xu_f_2xi64_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_xu_f_2xi64_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vfwcvt.xu.f.mask.nxv2i64.nxv2f32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vfwcvt_xu_f_2xi64_2xf32_mask(__epi_2xi64 arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_xu_f_2xi64_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_xu_f_4xi64_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfwcvt.xu.f.nxv4i64.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfwcvt_xu_f_4xi64_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_xu_f_4xi64_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_xu_f_4xi64_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vfwcvt.xu.f.mask.nxv4i64.nxv4f32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vfwcvt_xu_f_4xi64_4xf32_mask(__epi_4xi64 arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_xu_f_4xi64_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwcvt_xu_f_8xi64_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vfwcvt.xu.f.nxv8i64.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vfwcvt_xu_f_8xi64_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vfwcvt_xu_f_8xi64_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vfwcvt_xu_f_8xi64_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vfwcvt.xu.f.mask.nxv8i64.nxv8f32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vfwcvt_xu_f_8xi64_8xf32_mask(__epi_8xi64 arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwcvt_xu_f_8xi64_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmacc_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwmacc.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwmacc_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwmacc_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmacc_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwmacc.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwmacc_2xf64_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmacc_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmacc_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwmacc.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwmacc_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwmacc_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmacc_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwmacc.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwmacc_4xf64_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmacc_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmacc_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwmacc.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwmacc_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwmacc_8xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmacc_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwmacc.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwmacc_8xf64_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmacc_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmsac_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwmsac.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwmsac_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwmsac_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmsac_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwmsac.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwmsac_2xf64_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmsac_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmsac_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwmsac.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwmsac_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwmsac_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmsac_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwmsac.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwmsac_4xf64_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmsac_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmsac_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwmsac.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwmsac_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwmsac_8xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwmsac_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwmsac.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwmsac_8xf64_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmsac_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmul_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwmul.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwmul_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwmul_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwmul_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwmul.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwmul_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmul_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmul_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwmul.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwmul_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwmul_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwmul_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwmul.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwmul_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmul_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwmul_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwmul.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwmul_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwmul_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwmul_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwmul.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwmul_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwmul_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwnmacc_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwnmacc.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwnmacc_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwnmacc_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwnmacc_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwnmacc.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwnmacc_2xf64_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwnmacc_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwnmacc_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwnmacc.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwnmacc_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwnmacc_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwnmacc_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwnmacc.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwnmacc_4xf64_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwnmacc_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwnmacc_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwnmacc.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwnmacc_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwnmacc_8xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwnmacc_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwnmacc.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwnmacc_8xf64_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwnmacc_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwnmsac_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwnmsac.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwnmsac_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwnmsac_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwnmsac_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwnmsac.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwnmsac_2xf64_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwnmsac_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwnmsac_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwnmsac.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwnmsac_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwnmsac_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwnmsac_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwnmsac.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwnmsac_4xf64_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwnmsac_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwnmsac_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwnmsac.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwnmsac_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vfwnmsac_8xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vfwnmsac_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwnmsac.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwnmsac_8xf64_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwnmsac_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwredosum_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwredosum.nxv2f64.nxv2f32.nxv2f64(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwredosum_2xf64(__epi_2xf32 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwredosum_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwredosum_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwredosum.mask.nxv2f64.nxv2f32.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwredosum_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwredosum_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwredosum_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwredosum.nxv4f64.nxv4f32.nxv4f64(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwredosum_4xf64(__epi_4xf32 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwredosum_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwredosum_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwredosum.mask.nxv4f64.nxv4f32.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwredosum_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwredosum_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwredosum_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwredosum.nxv8f64.nxv8f32.nxv8f64(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwredosum_8xf64(__epi_8xf32 arg_0, __epi_8xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwredosum_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwredosum_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwredosum.mask.nxv8f64.nxv8f32.nxv8f64.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwredosum_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwredosum_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwredsum_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwredsum.nxv2f64.nxv2f32.nxv2f64(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwredsum_2xf64(__epi_2xf32 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwredsum_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwredsum_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwredsum.mask.nxv2f64.nxv2f32.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwredsum_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf32 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwredsum_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwredsum_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwredsum.nxv4f64.nxv4f32.nxv4f64(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwredsum_4xf64(__epi_4xf32 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwredsum_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwredsum_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwredsum.mask.nxv4f64.nxv4f32.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwredsum_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf32 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwredsum_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwredsum_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwredsum.nxv8f64.nxv8f32.nxv8f64(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwredsum_8xf64(__epi_8xf32 arg_0, __epi_8xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwredsum_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwredsum_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwredsum.mask.nxv8f64.nxv8f32.nxv8f64.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x double> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwredsum_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf32 arg_1, __epi_8xf64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwredsum_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwsub_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwsub.nxv2f64.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwsub_2xf64(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwsub_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwsub_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwsub.mask.nxv2f64.nxv2f32.nxv2f32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwsub_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwsub_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwsub_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwsub.nxv4f64.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwsub_4xf64(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwsub_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwsub_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwsub.mask.nxv4f64.nxv4f32.nxv4f32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwsub_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwsub_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwsub_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwsub.nxv8f64.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwsub_8xf64(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwsub_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwsub_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwsub.mask.nxv8f64.nxv8f32.nxv8f32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwsub_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwsub_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwsub_w_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwsub.w.nxv2f64.nxv2f32(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwsub_w_2xf64(__epi_2xf64 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwsub_w_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwsub_w_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vfwsub.w.mask.nxv2f64.nxv2f32.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vfwsub_w_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwsub_w_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwsub_w_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwsub.w.nxv4f64.nxv4f32(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwsub_w_4xf64(__epi_4xf64 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwsub_w_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwsub_w_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vfwsub.w.mask.nxv4f64.nxv4f32.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vfwsub_w_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwsub_w_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vfwsub_w_8xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwsub.w.nxv8f64.nxv8f32(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwsub_w_8xf64(__epi_8xf64 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vfwsub_w_8xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vfwsub_w_8xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x double> @llvm.epi.vfwsub.w.mask.nxv8f64.nxv8f32.nxv8i1(<vscale x 8 x double> [[ARG_0:%.*]], <vscale x 8 x double> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
__epi_8xf64 test_vfwsub_w_8xf64_mask(__epi_8xf64 arg_0, __epi_8xf64 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vfwsub_w_8xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vid_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vid.nxv8i8(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vid_8xi8(unsigned long int arg_0)
{
    return __builtin_epi_vid_8xi8(arg_0);
}

// CHECK-O2-LABEL: @test_vid_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vid.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vid_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vid_8xi8_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vid_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vid.nxv4i16(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vid_4xi16(unsigned long int arg_0)
{
    return __builtin_epi_vid_4xi16(arg_0);
}

// CHECK-O2-LABEL: @test_vid_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vid.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vid_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vid_4xi16_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vid_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vid.nxv2i32(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vid_2xi32(unsigned long int arg_0)
{
    return __builtin_epi_vid_2xi32(arg_0);
}

// CHECK-O2-LABEL: @test_vid_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vid.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vid_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vid_2xi32_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vid_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vid.nxv1i64(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vid_1xi64(unsigned long int arg_0)
{
    return __builtin_epi_vid_1xi64(arg_0);
}

// CHECK-O2-LABEL: @test_vid_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vid.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vid_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vid_1xi64_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vid_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vid.nxv16i8(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vid_16xi8(unsigned long int arg_0)
{
    return __builtin_epi_vid_16xi8(arg_0);
}

// CHECK-O2-LABEL: @test_vid_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vid.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vid_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vid_16xi8_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vid_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vid.nxv8i16(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vid_8xi16(unsigned long int arg_0)
{
    return __builtin_epi_vid_8xi16(arg_0);
}

// CHECK-O2-LABEL: @test_vid_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vid.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vid_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vid_8xi16_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vid_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vid.nxv4i32(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vid_4xi32(unsigned long int arg_0)
{
    return __builtin_epi_vid_4xi32(arg_0);
}

// CHECK-O2-LABEL: @test_vid_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vid.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vid_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vid_4xi32_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vid_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vid.nxv2i64(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vid_2xi64(unsigned long int arg_0)
{
    return __builtin_epi_vid_2xi64(arg_0);
}

// CHECK-O2-LABEL: @test_vid_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vid.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vid_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vid_2xi64_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vid_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vid.nxv32i8(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vid_32xi8(unsigned long int arg_0)
{
    return __builtin_epi_vid_32xi8(arg_0);
}

// CHECK-O2-LABEL: @test_vid_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vid.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vid_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vid_32xi8_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vid_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vid.nxv16i16(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vid_16xi16(unsigned long int arg_0)
{
    return __builtin_epi_vid_16xi16(arg_0);
}

// CHECK-O2-LABEL: @test_vid_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vid.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vid_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vid_16xi16_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vid_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vid.nxv8i32(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vid_8xi32(unsigned long int arg_0)
{
    return __builtin_epi_vid_8xi32(arg_0);
}

// CHECK-O2-LABEL: @test_vid_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vid.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vid_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vid_8xi32_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vid_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vid.nxv4i64(i64 [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vid_4xi64(unsigned long int arg_0)
{
    return __builtin_epi_vid_4xi64(arg_0);
}

// CHECK-O2-LABEL: @test_vid_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vid.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vid_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vid_4xi64_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_viota_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.viota.nxv8i8.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_viota_8xi8(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_8xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.viota.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_viota_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi1 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_viota_8xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_viota_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.viota.nxv4i16.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_viota_4xi16(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.viota.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_viota_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi1 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_viota_4xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_viota_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.viota.nxv2i32.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_viota_2xi32(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.viota.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_viota_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi1 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_viota_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_viota_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.viota.nxv1i64.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_viota_1xi64(__epi_1xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.viota.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_viota_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi1 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_viota_1xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_viota_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.viota.nxv16i8.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_viota_16xi8(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_16xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.viota.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_viota_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi1 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_viota_16xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_viota_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.viota.nxv8i16.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_viota_8xi16(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.viota.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_viota_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi1 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_viota_8xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_viota_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.viota.nxv4i32.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_viota_4xi32(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.viota.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_viota_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi1 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_viota_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_viota_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.viota.nxv2i64.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_viota_2xi64(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.viota.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_viota_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi1 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_viota_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_viota_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.viota.nxv32i8.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_viota_32xi8(__epi_32xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_32xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.viota.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_viota_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi1 arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_viota_32xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_viota_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.viota.nxv16i16.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_viota_16xi16(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.viota.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_viota_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi1 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_viota_16xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_viota_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.viota.nxv8i32.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_viota_8xi32(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.viota.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_viota_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi1 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_viota_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_viota_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.viota.nxv4i64.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_viota_4xi64(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_viota_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_viota_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.viota.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_viota_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi1 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_viota_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nxv8i8(<vscale x 8 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_8xi8(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_8xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_8xi8_mask(__epi_8xi8 arg_0, const signed char*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_8xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nxv4i16(<vscale x 4 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_4xi16(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_4xi16_mask(__epi_4xi16 arg_0, const signed short int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_4xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nxv2i32(<vscale x 2 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_2xi32(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_2xi32_mask(__epi_2xi32 arg_0, const signed int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nxv1i64(<vscale x 1 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_1xi64(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_1xi64_mask(__epi_1xi64 arg_0, const signed long int*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_1xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.nxv2f32(<vscale x 2 x float>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_2xf32(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_2xf32_mask(__epi_2xf32 arg_0, const float*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nxv1f64(<vscale x 1 x double>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_1xf64(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_1xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double>* [[TMP0]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_1xf64_mask(__epi_1xf64 arg_0, const double*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_1xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nxv16i8(<vscale x 16 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_16xi8(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_16xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_16xi8_mask(__epi_16xi8 arg_0, const signed char*  arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_16xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nxv8i16(<vscale x 8 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_8xi16(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_8xi16_mask(__epi_8xi16 arg_0, const signed short int*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_8xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nxv4i32(<vscale x 4 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_4xi32(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_4xi32_mask(__epi_4xi32 arg_0, const signed int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nxv2i64(<vscale x 2 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_2xi64(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_2xi64_mask(__epi_2xi64 arg_0, const signed long int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.nxv4f32(<vscale x 4 x float>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_4xf32(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.mask.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_4xf32_mask(__epi_4xf32 arg_0, const float*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.nxv2f64(<vscale x 2 x double>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_2xf64(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.mask.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_2xf64_mask(__epi_2xf64 arg_0, const double*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nxv32i8(<vscale x 32 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_32xi8(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_32xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_32xi8_mask(__epi_32xi8 arg_0, const signed char*  arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_32xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nxv16i16(<vscale x 16 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_16xi16(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_16xi16_mask(__epi_16xi16 arg_0, const signed short int*  arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_16xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nxv8i32(<vscale x 8 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_8xi32(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_8xi32_mask(__epi_8xi32 arg_0, const signed int*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nxv4i64(<vscale x 4 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_4xi64(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_4xi64_mask(__epi_4xi64 arg_0, const signed long int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.nxv8f32(<vscale x 8 x float>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_8xf32(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.mask.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_8xf32_mask(__epi_8xf32 arg_0, const float*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.nxv4f64(<vscale x 4 x double>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_4xf64(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.mask.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_4xf64_mask(__epi_4xf64 arg_0, const double*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_indexed_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_indexed_8xi8(const signed char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_indexed_8xi8_mask(__epi_8xi8 arg_0, const signed char*  arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_indexed_4xi16(const signed short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_indexed_4xi16_mask(__epi_4xi16 arg_0, const signed short int*  arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_indexed_2xi32(const signed int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_indexed_2xi32_mask(__epi_2xi32 arg_0, const signed int*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_indexed_1xi64(const signed long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_indexed_1xi64_mask(__epi_1xi64 arg_0, const signed long int*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.indexed.nxv2f32.nxv2i32(<vscale x 2 x float>* [[TMP0]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_indexed_2xf32(const float*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_indexed_2xf32_mask(__epi_2xf32 arg_0, const float*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.indexed.nxv1f64.nxv1i64(<vscale x 1 x double>* [[TMP0]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_indexed_1xf64(const double*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_indexed_1xf64_mask(__epi_1xf64 arg_0, const double*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.indexed.nxv16i8.nxv16i8(<vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_indexed_16xi8(const signed char*  arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.indexed.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_indexed_16xi8_mask(__epi_16xi8 arg_0, const signed char*  arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.indexed.nxv8i16.nxv8i16(<vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_indexed_8xi16(const signed short int*  arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.indexed.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_indexed_8xi16_mask(__epi_8xi16 arg_0, const signed short int*  arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.indexed.nxv4i32.nxv4i32(<vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_indexed_4xi32(const signed int*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.indexed.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_indexed_4xi32_mask(__epi_4xi32 arg_0, const signed int*  arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.indexed.nxv2i64.nxv2i64(<vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_indexed_2xi64(const signed long int*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.indexed.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_indexed_2xi64_mask(__epi_2xi64 arg_0, const signed long int*  arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.indexed.nxv4f32.nxv4i32(<vscale x 4 x float>* [[TMP0]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_indexed_4xf32(const float*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.indexed.mask.nxv4f32.nxv4i32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_indexed_4xf32_mask(__epi_4xf32 arg_0, const float*  arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.indexed.nxv2f64.nxv2i64(<vscale x 2 x double>* [[TMP0]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_indexed_2xf64(const double*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.indexed.mask.nxv2f64.nxv2i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_indexed_2xf64_mask(__epi_2xf64 arg_0, const double*  arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.indexed.nxv32i8.nxv32i8(<vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_indexed_32xi8(const signed char*  arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.indexed.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_indexed_32xi8_mask(__epi_32xi8 arg_0, const signed char*  arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.indexed.nxv16i16.nxv16i16(<vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_indexed_16xi16(const signed short int*  arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.indexed.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_indexed_16xi16_mask(__epi_16xi16 arg_0, const signed short int*  arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.indexed.nxv8i32.nxv8i32(<vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_indexed_8xi32(const signed int*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.indexed.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_indexed_8xi32_mask(__epi_8xi32 arg_0, const signed int*  arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.indexed.nxv4i64.nxv4i64(<vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_indexed_4xi64(const signed long int*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.indexed.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_indexed_4xi64_mask(__epi_4xi64 arg_0, const signed long int*  arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.indexed.nxv8f32.nxv8i32(<vscale x 8 x float>* [[TMP0]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_indexed_8xf32(const float*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.indexed.mask.nxv8f32.nxv8i32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_indexed_8xf32_mask(__epi_8xf32 arg_0, const float*  arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.indexed.nxv4f64.nxv4i64(<vscale x 4 x double>* [[TMP0]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_indexed_4xf64(const double*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.indexed.mask.nxv4f64.nxv4i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_indexed_4xf64_mask(__epi_4xf64 arg_0, const double*  arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_indexed_unsigned_8xi8(const unsigned char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_indexed_unsigned_8xi8_mask(__epi_8xi8 arg_0, const unsigned char*  arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_unsigned_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_indexed_unsigned_4xi16(const unsigned short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_indexed_unsigned_4xi16_mask(__epi_4xi16 arg_0, const unsigned short int*  arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_unsigned_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_indexed_unsigned_2xi32(const unsigned int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_indexed_unsigned_2xi32_mask(__epi_2xi32 arg_0, const unsigned int*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_unsigned_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_indexed_unsigned_1xi64(const unsigned long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_indexed_unsigned_1xi64_mask(__epi_1xi64 arg_0, const unsigned long int*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_unsigned_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.indexed.nxv16i8.nxv16i8(<vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_indexed_unsigned_16xi8(const unsigned char*  arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.indexed.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_indexed_unsigned_16xi8_mask(__epi_16xi8 arg_0, const unsigned char*  arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_unsigned_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.indexed.nxv8i16.nxv8i16(<vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_indexed_unsigned_8xi16(const unsigned short int*  arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.indexed.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_indexed_unsigned_8xi16_mask(__epi_8xi16 arg_0, const unsigned short int*  arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_unsigned_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.indexed.nxv4i32.nxv4i32(<vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_indexed_unsigned_4xi32(const unsigned int*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.indexed.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_indexed_unsigned_4xi32_mask(__epi_4xi32 arg_0, const unsigned int*  arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_unsigned_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.indexed.nxv2i64.nxv2i64(<vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_indexed_unsigned_2xi64(const unsigned long int*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.indexed.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_indexed_unsigned_2xi64_mask(__epi_2xi64 arg_0, const unsigned long int*  arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_unsigned_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.indexed.nxv32i8.nxv32i8(<vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_indexed_unsigned_32xi8(const unsigned char*  arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.indexed.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_indexed_unsigned_32xi8_mask(__epi_32xi8 arg_0, const unsigned char*  arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_unsigned_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.indexed.nxv16i16.nxv16i16(<vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_indexed_unsigned_16xi16(const unsigned short int*  arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.indexed.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_indexed_unsigned_16xi16_mask(__epi_16xi16 arg_0, const unsigned short int*  arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_unsigned_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.indexed.nxv8i32.nxv8i32(<vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_indexed_unsigned_8xi32(const unsigned int*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.indexed.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_indexed_unsigned_8xi32_mask(__epi_8xi32 arg_0, const unsigned int*  arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_unsigned_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.indexed.nxv4i64.nxv4i64(<vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_indexed_unsigned_4xi64(const unsigned long int*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_indexed_unsigned_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_indexed_unsigned_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.indexed.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_indexed_unsigned_4xi64_mask(__epi_4xi64 arg_0, const unsigned long int*  arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_indexed_unsigned_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i1>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = load <vscale x 8 x i1>, <vscale x 8 x i1>* [[TMP0]], align 1
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP1]]
//
__epi_8xi1 test_vload_8xi1(const unsigned char*  arg_0)
{
    return __builtin_epi_vload_8xi1(arg_0);
}

// CHECK-O2-LABEL: @test_vload_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i1>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = load <vscale x 4 x i1>, <vscale x 4 x i1>* [[TMP0]], align 2
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP1]]
//
__epi_4xi1 test_vload_4xi1(const unsigned short int*  arg_0)
{
    return __builtin_epi_vload_4xi1(arg_0);
}

// CHECK-O2-LABEL: @test_vload_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i1>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = load <vscale x 2 x i1>, <vscale x 2 x i1>* [[TMP0]], align 4
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP1]]
//
__epi_2xi1 test_vload_2xi1(const unsigned int*  arg_0)
{
    return __builtin_epi_vload_2xi1(arg_0);
}

// CHECK-O2-LABEL: @test_vload_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i1>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = load <vscale x 1 x i1>, <vscale x 1 x i1>* [[TMP0]], align 8
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP1]]
//
__epi_1xi1 test_vload_1xi1(const unsigned long int*  arg_0)
{
    return __builtin_epi_vload_1xi1(arg_0);
}

// CHECK-O2-LABEL: @test_vload_nt_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nt.nxv8i8(<vscale x 8 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_nt_8xi8(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_8xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nt.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_nt_8xi8_mask(__epi_8xi8 arg_0, const signed char*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_8xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nt.nxv4i16(<vscale x 4 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_nt_4xi16(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nt.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_nt_4xi16_mask(__epi_4xi16 arg_0, const signed short int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_4xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nt.nxv2i32(<vscale x 2 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_nt_2xi32(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nt.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_nt_2xi32_mask(__epi_2xi32 arg_0, const signed int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nt.nxv1i64(<vscale x 1 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_nt_1xi64(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nt.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_nt_1xi64_mask(__epi_1xi64 arg_0, const signed long int*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_1xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.nt.nxv2f32(<vscale x 2 x float>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_nt_2xf32(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_2xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.nt.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_nt_2xf32_mask(__epi_2xf32 arg_0, const float*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nt.nxv1f64(<vscale x 1 x double>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_nt_1xf64(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_1xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nt.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double>* [[TMP0]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_nt_1xf64_mask(__epi_1xf64 arg_0, const double*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_1xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nt.nxv16i8(<vscale x 16 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_nt_16xi8(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_16xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nt.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_nt_16xi8_mask(__epi_16xi8 arg_0, const signed char*  arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_16xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nt.nxv8i16(<vscale x 8 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_nt_8xi16(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nt.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_nt_8xi16_mask(__epi_8xi16 arg_0, const signed short int*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_8xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nt.nxv4i32(<vscale x 4 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_nt_4xi32(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nt.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_nt_4xi32_mask(__epi_4xi32 arg_0, const signed int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nt.nxv2i64(<vscale x 2 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_nt_2xi64(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nt.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_nt_2xi64_mask(__epi_2xi64 arg_0, const signed long int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.nt.nxv4f32(<vscale x 4 x float>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_nt_4xf32(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_4xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.nt.mask.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_nt_4xf32_mask(__epi_4xf32 arg_0, const float*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.nt.nxv2f64(<vscale x 2 x double>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_nt_2xf64(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_2xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.nt.mask.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_nt_2xf64_mask(__epi_2xf64 arg_0, const double*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nt.nxv32i8(<vscale x 32 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_nt_32xi8(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_32xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nt.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_nt_32xi8_mask(__epi_32xi8 arg_0, const signed char*  arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_32xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nt.nxv16i16(<vscale x 16 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_nt_16xi16(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nt.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_nt_16xi16_mask(__epi_16xi16 arg_0, const signed short int*  arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_16xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nt.nxv8i32(<vscale x 8 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_nt_8xi32(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nt.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_nt_8xi32_mask(__epi_8xi32 arg_0, const signed int*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nt.nxv4i64(<vscale x 4 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_nt_4xi64(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nt.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_nt_4xi64_mask(__epi_4xi64 arg_0, const signed long int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.nt.nxv8f32(<vscale x 8 x float>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_nt_8xf32(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_8xf32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.nt.mask.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_nt_8xf32_mask(__epi_8xf32 arg_0, const float*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.nt.nxv4f64(<vscale x 4 x double>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_nt_4xf64(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_4xf64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.nt.mask.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_nt_4xf64_mask(__epi_4xf64 arg_0, const double*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nt.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_nt_indexed_8xi8(const signed char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nt.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_nt_indexed_8xi8_mask(__epi_8xi8 arg_0, const signed char*  arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nt.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_nt_indexed_4xi16(const signed short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nt.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_nt_indexed_4xi16_mask(__epi_4xi16 arg_0, const signed short int*  arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nt.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_nt_indexed_2xi32(const signed int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nt.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_nt_indexed_2xi32_mask(__epi_2xi32 arg_0, const signed int*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nt.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_nt_indexed_1xi64(const signed long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nt.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_nt_indexed_1xi64_mask(__epi_1xi64 arg_0, const signed long int*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.nt.indexed.nxv2f32.nxv2i32(<vscale x 2 x float>* [[TMP0]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_nt_indexed_2xf32(const float*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.nt.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_nt_indexed_2xf32_mask(__epi_2xf32 arg_0, const float*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nt.indexed.nxv1f64.nxv1i64(<vscale x 1 x double>* [[TMP0]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_nt_indexed_1xf64(const double*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nt.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_nt_indexed_1xf64_mask(__epi_1xf64 arg_0, const double*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nt.indexed.nxv16i8.nxv16i8(<vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_nt_indexed_16xi8(const signed char*  arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nt.indexed.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_nt_indexed_16xi8_mask(__epi_16xi8 arg_0, const signed char*  arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nt.indexed.nxv8i16.nxv8i16(<vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_nt_indexed_8xi16(const signed short int*  arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nt.indexed.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_nt_indexed_8xi16_mask(__epi_8xi16 arg_0, const signed short int*  arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nt.indexed.nxv4i32.nxv4i32(<vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_nt_indexed_4xi32(const signed int*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nt.indexed.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_nt_indexed_4xi32_mask(__epi_4xi32 arg_0, const signed int*  arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nt.indexed.nxv2i64.nxv2i64(<vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_nt_indexed_2xi64(const signed long int*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nt.indexed.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_nt_indexed_2xi64_mask(__epi_2xi64 arg_0, const signed long int*  arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.nt.indexed.nxv4f32.nxv4i32(<vscale x 4 x float>* [[TMP0]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_nt_indexed_4xf32(const float*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.nt.indexed.mask.nxv4f32.nxv4i32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_nt_indexed_4xf32_mask(__epi_4xf32 arg_0, const float*  arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.nt.indexed.nxv2f64.nxv2i64(<vscale x 2 x double>* [[TMP0]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_nt_indexed_2xf64(const double*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.nt.indexed.mask.nxv2f64.nxv2i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_nt_indexed_2xf64_mask(__epi_2xf64 arg_0, const double*  arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nt.indexed.nxv32i8.nxv32i8(<vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_nt_indexed_32xi8(const signed char*  arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nt.indexed.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_nt_indexed_32xi8_mask(__epi_32xi8 arg_0, const signed char*  arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nt.indexed.nxv16i16.nxv16i16(<vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_nt_indexed_16xi16(const signed short int*  arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nt.indexed.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_nt_indexed_16xi16_mask(__epi_16xi16 arg_0, const signed short int*  arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nt.indexed.nxv8i32.nxv8i32(<vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_nt_indexed_8xi32(const signed int*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nt.indexed.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_nt_indexed_8xi32_mask(__epi_8xi32 arg_0, const signed int*  arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nt.indexed.nxv4i64.nxv4i64(<vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_nt_indexed_4xi64(const signed long int*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nt.indexed.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_nt_indexed_4xi64_mask(__epi_4xi64 arg_0, const signed long int*  arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.nt.indexed.nxv8f32.nxv8i32(<vscale x 8 x float>* [[TMP0]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_nt_indexed_8xf32(const float*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.nt.indexed.mask.nxv8f32.nxv8i32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_nt_indexed_8xf32_mask(__epi_8xf32 arg_0, const float*  arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.nt.indexed.nxv4f64.nxv4i64(<vscale x 4 x double>* [[TMP0]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_nt_indexed_4xf64(const double*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.nt.indexed.mask.nxv4f64.nxv4i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_nt_indexed_4xf64_mask(__epi_4xf64 arg_0, const double*  arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nt.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_nt_indexed_unsigned_8xi8(const unsigned char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_unsigned_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nt.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_nt_indexed_unsigned_8xi8_mask(__epi_8xi8 arg_0, const unsigned char*  arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_unsigned_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nt.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_nt_indexed_unsigned_4xi16(const unsigned short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_unsigned_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nt.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_nt_indexed_unsigned_4xi16_mask(__epi_4xi16 arg_0, const unsigned short int*  arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_unsigned_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nt.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_nt_indexed_unsigned_2xi32(const unsigned int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_unsigned_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nt.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_nt_indexed_unsigned_2xi32_mask(__epi_2xi32 arg_0, const unsigned int*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_unsigned_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nt.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_nt_indexed_unsigned_1xi64(const unsigned long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_unsigned_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nt.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_nt_indexed_unsigned_1xi64_mask(__epi_1xi64 arg_0, const unsigned long int*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_unsigned_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nt.indexed.nxv16i8.nxv16i8(<vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_nt_indexed_unsigned_16xi8(const unsigned char*  arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_unsigned_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nt.indexed.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_nt_indexed_unsigned_16xi8_mask(__epi_16xi8 arg_0, const unsigned char*  arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_unsigned_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nt.indexed.nxv8i16.nxv8i16(<vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_nt_indexed_unsigned_8xi16(const unsigned short int*  arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_unsigned_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nt.indexed.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_nt_indexed_unsigned_8xi16_mask(__epi_8xi16 arg_0, const unsigned short int*  arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_unsigned_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nt.indexed.nxv4i32.nxv4i32(<vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_nt_indexed_unsigned_4xi32(const unsigned int*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_unsigned_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nt.indexed.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_nt_indexed_unsigned_4xi32_mask(__epi_4xi32 arg_0, const unsigned int*  arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_unsigned_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nt.indexed.nxv2i64.nxv2i64(<vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_nt_indexed_unsigned_2xi64(const unsigned long int*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_unsigned_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nt.indexed.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_nt_indexed_unsigned_2xi64_mask(__epi_2xi64 arg_0, const unsigned long int*  arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_unsigned_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nt.indexed.nxv32i8.nxv32i8(<vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_nt_indexed_unsigned_32xi8(const unsigned char*  arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_unsigned_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nt.indexed.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_nt_indexed_unsigned_32xi8_mask(__epi_32xi8 arg_0, const unsigned char*  arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_unsigned_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nt.indexed.nxv16i16.nxv16i16(<vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_nt_indexed_unsigned_16xi16(const unsigned short int*  arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_unsigned_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nt.indexed.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_nt_indexed_unsigned_16xi16_mask(__epi_16xi16 arg_0, const unsigned short int*  arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_unsigned_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nt.indexed.nxv8i32.nxv8i32(<vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_nt_indexed_unsigned_8xi32(const unsigned int*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_unsigned_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nt.indexed.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_nt_indexed_unsigned_8xi32_mask(__epi_8xi32 arg_0, const unsigned int*  arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_unsigned_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nt.indexed.nxv4i64.nxv4i64(<vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_nt_indexed_unsigned_4xi64(const unsigned long int*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_indexed_unsigned_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_indexed_unsigned_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nt.indexed.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_nt_indexed_unsigned_4xi64_mask(__epi_4xi64 arg_0, const unsigned long int*  arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_indexed_unsigned_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nt.strided.nxv8i8(<vscale x 8 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_nt_strided_8xi8(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nt.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_nt_strided_8xi8_mask(__epi_8xi8 arg_0, const signed char*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nt.strided.nxv4i16(<vscale x 4 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_nt_strided_4xi16(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nt.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_nt_strided_4xi16_mask(__epi_4xi16 arg_0, const signed short int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nt.strided.nxv2i32(<vscale x 2 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_nt_strided_2xi32(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nt.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_nt_strided_2xi32_mask(__epi_2xi32 arg_0, const signed int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nt.strided.nxv1i64(<vscale x 1 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_nt_strided_1xi64(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nt.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_nt_strided_1xi64_mask(__epi_1xi64 arg_0, const signed long int*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.nt.strided.nxv2f32(<vscale x 2 x float>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_nt_strided_2xf32(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.nt.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_nt_strided_2xf32_mask(__epi_2xf32 arg_0, const float*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nt.strided.nxv1f64(<vscale x 1 x double>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_nt_strided_1xf64(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.nt.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_nt_strided_1xf64_mask(__epi_1xf64 arg_0, const double*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nt.strided.nxv16i8(<vscale x 16 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_nt_strided_16xi8(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nt.strided.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_nt_strided_16xi8_mask(__epi_16xi8 arg_0, const signed char*  arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nt.strided.nxv8i16(<vscale x 8 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_nt_strided_8xi16(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nt.strided.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_nt_strided_8xi16_mask(__epi_8xi16 arg_0, const signed short int*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nt.strided.nxv4i32(<vscale x 4 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_nt_strided_4xi32(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nt.strided.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_nt_strided_4xi32_mask(__epi_4xi32 arg_0, const signed int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nt.strided.nxv2i64(<vscale x 2 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_nt_strided_2xi64(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nt.strided.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_nt_strided_2xi64_mask(__epi_2xi64 arg_0, const signed long int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.nt.strided.nxv4f32(<vscale x 4 x float>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_nt_strided_4xf32(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.nt.strided.mask.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_nt_strided_4xf32_mask(__epi_4xf32 arg_0, const float*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.nt.strided.nxv2f64(<vscale x 2 x double>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_nt_strided_2xf64(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.nt.strided.mask.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_nt_strided_2xf64_mask(__epi_2xf64 arg_0, const double*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nt.strided.nxv32i8(<vscale x 32 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_nt_strided_32xi8(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nt.strided.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_nt_strided_32xi8_mask(__epi_32xi8 arg_0, const signed char*  arg_1, signed long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nt.strided.nxv16i16(<vscale x 16 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_nt_strided_16xi16(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nt.strided.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_nt_strided_16xi16_mask(__epi_16xi16 arg_0, const signed short int*  arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nt.strided.nxv8i32(<vscale x 8 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_nt_strided_8xi32(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nt.strided.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_nt_strided_8xi32_mask(__epi_8xi32 arg_0, const signed int*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nt.strided.nxv4i64(<vscale x 4 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_nt_strided_4xi64(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nt.strided.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_nt_strided_4xi64_mask(__epi_4xi64 arg_0, const signed long int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.nt.strided.nxv8f32(<vscale x 8 x float>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_nt_strided_8xf32(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.nt.strided.mask.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_nt_strided_8xf32_mask(__epi_8xf32 arg_0, const float*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.nt.strided.nxv4f64(<vscale x 4 x double>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_nt_strided_4xf64(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.nt.strided.mask.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_nt_strided_4xf64_mask(__epi_4xf64 arg_0, const double*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nt.strided.nxv8i8(<vscale x 8 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_nt_strided_unsigned_8xi8(const unsigned char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_unsigned_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nt.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_nt_strided_unsigned_8xi8_mask(__epi_8xi8 arg_0, const unsigned char*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_unsigned_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nt.strided.nxv4i16(<vscale x 4 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_nt_strided_unsigned_4xi16(const unsigned short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_unsigned_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nt.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_nt_strided_unsigned_4xi16_mask(__epi_4xi16 arg_0, const unsigned short int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_unsigned_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nt.strided.nxv2i32(<vscale x 2 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_nt_strided_unsigned_2xi32(const unsigned int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_unsigned_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nt.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_nt_strided_unsigned_2xi32_mask(__epi_2xi32 arg_0, const unsigned int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_unsigned_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nt.strided.nxv1i64(<vscale x 1 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_nt_strided_unsigned_1xi64(const unsigned long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_unsigned_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nt.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_nt_strided_unsigned_1xi64_mask(__epi_1xi64 arg_0, const unsigned long int*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_unsigned_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nt.strided.nxv16i8(<vscale x 16 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_nt_strided_unsigned_16xi8(const unsigned char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_unsigned_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nt.strided.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_nt_strided_unsigned_16xi8_mask(__epi_16xi8 arg_0, const unsigned char*  arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_unsigned_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nt.strided.nxv8i16(<vscale x 8 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_nt_strided_unsigned_8xi16(const unsigned short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_unsigned_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nt.strided.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_nt_strided_unsigned_8xi16_mask(__epi_8xi16 arg_0, const unsigned short int*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_unsigned_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nt.strided.nxv4i32(<vscale x 4 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_nt_strided_unsigned_4xi32(const unsigned int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_unsigned_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nt.strided.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_nt_strided_unsigned_4xi32_mask(__epi_4xi32 arg_0, const unsigned int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_unsigned_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nt.strided.nxv2i64(<vscale x 2 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_nt_strided_unsigned_2xi64(const unsigned long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_unsigned_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nt.strided.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_nt_strided_unsigned_2xi64_mask(__epi_2xi64 arg_0, const unsigned long int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_unsigned_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nt.strided.nxv32i8(<vscale x 32 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_nt_strided_unsigned_32xi8(const unsigned char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_unsigned_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nt.strided.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_nt_strided_unsigned_32xi8_mask(__epi_32xi8 arg_0, const unsigned char*  arg_1, signed long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_unsigned_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nt.strided.nxv16i16(<vscale x 16 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_nt_strided_unsigned_16xi16(const unsigned short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_unsigned_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nt.strided.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_nt_strided_unsigned_16xi16_mask(__epi_16xi16 arg_0, const unsigned short int*  arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_unsigned_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nt.strided.nxv8i32(<vscale x 8 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_nt_strided_unsigned_8xi32(const unsigned int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_unsigned_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nt.strided.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_nt_strided_unsigned_8xi32_mask(__epi_8xi32 arg_0, const unsigned int*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_unsigned_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nt.strided.nxv4i64(<vscale x 4 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_nt_strided_unsigned_4xi64(const unsigned long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_nt_strided_unsigned_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_nt_strided_unsigned_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nt.strided.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_nt_strided_unsigned_4xi64_mask(__epi_4xi64 arg_0, const unsigned long int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_nt_strided_unsigned_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nt.nxv8i8(<vscale x 8 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_nt_unsigned_8xi8(const unsigned char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_unsigned_8xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nt.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_nt_unsigned_8xi8_mask(__epi_8xi8 arg_0, const unsigned char*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_unsigned_8xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nt.nxv4i16(<vscale x 4 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_nt_unsigned_4xi16(const unsigned short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_unsigned_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nt.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_nt_unsigned_4xi16_mask(__epi_4xi16 arg_0, const unsigned short int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_unsigned_4xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nt.nxv2i32(<vscale x 2 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_nt_unsigned_2xi32(const unsigned int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_unsigned_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nt.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_nt_unsigned_2xi32_mask(__epi_2xi32 arg_0, const unsigned int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_unsigned_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nt.nxv1i64(<vscale x 1 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_nt_unsigned_1xi64(const unsigned long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_unsigned_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nt.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_nt_unsigned_1xi64_mask(__epi_1xi64 arg_0, const unsigned long int*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_unsigned_1xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nt.nxv16i8(<vscale x 16 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_nt_unsigned_16xi8(const unsigned char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_unsigned_16xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nt.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_nt_unsigned_16xi8_mask(__epi_16xi8 arg_0, const unsigned char*  arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_unsigned_16xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nt.nxv8i16(<vscale x 8 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_nt_unsigned_8xi16(const unsigned short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_unsigned_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nt.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_nt_unsigned_8xi16_mask(__epi_8xi16 arg_0, const unsigned short int*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_unsigned_8xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nt.nxv4i32(<vscale x 4 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_nt_unsigned_4xi32(const unsigned int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_unsigned_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nt.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_nt_unsigned_4xi32_mask(__epi_4xi32 arg_0, const unsigned int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_unsigned_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nt.nxv2i64(<vscale x 2 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_nt_unsigned_2xi64(const unsigned long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_unsigned_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nt.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_nt_unsigned_2xi64_mask(__epi_2xi64 arg_0, const unsigned long int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_unsigned_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nt.nxv32i8(<vscale x 32 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_nt_unsigned_32xi8(const unsigned char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_unsigned_32xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nt.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_nt_unsigned_32xi8_mask(__epi_32xi8 arg_0, const unsigned char*  arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_unsigned_32xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nt.nxv16i16(<vscale x 16 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_nt_unsigned_16xi16(const unsigned short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_unsigned_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nt.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_nt_unsigned_16xi16_mask(__epi_16xi16 arg_0, const unsigned short int*  arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_unsigned_16xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nt.nxv8i32(<vscale x 8 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_nt_unsigned_8xi32(const unsigned int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_unsigned_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nt.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_nt_unsigned_8xi32_mask(__epi_8xi32 arg_0, const unsigned int*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_unsigned_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nt.nxv4i64(<vscale x 4 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_nt_unsigned_4xi64(const unsigned long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_nt_unsigned_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_nt_unsigned_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nt.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_nt_unsigned_4xi64_mask(__epi_4xi64 arg_0, const unsigned long int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_nt_unsigned_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_strided_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.strided.nxv8i8(<vscale x 8 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_strided_8xi8(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_strided_8xi8_mask(__epi_8xi8 arg_0, const signed char*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.strided.nxv4i16(<vscale x 4 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_strided_4xi16(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_strided_4xi16_mask(__epi_4xi16 arg_0, const signed short int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.strided.nxv2i32(<vscale x 2 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_strided_2xi32(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_strided_2xi32_mask(__epi_2xi32 arg_0, const signed int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.strided.nxv1i64(<vscale x 1 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_strided_1xi64(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_strided_1xi64_mask(__epi_1xi64 arg_0, const signed long int*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.strided.nxv2f32(<vscale x 2 x float>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_strided_2xf32(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vload.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP1]]
//
__epi_2xf32 test_vload_strided_2xf32_mask(__epi_2xf32 arg_0, const float*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.strided.nxv1f64(<vscale x 1 x double>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_strided_1xf64(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vload.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP1]]
//
__epi_1xf64 test_vload_strided_1xf64_mask(__epi_1xf64 arg_0, const double*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.strided.nxv16i8(<vscale x 16 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_strided_16xi8(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.strided.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_strided_16xi8_mask(__epi_16xi8 arg_0, const signed char*  arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.strided.nxv8i16(<vscale x 8 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_strided_8xi16(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.strided.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_strided_8xi16_mask(__epi_8xi16 arg_0, const signed short int*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.strided.nxv4i32(<vscale x 4 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_strided_4xi32(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.strided.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_strided_4xi32_mask(__epi_4xi32 arg_0, const signed int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.strided.nxv2i64(<vscale x 2 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_strided_2xi64(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.strided.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_strided_2xi64_mask(__epi_2xi64 arg_0, const signed long int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.strided.nxv4f32(<vscale x 4 x float>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_strided_4xf32(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vload.strided.mask.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP1]]
//
__epi_4xf32 test_vload_strided_4xf32_mask(__epi_4xf32 arg_0, const float*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.strided.nxv2f64(<vscale x 2 x double>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_strided_2xf64(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vload.strided.mask.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP1]]
//
__epi_2xf64 test_vload_strided_2xf64_mask(__epi_2xf64 arg_0, const double*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.strided.nxv32i8(<vscale x 32 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_strided_32xi8(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.strided.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_strided_32xi8_mask(__epi_32xi8 arg_0, const signed char*  arg_1, signed long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.strided.nxv16i16(<vscale x 16 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_strided_16xi16(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.strided.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_strided_16xi16_mask(__epi_16xi16 arg_0, const signed short int*  arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.strided.nxv8i32(<vscale x 8 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_strided_8xi32(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.strided.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_strided_8xi32_mask(__epi_8xi32 arg_0, const signed int*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.strided.nxv4i64(<vscale x 4 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_strided_4xi64(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.strided.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_strided_4xi64_mask(__epi_4xi64 arg_0, const signed long int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.strided.nxv8f32(<vscale x 8 x float>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_strided_8xf32(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_1:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vload.strided.mask.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP1]]
//
__epi_8xf32 test_vload_strided_8xf32_mask(__epi_8xf32 arg_0, const float*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.strided.nxv4f64(<vscale x 4 x double>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_strided_4xf64(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_1:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vload.strided.mask.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP1]]
//
__epi_4xf64 test_vload_strided_4xf64_mask(__epi_4xf64 arg_0, const double*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.strided.nxv8i8(<vscale x 8 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_strided_unsigned_8xi8(const unsigned char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_strided_unsigned_8xi8_mask(__epi_8xi8 arg_0, const unsigned char*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_unsigned_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.strided.nxv4i16(<vscale x 4 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_strided_unsigned_4xi16(const unsigned short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_strided_unsigned_4xi16_mask(__epi_4xi16 arg_0, const unsigned short int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_unsigned_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.strided.nxv2i32(<vscale x 2 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_strided_unsigned_2xi32(const unsigned int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_strided_unsigned_2xi32_mask(__epi_2xi32 arg_0, const unsigned int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_unsigned_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.strided.nxv1i64(<vscale x 1 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_strided_unsigned_1xi64(const unsigned long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_strided_unsigned_1xi64_mask(__epi_1xi64 arg_0, const unsigned long int*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_unsigned_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.strided.nxv16i8(<vscale x 16 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_strided_unsigned_16xi8(const unsigned char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.strided.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_strided_unsigned_16xi8_mask(__epi_16xi8 arg_0, const unsigned char*  arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_unsigned_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.strided.nxv8i16(<vscale x 8 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_strided_unsigned_8xi16(const unsigned short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.strided.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_strided_unsigned_8xi16_mask(__epi_8xi16 arg_0, const unsigned short int*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_unsigned_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.strided.nxv4i32(<vscale x 4 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_strided_unsigned_4xi32(const unsigned int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.strided.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_strided_unsigned_4xi32_mask(__epi_4xi32 arg_0, const unsigned int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_unsigned_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.strided.nxv2i64(<vscale x 2 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_strided_unsigned_2xi64(const unsigned long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.strided.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_strided_unsigned_2xi64_mask(__epi_2xi64 arg_0, const unsigned long int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_unsigned_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.strided.nxv32i8(<vscale x 32 x i8>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_strided_unsigned_32xi8(const unsigned char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.strided.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_strided_unsigned_32xi8_mask(__epi_32xi8 arg_0, const unsigned char*  arg_1, signed long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_unsigned_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.strided.nxv16i16(<vscale x 16 x i16>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_strided_unsigned_16xi16(const unsigned short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.strided.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_strided_unsigned_16xi16_mask(__epi_16xi16 arg_0, const unsigned short int*  arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_unsigned_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.strided.nxv8i32(<vscale x 8 x i32>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_strided_unsigned_8xi32(const unsigned int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.strided.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_strided_unsigned_8xi32_mask(__epi_8xi32 arg_0, const unsigned int*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_unsigned_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.strided.nxv4i64(<vscale x 4 x i64>* [[TMP0]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_strided_unsigned_4xi64(const unsigned long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vload_strided_unsigned_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vload_strided_unsigned_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.strided.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_strided_unsigned_4xi64_mask(__epi_4xi64 arg_0, const unsigned long int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vload_strided_unsigned_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vload_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.nxv8i8(<vscale x 8 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_unsigned_8xi8(const unsigned char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_8xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vload.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP1]]
//
__epi_8xi8 test_vload_unsigned_8xi8_mask(__epi_8xi8 arg_0, const unsigned char*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_unsigned_8xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.nxv4i16(<vscale x 4 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_unsigned_4xi16(const unsigned short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vload.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP1]]
//
__epi_4xi16 test_vload_unsigned_4xi16_mask(__epi_4xi16 arg_0, const unsigned short int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_unsigned_4xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.nxv2i32(<vscale x 2 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_unsigned_2xi32(const unsigned int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vload.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP1]]
//
__epi_2xi32 test_vload_unsigned_2xi32_mask(__epi_2xi32 arg_0, const unsigned int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_unsigned_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.nxv1i64(<vscale x 1 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_unsigned_1xi64(const unsigned long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vload.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP1]]
//
__epi_1xi64 test_vload_unsigned_1xi64_mask(__epi_1xi64 arg_0, const unsigned long int*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_unsigned_1xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.nxv16i8(<vscale x 16 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_unsigned_16xi8(const unsigned char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_16xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vload.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP1]]
//
__epi_16xi8 test_vload_unsigned_16xi8_mask(__epi_16xi8 arg_0, const unsigned char*  arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_unsigned_16xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.nxv8i16(<vscale x 8 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_unsigned_8xi16(const unsigned short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vload.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP1]]
//
__epi_8xi16 test_vload_unsigned_8xi16_mask(__epi_8xi16 arg_0, const unsigned short int*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_unsigned_8xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.nxv4i32(<vscale x 4 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_unsigned_4xi32(const unsigned int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vload.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP1]]
//
__epi_4xi32 test_vload_unsigned_4xi32_mask(__epi_4xi32 arg_0, const unsigned int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_unsigned_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.nxv2i64(<vscale x 2 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_unsigned_2xi64(const unsigned long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vload.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP1]]
//
__epi_2xi64 test_vload_unsigned_2xi64_mask(__epi_2xi64 arg_0, const unsigned long int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_unsigned_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.nxv32i8(<vscale x 32 x i8>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_unsigned_32xi8(const unsigned char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_32xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_1:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vload.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP1]]
//
__epi_32xi8 test_vload_unsigned_32xi8_mask(__epi_32xi8 arg_0, const unsigned char*  arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_unsigned_32xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.nxv16i16(<vscale x 16 x i16>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_unsigned_16xi16(const unsigned short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_1:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vload.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP1]]
//
__epi_16xi16 test_vload_unsigned_16xi16_mask(__epi_16xi16 arg_0, const unsigned short int*  arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_unsigned_16xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.nxv8i32(<vscale x 8 x i32>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_unsigned_8xi32(const unsigned int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_1:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vload.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP1]]
//
__epi_8xi32 test_vload_unsigned_8xi32_mask(__epi_8xi32 arg_0, const unsigned int*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_unsigned_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vload_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.nxv4i64(<vscale x 4 x i64>* [[TMP0]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_unsigned_4xi64(const unsigned long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vload_unsigned_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vload_unsigned_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_1:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    [[TMP1:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vload.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP1]]
//
__epi_4xi64 test_vload_unsigned_4xi64_mask(__epi_4xi64 arg_0, const unsigned long int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vload_unsigned_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg2_8xi8x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg2.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X2]] [[TMP4]]
//
__epi_8xi8x2 test_vlseg2_8xi8x2(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg2_8xi8x2(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg2_8xi8x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg2.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X2]] [[TMP4]]
//
__epi_8xi8x2 test_vlseg2_8xi8x2_mask(__epi_8xi8x2 arg_0, const signed char*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg2_8xi8x2_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg2_4xi16x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg2.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X2]] [[TMP4]]
//
__epi_4xi16x2 test_vlseg2_4xi16x2(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg2_4xi16x2(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg2_4xi16x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg2.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X2]] [[TMP4]]
//
__epi_4xi16x2 test_vlseg2_4xi16x2_mask(__epi_4xi16x2 arg_0, const signed short int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg2_4xi16x2_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg2_2xi32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg2.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X2]] [[TMP4]]
//
__epi_2xi32x2 test_vlseg2_2xi32x2(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg2_2xi32x2(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg2_2xi32x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg2.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X2]] [[TMP4]]
//
__epi_2xi32x2 test_vlseg2_2xi32x2_mask(__epi_2xi32x2 arg_0, const signed int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg2_2xi32x2_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg2_1xi64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg2.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X2]] [[TMP4]]
//
__epi_1xi64x2 test_vlseg2_1xi64x2(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg2_1xi64x2(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg2_1xi64x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg2.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X2]] [[TMP4]]
//
__epi_1xi64x2 test_vlseg2_1xi64x2_mask(__epi_1xi64x2 arg_0, const signed long int*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg2_1xi64x2_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg2_2xf32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg2.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X2]] [[TMP4]]
//
__epi_2xf32x2 test_vlseg2_2xf32x2(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg2_2xf32x2(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg2_2xf32x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg2.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X2]] [[TMP4]]
//
__epi_2xf32x2 test_vlseg2_2xf32x2_mask(__epi_2xf32x2 arg_0, const float*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg2_2xf32x2_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg2_1xf64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg2.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X2]] [[TMP4]]
//
__epi_1xf64x2 test_vlseg2_1xf64x2(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg2_1xf64x2(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg2_1xf64x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg2.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X2]] [[TMP4]]
//
__epi_1xf64x2 test_vlseg2_1xf64x2_mask(__epi_1xf64x2 arg_0, const double*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg2_1xf64x2_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg2_indexed_8xi8x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg2.indexed.nxv8i8.nxv8i8(i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X2]] [[TMP4]]
//
__epi_8xi8x2 test_vlseg2_indexed_8xi8x2(const signed char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg2_indexed_8xi8x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg2_indexed_8xi8x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg2.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X2]] [[TMP4]]
//
__epi_8xi8x2 test_vlseg2_indexed_8xi8x2_mask(__epi_8xi8x2 arg_0, const signed char*  arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg2_indexed_8xi8x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg2_indexed_4xi16x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg2.indexed.nxv4i16.nxv4i16(i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X2]] [[TMP4]]
//
__epi_4xi16x2 test_vlseg2_indexed_4xi16x2(const signed short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg2_indexed_4xi16x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg2_indexed_4xi16x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg2.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X2]] [[TMP4]]
//
__epi_4xi16x2 test_vlseg2_indexed_4xi16x2_mask(__epi_4xi16x2 arg_0, const signed short int*  arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg2_indexed_4xi16x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg2_indexed_2xi32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg2.indexed.nxv2i32.nxv2i32(i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X2]] [[TMP4]]
//
__epi_2xi32x2 test_vlseg2_indexed_2xi32x2(const signed int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg2_indexed_2xi32x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg2_indexed_2xi32x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg2.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X2]] [[TMP4]]
//
__epi_2xi32x2 test_vlseg2_indexed_2xi32x2_mask(__epi_2xi32x2 arg_0, const signed int*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg2_indexed_2xi32x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg2_indexed_1xi64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg2.indexed.nxv1i64.nxv1i64(i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X2]] [[TMP4]]
//
__epi_1xi64x2 test_vlseg2_indexed_1xi64x2(const signed long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg2_indexed_1xi64x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg2_indexed_1xi64x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg2.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X2]] [[TMP4]]
//
__epi_1xi64x2 test_vlseg2_indexed_1xi64x2_mask(__epi_1xi64x2 arg_0, const signed long int*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg2_indexed_1xi64x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg2_indexed_2xf32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg2.indexed.nxv2f32.nxv2i32(float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X2]] [[TMP4]]
//
__epi_2xf32x2 test_vlseg2_indexed_2xf32x2(const float*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg2_indexed_2xf32x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg2_indexed_2xf32x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg2.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X2]] [[TMP4]]
//
__epi_2xf32x2 test_vlseg2_indexed_2xf32x2_mask(__epi_2xf32x2 arg_0, const float*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg2_indexed_2xf32x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg2_indexed_1xf64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg2.indexed.nxv1f64.nxv1i64(double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X2]] [[TMP4]]
//
__epi_1xf64x2 test_vlseg2_indexed_1xf64x2(const double*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg2_indexed_1xf64x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg2_indexed_1xf64x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg2.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X2]] [[TMP4]]
//
__epi_1xf64x2 test_vlseg2_indexed_1xf64x2_mask(__epi_1xf64x2 arg_0, const double*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg2_indexed_1xf64x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg2_strided_8xi8x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg2.strided.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X2]] [[TMP4]]
//
__epi_8xi8x2 test_vlseg2_strided_8xi8x2(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg2_strided_8xi8x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg2_strided_8xi8x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg2.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], i8* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X2]] [[TMP4]]
//
__epi_8xi8x2 test_vlseg2_strided_8xi8x2_mask(__epi_8xi8x2 arg_0, const signed char*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg2_strided_8xi8x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg2_strided_4xi16x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg2.strided.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X2]] [[TMP4]]
//
__epi_4xi16x2 test_vlseg2_strided_4xi16x2(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg2_strided_4xi16x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg2_strided_4xi16x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg2.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], i16* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X2]] [[TMP4]]
//
__epi_4xi16x2 test_vlseg2_strided_4xi16x2_mask(__epi_4xi16x2 arg_0, const signed short int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg2_strided_4xi16x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg2_strided_2xi32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg2.strided.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X2]] [[TMP4]]
//
__epi_2xi32x2 test_vlseg2_strided_2xi32x2(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg2_strided_2xi32x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg2_strided_2xi32x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg2.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], i32* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X2]] [[TMP4]]
//
__epi_2xi32x2 test_vlseg2_strided_2xi32x2_mask(__epi_2xi32x2 arg_0, const signed int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg2_strided_2xi32x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg2_strided_1xi64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg2.strided.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X2]] [[TMP4]]
//
__epi_1xi64x2 test_vlseg2_strided_1xi64x2(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg2_strided_1xi64x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg2_strided_1xi64x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg2.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], i64* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X2]] [[TMP4]]
//
__epi_1xi64x2 test_vlseg2_strided_1xi64x2_mask(__epi_1xi64x2 arg_0, const signed long int*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg2_strided_1xi64x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg2_strided_2xf32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg2.strided.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X2]] [[TMP4]]
//
__epi_2xf32x2 test_vlseg2_strided_2xf32x2(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg2_strided_2xf32x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg2_strided_2xf32x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg2.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], float* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X2]] [[TMP4]]
//
__epi_2xf32x2 test_vlseg2_strided_2xf32x2_mask(__epi_2xf32x2 arg_0, const float*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg2_strided_2xf32x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg2_strided_1xf64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg2.strided.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X2]] [[TMP4]]
//
__epi_1xf64x2 test_vlseg2_strided_1xf64x2(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg2_strided_1xf64x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg2_strided_1xf64x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg2.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], double* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X2]] [[TMP4]]
//
__epi_1xf64x2 test_vlseg2_strided_1xf64x2_mask(__epi_1xf64x2 arg_0, const double*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg2_strided_1xf64x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg3_8xi8x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg3.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X3]] [[TMP6]]
//
__epi_8xi8x3 test_vlseg3_8xi8x3(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg3_8xi8x3(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg3_8xi8x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg3.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X3]] [[TMP6]]
//
__epi_8xi8x3 test_vlseg3_8xi8x3_mask(__epi_8xi8x3 arg_0, const signed char*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg3_8xi8x3_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg3_4xi16x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg3.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X3]] [[TMP6]]
//
__epi_4xi16x3 test_vlseg3_4xi16x3(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg3_4xi16x3(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg3_4xi16x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg3.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X3]] [[TMP6]]
//
__epi_4xi16x3 test_vlseg3_4xi16x3_mask(__epi_4xi16x3 arg_0, const signed short int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg3_4xi16x3_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg3_2xi32x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg3.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X3]] [[TMP6]]
//
__epi_2xi32x3 test_vlseg3_2xi32x3(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg3_2xi32x3(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg3_2xi32x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg3.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X3]] [[TMP6]]
//
__epi_2xi32x3 test_vlseg3_2xi32x3_mask(__epi_2xi32x3 arg_0, const signed int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg3_2xi32x3_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg3_1xi64x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg3.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X3]] [[TMP6]]
//
__epi_1xi64x3 test_vlseg3_1xi64x3(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg3_1xi64x3(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg3_1xi64x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg3.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X3]] [[TMP6]]
//
__epi_1xi64x3 test_vlseg3_1xi64x3_mask(__epi_1xi64x3 arg_0, const signed long int*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg3_1xi64x3_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg3_2xf32x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg3.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X3]] [[TMP6]]
//
__epi_2xf32x3 test_vlseg3_2xf32x3(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg3_2xf32x3(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg3_2xf32x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg3.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X3]] [[TMP6]]
//
__epi_2xf32x3 test_vlseg3_2xf32x3_mask(__epi_2xf32x3 arg_0, const float*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg3_2xf32x3_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg3_1xf64x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg3.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X3]] [[TMP6]]
//
__epi_1xf64x3 test_vlseg3_1xf64x3(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg3_1xf64x3(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg3_1xf64x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg3.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X3]] [[TMP6]]
//
__epi_1xf64x3 test_vlseg3_1xf64x3_mask(__epi_1xf64x3 arg_0, const double*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg3_1xf64x3_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg3_indexed_8xi8x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg3.indexed.nxv8i8.nxv8i8(i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X3]] [[TMP6]]
//
__epi_8xi8x3 test_vlseg3_indexed_8xi8x3(const signed char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg3_indexed_8xi8x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg3_indexed_8xi8x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg3.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X3]] [[TMP6]]
//
__epi_8xi8x3 test_vlseg3_indexed_8xi8x3_mask(__epi_8xi8x3 arg_0, const signed char*  arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg3_indexed_8xi8x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg3_indexed_4xi16x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg3.indexed.nxv4i16.nxv4i16(i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X3]] [[TMP6]]
//
__epi_4xi16x3 test_vlseg3_indexed_4xi16x3(const signed short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg3_indexed_4xi16x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg3_indexed_4xi16x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg3.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X3]] [[TMP6]]
//
__epi_4xi16x3 test_vlseg3_indexed_4xi16x3_mask(__epi_4xi16x3 arg_0, const signed short int*  arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg3_indexed_4xi16x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg3_indexed_2xi32x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg3.indexed.nxv2i32.nxv2i32(i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X3]] [[TMP6]]
//
__epi_2xi32x3 test_vlseg3_indexed_2xi32x3(const signed int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg3_indexed_2xi32x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg3_indexed_2xi32x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg3.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X3]] [[TMP6]]
//
__epi_2xi32x3 test_vlseg3_indexed_2xi32x3_mask(__epi_2xi32x3 arg_0, const signed int*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg3_indexed_2xi32x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg3_indexed_1xi64x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg3.indexed.nxv1i64.nxv1i64(i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X3]] [[TMP6]]
//
__epi_1xi64x3 test_vlseg3_indexed_1xi64x3(const signed long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg3_indexed_1xi64x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg3_indexed_1xi64x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg3.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X3]] [[TMP6]]
//
__epi_1xi64x3 test_vlseg3_indexed_1xi64x3_mask(__epi_1xi64x3 arg_0, const signed long int*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg3_indexed_1xi64x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg3_indexed_2xf32x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg3.indexed.nxv2f32.nxv2i32(float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X3]] [[TMP6]]
//
__epi_2xf32x3 test_vlseg3_indexed_2xf32x3(const float*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg3_indexed_2xf32x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg3_indexed_2xf32x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg3.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X3]] [[TMP6]]
//
__epi_2xf32x3 test_vlseg3_indexed_2xf32x3_mask(__epi_2xf32x3 arg_0, const float*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg3_indexed_2xf32x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg3_indexed_1xf64x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg3.indexed.nxv1f64.nxv1i64(double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X3]] [[TMP6]]
//
__epi_1xf64x3 test_vlseg3_indexed_1xf64x3(const double*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg3_indexed_1xf64x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg3_indexed_1xf64x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg3.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X3]] [[TMP6]]
//
__epi_1xf64x3 test_vlseg3_indexed_1xf64x3_mask(__epi_1xf64x3 arg_0, const double*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg3_indexed_1xf64x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg3_strided_8xi8x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg3.strided.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X3]] [[TMP6]]
//
__epi_8xi8x3 test_vlseg3_strided_8xi8x3(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg3_strided_8xi8x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg3_strided_8xi8x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg3.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], i8* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X3]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X3]] [[TMP6]]
//
__epi_8xi8x3 test_vlseg3_strided_8xi8x3_mask(__epi_8xi8x3 arg_0, const signed char*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg3_strided_8xi8x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg3_strided_4xi16x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg3.strided.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X3]] [[TMP6]]
//
__epi_4xi16x3 test_vlseg3_strided_4xi16x3(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg3_strided_4xi16x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg3_strided_4xi16x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg3.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], i16* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X3]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X3]] [[TMP6]]
//
__epi_4xi16x3 test_vlseg3_strided_4xi16x3_mask(__epi_4xi16x3 arg_0, const signed short int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg3_strided_4xi16x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg3_strided_2xi32x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg3.strided.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X3]] [[TMP6]]
//
__epi_2xi32x3 test_vlseg3_strided_2xi32x3(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg3_strided_2xi32x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg3_strided_2xi32x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg3.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], i32* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X3]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X3]] [[TMP6]]
//
__epi_2xi32x3 test_vlseg3_strided_2xi32x3_mask(__epi_2xi32x3 arg_0, const signed int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg3_strided_2xi32x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg3_strided_1xi64x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg3.strided.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X3]] [[TMP6]]
//
__epi_1xi64x3 test_vlseg3_strided_1xi64x3(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg3_strided_1xi64x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg3_strided_1xi64x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg3.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], i64* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X3]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X3]] [[TMP6]]
//
__epi_1xi64x3 test_vlseg3_strided_1xi64x3_mask(__epi_1xi64x3 arg_0, const signed long int*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg3_strided_1xi64x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg3_strided_2xf32x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg3.strided.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X3]] [[TMP6]]
//
__epi_2xf32x3 test_vlseg3_strided_2xf32x3(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg3_strided_2xf32x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg3_strided_2xf32x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg3.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], float* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X3]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X3]] [[TMP6]]
//
__epi_2xf32x3 test_vlseg3_strided_2xf32x3_mask(__epi_2xf32x3 arg_0, const float*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg3_strided_2xf32x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg3_strided_1xf64x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg3.strided.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X3]] [[TMP6]]
//
__epi_1xf64x3 test_vlseg3_strided_1xf64x3(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg3_strided_1xf64x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg3_strided_1xf64x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg3.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], double* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X3]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X3]] [[TMP6]]
//
__epi_1xf64x3 test_vlseg3_strided_1xf64x3_mask(__epi_1xf64x3 arg_0, const double*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg3_strided_1xf64x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg4_8xi8x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg4.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X4]] [[TMP8]]
//
__epi_8xi8x4 test_vlseg4_8xi8x4(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg4_8xi8x4(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg4_8xi8x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg4.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X4]] [[TMP8]]
//
__epi_8xi8x4 test_vlseg4_8xi8x4_mask(__epi_8xi8x4 arg_0, const signed char*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg4_8xi8x4_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg4_4xi16x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg4.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X4]] [[TMP8]]
//
__epi_4xi16x4 test_vlseg4_4xi16x4(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg4_4xi16x4(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg4_4xi16x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg4.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X4]] [[TMP8]]
//
__epi_4xi16x4 test_vlseg4_4xi16x4_mask(__epi_4xi16x4 arg_0, const signed short int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg4_4xi16x4_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg4_2xi32x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg4.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X4]] [[TMP8]]
//
__epi_2xi32x4 test_vlseg4_2xi32x4(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg4_2xi32x4(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg4_2xi32x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg4.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X4]] [[TMP8]]
//
__epi_2xi32x4 test_vlseg4_2xi32x4_mask(__epi_2xi32x4 arg_0, const signed int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg4_2xi32x4_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg4_1xi64x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg4.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X4]] [[TMP8]]
//
__epi_1xi64x4 test_vlseg4_1xi64x4(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg4_1xi64x4(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg4_1xi64x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg4.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X4]] [[TMP8]]
//
__epi_1xi64x4 test_vlseg4_1xi64x4_mask(__epi_1xi64x4 arg_0, const signed long int*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg4_1xi64x4_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg4_2xf32x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg4.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X4]] [[TMP8]]
//
__epi_2xf32x4 test_vlseg4_2xf32x4(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg4_2xf32x4(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg4_2xf32x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg4.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X4]] [[TMP8]]
//
__epi_2xf32x4 test_vlseg4_2xf32x4_mask(__epi_2xf32x4 arg_0, const float*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg4_2xf32x4_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg4_1xf64x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg4.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X4]] [[TMP8]]
//
__epi_1xf64x4 test_vlseg4_1xf64x4(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg4_1xf64x4(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg4_1xf64x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg4.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X4]] [[TMP8]]
//
__epi_1xf64x4 test_vlseg4_1xf64x4_mask(__epi_1xf64x4 arg_0, const double*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg4_1xf64x4_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg4_indexed_8xi8x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg4.indexed.nxv8i8.nxv8i8(i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X4]] [[TMP8]]
//
__epi_8xi8x4 test_vlseg4_indexed_8xi8x4(const signed char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg4_indexed_8xi8x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg4_indexed_8xi8x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg4.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X4]] [[TMP8]]
//
__epi_8xi8x4 test_vlseg4_indexed_8xi8x4_mask(__epi_8xi8x4 arg_0, const signed char*  arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg4_indexed_8xi8x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg4_indexed_4xi16x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg4.indexed.nxv4i16.nxv4i16(i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X4]] [[TMP8]]
//
__epi_4xi16x4 test_vlseg4_indexed_4xi16x4(const signed short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg4_indexed_4xi16x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg4_indexed_4xi16x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg4.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X4]] [[TMP8]]
//
__epi_4xi16x4 test_vlseg4_indexed_4xi16x4_mask(__epi_4xi16x4 arg_0, const signed short int*  arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg4_indexed_4xi16x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg4_indexed_2xi32x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg4.indexed.nxv2i32.nxv2i32(i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X4]] [[TMP8]]
//
__epi_2xi32x4 test_vlseg4_indexed_2xi32x4(const signed int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg4_indexed_2xi32x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg4_indexed_2xi32x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg4.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X4]] [[TMP8]]
//
__epi_2xi32x4 test_vlseg4_indexed_2xi32x4_mask(__epi_2xi32x4 arg_0, const signed int*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg4_indexed_2xi32x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg4_indexed_1xi64x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg4.indexed.nxv1i64.nxv1i64(i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X4]] [[TMP8]]
//
__epi_1xi64x4 test_vlseg4_indexed_1xi64x4(const signed long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg4_indexed_1xi64x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg4_indexed_1xi64x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg4.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X4]] [[TMP8]]
//
__epi_1xi64x4 test_vlseg4_indexed_1xi64x4_mask(__epi_1xi64x4 arg_0, const signed long int*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg4_indexed_1xi64x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg4_indexed_2xf32x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg4.indexed.nxv2f32.nxv2i32(float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X4]] [[TMP8]]
//
__epi_2xf32x4 test_vlseg4_indexed_2xf32x4(const float*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg4_indexed_2xf32x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg4_indexed_2xf32x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg4.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X4]] [[TMP8]]
//
__epi_2xf32x4 test_vlseg4_indexed_2xf32x4_mask(__epi_2xf32x4 arg_0, const float*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg4_indexed_2xf32x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg4_indexed_1xf64x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg4.indexed.nxv1f64.nxv1i64(double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X4]] [[TMP8]]
//
__epi_1xf64x4 test_vlseg4_indexed_1xf64x4(const double*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg4_indexed_1xf64x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg4_indexed_1xf64x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg4.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X4]] [[TMP8]]
//
__epi_1xf64x4 test_vlseg4_indexed_1xf64x4_mask(__epi_1xf64x4 arg_0, const double*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg4_indexed_1xf64x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg4_strided_8xi8x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg4.strided.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X4]] [[TMP8]]
//
__epi_8xi8x4 test_vlseg4_strided_8xi8x4(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg4_strided_8xi8x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg4_strided_8xi8x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg4.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], i8* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X4]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X4]] [[TMP8]]
//
__epi_8xi8x4 test_vlseg4_strided_8xi8x4_mask(__epi_8xi8x4 arg_0, const signed char*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg4_strided_8xi8x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg4_strided_4xi16x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg4.strided.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X4]] [[TMP8]]
//
__epi_4xi16x4 test_vlseg4_strided_4xi16x4(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg4_strided_4xi16x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg4_strided_4xi16x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg4.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], i16* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X4]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X4]] [[TMP8]]
//
__epi_4xi16x4 test_vlseg4_strided_4xi16x4_mask(__epi_4xi16x4 arg_0, const signed short int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg4_strided_4xi16x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg4_strided_2xi32x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg4.strided.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X4]] [[TMP8]]
//
__epi_2xi32x4 test_vlseg4_strided_2xi32x4(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg4_strided_2xi32x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg4_strided_2xi32x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg4.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], i32* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X4]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X4]] [[TMP8]]
//
__epi_2xi32x4 test_vlseg4_strided_2xi32x4_mask(__epi_2xi32x4 arg_0, const signed int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg4_strided_2xi32x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg4_strided_1xi64x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg4.strided.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X4]] [[TMP8]]
//
__epi_1xi64x4 test_vlseg4_strided_1xi64x4(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg4_strided_1xi64x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg4_strided_1xi64x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg4.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], i64* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X4]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X4]] [[TMP8]]
//
__epi_1xi64x4 test_vlseg4_strided_1xi64x4_mask(__epi_1xi64x4 arg_0, const signed long int*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg4_strided_1xi64x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg4_strided_2xf32x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg4.strided.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X4]] [[TMP8]]
//
__epi_2xf32x4 test_vlseg4_strided_2xf32x4(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg4_strided_2xf32x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg4_strided_2xf32x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg4.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], float* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X4]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X4]] [[TMP8]]
//
__epi_2xf32x4 test_vlseg4_strided_2xf32x4_mask(__epi_2xf32x4 arg_0, const float*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg4_strided_2xf32x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg4_strided_1xf64x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg4.strided.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X4]] [[TMP8]]
//
__epi_1xf64x4 test_vlseg4_strided_1xf64x4(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg4_strided_1xf64x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg4_strided_1xf64x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg4.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], double* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X4]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X4]] [[TMP8]]
//
__epi_1xf64x4 test_vlseg4_strided_1xf64x4_mask(__epi_1xf64x4 arg_0, const double*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg4_strided_1xf64x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg5_8xi8x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg5.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X5]] [[TMP10]]
//
__epi_8xi8x5 test_vlseg5_8xi8x5(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg5_8xi8x5(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg5_8xi8x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg5.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE4:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X5]] [[TMP10]]
//
__epi_8xi8x5 test_vlseg5_8xi8x5_mask(__epi_8xi8x5 arg_0, const signed char*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg5_8xi8x5_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg5_4xi16x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg5.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X5]] [[TMP10]]
//
__epi_4xi16x5 test_vlseg5_4xi16x5(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg5_4xi16x5(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg5_4xi16x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg5.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE4:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X5]] [[TMP10]]
//
__epi_4xi16x5 test_vlseg5_4xi16x5_mask(__epi_4xi16x5 arg_0, const signed short int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg5_4xi16x5_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg5_2xi32x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg5.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X5]] [[TMP10]]
//
__epi_2xi32x5 test_vlseg5_2xi32x5(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg5_2xi32x5(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg5_2xi32x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg5.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE4:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X5]] [[TMP10]]
//
__epi_2xi32x5 test_vlseg5_2xi32x5_mask(__epi_2xi32x5 arg_0, const signed int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg5_2xi32x5_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg5_1xi64x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg5.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X5]] [[TMP10]]
//
__epi_1xi64x5 test_vlseg5_1xi64x5(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg5_1xi64x5(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg5_1xi64x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg5.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE4:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X5]] [[TMP10]]
//
__epi_1xi64x5 test_vlseg5_1xi64x5_mask(__epi_1xi64x5 arg_0, const signed long int*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg5_1xi64x5_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg5_2xf32x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg5.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X5]] [[TMP10]]
//
__epi_2xf32x5 test_vlseg5_2xf32x5(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg5_2xf32x5(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg5_2xf32x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg5.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], <vscale x 2 x float> [[ARG_0_COERCE4:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X5]] [[TMP10]]
//
__epi_2xf32x5 test_vlseg5_2xf32x5_mask(__epi_2xf32x5 arg_0, const float*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg5_2xf32x5_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg5_1xf64x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg5.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X5]] [[TMP10]]
//
__epi_1xf64x5 test_vlseg5_1xf64x5(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg5_1xf64x5(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg5_1xf64x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg5.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], <vscale x 1 x double> [[ARG_0_COERCE4:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X5]] [[TMP10]]
//
__epi_1xf64x5 test_vlseg5_1xf64x5_mask(__epi_1xf64x5 arg_0, const double*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg5_1xf64x5_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg5_indexed_8xi8x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg5.indexed.nxv8i8.nxv8i8(i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X5]] [[TMP10]]
//
__epi_8xi8x5 test_vlseg5_indexed_8xi8x5(const signed char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg5_indexed_8xi8x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg5_indexed_8xi8x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg5.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE4:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X5]] [[TMP10]]
//
__epi_8xi8x5 test_vlseg5_indexed_8xi8x5_mask(__epi_8xi8x5 arg_0, const signed char*  arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg5_indexed_8xi8x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg5_indexed_4xi16x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg5.indexed.nxv4i16.nxv4i16(i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X5]] [[TMP10]]
//
__epi_4xi16x5 test_vlseg5_indexed_4xi16x5(const signed short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg5_indexed_4xi16x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg5_indexed_4xi16x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg5.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE4:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X5]] [[TMP10]]
//
__epi_4xi16x5 test_vlseg5_indexed_4xi16x5_mask(__epi_4xi16x5 arg_0, const signed short int*  arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg5_indexed_4xi16x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg5_indexed_2xi32x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg5.indexed.nxv2i32.nxv2i32(i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X5]] [[TMP10]]
//
__epi_2xi32x5 test_vlseg5_indexed_2xi32x5(const signed int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg5_indexed_2xi32x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg5_indexed_2xi32x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg5.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE4:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X5]] [[TMP10]]
//
__epi_2xi32x5 test_vlseg5_indexed_2xi32x5_mask(__epi_2xi32x5 arg_0, const signed int*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg5_indexed_2xi32x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg5_indexed_1xi64x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg5.indexed.nxv1i64.nxv1i64(i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X5]] [[TMP10]]
//
__epi_1xi64x5 test_vlseg5_indexed_1xi64x5(const signed long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg5_indexed_1xi64x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg5_indexed_1xi64x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg5.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE4:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X5]] [[TMP10]]
//
__epi_1xi64x5 test_vlseg5_indexed_1xi64x5_mask(__epi_1xi64x5 arg_0, const signed long int*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg5_indexed_1xi64x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg5_indexed_2xf32x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg5.indexed.nxv2f32.nxv2i32(float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X5]] [[TMP10]]
//
__epi_2xf32x5 test_vlseg5_indexed_2xf32x5(const float*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg5_indexed_2xf32x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg5_indexed_2xf32x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg5.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], <vscale x 2 x float> [[ARG_0_COERCE4:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X5]] [[TMP10]]
//
__epi_2xf32x5 test_vlseg5_indexed_2xf32x5_mask(__epi_2xf32x5 arg_0, const float*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg5_indexed_2xf32x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg5_indexed_1xf64x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg5.indexed.nxv1f64.nxv1i64(double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X5]] [[TMP10]]
//
__epi_1xf64x5 test_vlseg5_indexed_1xf64x5(const double*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg5_indexed_1xf64x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg5_indexed_1xf64x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg5.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], <vscale x 1 x double> [[ARG_0_COERCE4:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X5]] [[TMP10]]
//
__epi_1xf64x5 test_vlseg5_indexed_1xf64x5_mask(__epi_1xf64x5 arg_0, const double*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg5_indexed_1xf64x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg5_strided_8xi8x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg5.strided.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X5]] [[TMP10]]
//
__epi_8xi8x5 test_vlseg5_strided_8xi8x5(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg5_strided_8xi8x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg5_strided_8xi8x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg5.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE4:%.*]], i8* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X5]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X5]] [[TMP10]]
//
__epi_8xi8x5 test_vlseg5_strided_8xi8x5_mask(__epi_8xi8x5 arg_0, const signed char*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg5_strided_8xi8x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg5_strided_4xi16x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg5.strided.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X5]] [[TMP10]]
//
__epi_4xi16x5 test_vlseg5_strided_4xi16x5(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg5_strided_4xi16x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg5_strided_4xi16x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg5.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE4:%.*]], i16* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X5]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X5]] [[TMP10]]
//
__epi_4xi16x5 test_vlseg5_strided_4xi16x5_mask(__epi_4xi16x5 arg_0, const signed short int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg5_strided_4xi16x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg5_strided_2xi32x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg5.strided.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X5]] [[TMP10]]
//
__epi_2xi32x5 test_vlseg5_strided_2xi32x5(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg5_strided_2xi32x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg5_strided_2xi32x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg5.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE4:%.*]], i32* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X5]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X5]] [[TMP10]]
//
__epi_2xi32x5 test_vlseg5_strided_2xi32x5_mask(__epi_2xi32x5 arg_0, const signed int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg5_strided_2xi32x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg5_strided_1xi64x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg5.strided.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X5]] [[TMP10]]
//
__epi_1xi64x5 test_vlseg5_strided_1xi64x5(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg5_strided_1xi64x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg5_strided_1xi64x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg5.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE4:%.*]], i64* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X5]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X5]] [[TMP10]]
//
__epi_1xi64x5 test_vlseg5_strided_1xi64x5_mask(__epi_1xi64x5 arg_0, const signed long int*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg5_strided_1xi64x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg5_strided_2xf32x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg5.strided.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X5]] [[TMP10]]
//
__epi_2xf32x5 test_vlseg5_strided_2xf32x5(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg5_strided_2xf32x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg5_strided_2xf32x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg5.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], <vscale x 2 x float> [[ARG_0_COERCE4:%.*]], float* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X5]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X5]] [[TMP10]]
//
__epi_2xf32x5 test_vlseg5_strided_2xf32x5_mask(__epi_2xf32x5 arg_0, const float*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg5_strided_2xf32x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg5_strided_1xf64x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg5.strided.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X5]] [[TMP10]]
//
__epi_1xf64x5 test_vlseg5_strided_1xf64x5(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg5_strided_1xf64x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg5_strided_1xf64x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg5.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], <vscale x 1 x double> [[ARG_0_COERCE4:%.*]], double* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X5]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X5]] [[TMP10]]
//
__epi_1xf64x5 test_vlseg5_strided_1xf64x5_mask(__epi_1xf64x5 arg_0, const double*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg5_strided_1xf64x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg6_8xi8x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg6.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X6]] [[TMP12]]
//
__epi_8xi8x6 test_vlseg6_8xi8x6(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg6_8xi8x6(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg6_8xi8x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg6.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE5:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X6]] [[TMP12]]
//
__epi_8xi8x6 test_vlseg6_8xi8x6_mask(__epi_8xi8x6 arg_0, const signed char*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg6_8xi8x6_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg6_4xi16x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg6.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X6]] [[TMP12]]
//
__epi_4xi16x6 test_vlseg6_4xi16x6(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg6_4xi16x6(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg6_4xi16x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg6.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE5:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X6]] [[TMP12]]
//
__epi_4xi16x6 test_vlseg6_4xi16x6_mask(__epi_4xi16x6 arg_0, const signed short int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg6_4xi16x6_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg6_2xi32x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg6.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X6]] [[TMP12]]
//
__epi_2xi32x6 test_vlseg6_2xi32x6(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg6_2xi32x6(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg6_2xi32x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg6.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE5:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X6]] [[TMP12]]
//
__epi_2xi32x6 test_vlseg6_2xi32x6_mask(__epi_2xi32x6 arg_0, const signed int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg6_2xi32x6_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg6_1xi64x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg6.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X6]] [[TMP12]]
//
__epi_1xi64x6 test_vlseg6_1xi64x6(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg6_1xi64x6(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg6_1xi64x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg6.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE5:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X6]] [[TMP12]]
//
__epi_1xi64x6 test_vlseg6_1xi64x6_mask(__epi_1xi64x6 arg_0, const signed long int*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg6_1xi64x6_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg6_2xf32x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg6.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X6]] [[TMP12]]
//
__epi_2xf32x6 test_vlseg6_2xf32x6(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg6_2xf32x6(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg6_2xf32x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg6.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], <vscale x 2 x float> [[ARG_0_COERCE4:%.*]], <vscale x 2 x float> [[ARG_0_COERCE5:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X6]] [[TMP12]]
//
__epi_2xf32x6 test_vlseg6_2xf32x6_mask(__epi_2xf32x6 arg_0, const float*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg6_2xf32x6_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg6_1xf64x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg6.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X6]] [[TMP12]]
//
__epi_1xf64x6 test_vlseg6_1xf64x6(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg6_1xf64x6(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg6_1xf64x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg6.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], <vscale x 1 x double> [[ARG_0_COERCE4:%.*]], <vscale x 1 x double> [[ARG_0_COERCE5:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X6]] [[TMP12]]
//
__epi_1xf64x6 test_vlseg6_1xf64x6_mask(__epi_1xf64x6 arg_0, const double*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg6_1xf64x6_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg6_indexed_8xi8x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg6.indexed.nxv8i8.nxv8i8(i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X6]] [[TMP12]]
//
__epi_8xi8x6 test_vlseg6_indexed_8xi8x6(const signed char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg6_indexed_8xi8x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg6_indexed_8xi8x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg6.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE5:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X6]] [[TMP12]]
//
__epi_8xi8x6 test_vlseg6_indexed_8xi8x6_mask(__epi_8xi8x6 arg_0, const signed char*  arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg6_indexed_8xi8x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg6_indexed_4xi16x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg6.indexed.nxv4i16.nxv4i16(i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X6]] [[TMP12]]
//
__epi_4xi16x6 test_vlseg6_indexed_4xi16x6(const signed short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg6_indexed_4xi16x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg6_indexed_4xi16x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg6.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE5:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X6]] [[TMP12]]
//
__epi_4xi16x6 test_vlseg6_indexed_4xi16x6_mask(__epi_4xi16x6 arg_0, const signed short int*  arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg6_indexed_4xi16x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg6_indexed_2xi32x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg6.indexed.nxv2i32.nxv2i32(i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X6]] [[TMP12]]
//
__epi_2xi32x6 test_vlseg6_indexed_2xi32x6(const signed int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg6_indexed_2xi32x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg6_indexed_2xi32x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg6.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE5:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X6]] [[TMP12]]
//
__epi_2xi32x6 test_vlseg6_indexed_2xi32x6_mask(__epi_2xi32x6 arg_0, const signed int*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg6_indexed_2xi32x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg6_indexed_1xi64x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg6.indexed.nxv1i64.nxv1i64(i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X6]] [[TMP12]]
//
__epi_1xi64x6 test_vlseg6_indexed_1xi64x6(const signed long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg6_indexed_1xi64x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg6_indexed_1xi64x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg6.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE5:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X6]] [[TMP12]]
//
__epi_1xi64x6 test_vlseg6_indexed_1xi64x6_mask(__epi_1xi64x6 arg_0, const signed long int*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg6_indexed_1xi64x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg6_indexed_2xf32x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg6.indexed.nxv2f32.nxv2i32(float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X6]] [[TMP12]]
//
__epi_2xf32x6 test_vlseg6_indexed_2xf32x6(const float*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg6_indexed_2xf32x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg6_indexed_2xf32x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg6.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], <vscale x 2 x float> [[ARG_0_COERCE4:%.*]], <vscale x 2 x float> [[ARG_0_COERCE5:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X6]] [[TMP12]]
//
__epi_2xf32x6 test_vlseg6_indexed_2xf32x6_mask(__epi_2xf32x6 arg_0, const float*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg6_indexed_2xf32x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg6_indexed_1xf64x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg6.indexed.nxv1f64.nxv1i64(double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X6]] [[TMP12]]
//
__epi_1xf64x6 test_vlseg6_indexed_1xf64x6(const double*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg6_indexed_1xf64x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg6_indexed_1xf64x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg6.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], <vscale x 1 x double> [[ARG_0_COERCE4:%.*]], <vscale x 1 x double> [[ARG_0_COERCE5:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X6]] [[TMP12]]
//
__epi_1xf64x6 test_vlseg6_indexed_1xf64x6_mask(__epi_1xf64x6 arg_0, const double*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg6_indexed_1xf64x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg6_strided_8xi8x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg6.strided.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X6]] [[TMP12]]
//
__epi_8xi8x6 test_vlseg6_strided_8xi8x6(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg6_strided_8xi8x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg6_strided_8xi8x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg6.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE5:%.*]], i8* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X6]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X6]] [[TMP12]]
//
__epi_8xi8x6 test_vlseg6_strided_8xi8x6_mask(__epi_8xi8x6 arg_0, const signed char*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg6_strided_8xi8x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg6_strided_4xi16x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg6.strided.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X6]] [[TMP12]]
//
__epi_4xi16x6 test_vlseg6_strided_4xi16x6(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg6_strided_4xi16x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg6_strided_4xi16x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg6.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE5:%.*]], i16* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X6]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X6]] [[TMP12]]
//
__epi_4xi16x6 test_vlseg6_strided_4xi16x6_mask(__epi_4xi16x6 arg_0, const signed short int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg6_strided_4xi16x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg6_strided_2xi32x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg6.strided.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X6]] [[TMP12]]
//
__epi_2xi32x6 test_vlseg6_strided_2xi32x6(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg6_strided_2xi32x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg6_strided_2xi32x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg6.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE5:%.*]], i32* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X6]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X6]] [[TMP12]]
//
__epi_2xi32x6 test_vlseg6_strided_2xi32x6_mask(__epi_2xi32x6 arg_0, const signed int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg6_strided_2xi32x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg6_strided_1xi64x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg6.strided.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X6]] [[TMP12]]
//
__epi_1xi64x6 test_vlseg6_strided_1xi64x6(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg6_strided_1xi64x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg6_strided_1xi64x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg6.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE5:%.*]], i64* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X6]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X6]] [[TMP12]]
//
__epi_1xi64x6 test_vlseg6_strided_1xi64x6_mask(__epi_1xi64x6 arg_0, const signed long int*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg6_strided_1xi64x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg6_strided_2xf32x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg6.strided.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X6]] [[TMP12]]
//
__epi_2xf32x6 test_vlseg6_strided_2xf32x6(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg6_strided_2xf32x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg6_strided_2xf32x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg6.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], <vscale x 2 x float> [[ARG_0_COERCE4:%.*]], <vscale x 2 x float> [[ARG_0_COERCE5:%.*]], float* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X6]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X6]] [[TMP12]]
//
__epi_2xf32x6 test_vlseg6_strided_2xf32x6_mask(__epi_2xf32x6 arg_0, const float*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg6_strided_2xf32x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg6_strided_1xf64x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg6.strided.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X6]] [[TMP12]]
//
__epi_1xf64x6 test_vlseg6_strided_1xf64x6(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg6_strided_1xf64x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg6_strided_1xf64x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg6.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], <vscale x 1 x double> [[ARG_0_COERCE4:%.*]], <vscale x 1 x double> [[ARG_0_COERCE5:%.*]], double* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X6]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X6]] [[TMP12]]
//
__epi_1xf64x6 test_vlseg6_strided_1xf64x6_mask(__epi_1xf64x6 arg_0, const double*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg6_strided_1xf64x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg7_8xi8x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg7.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP12]], <vscale x 8 x i8> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X7]] [[TMP14]]
//
__epi_8xi8x7 test_vlseg7_8xi8x7(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg7_8xi8x7(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg7_8xi8x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg7.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE6:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP12]], <vscale x 8 x i8> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X7]] [[TMP14]]
//
__epi_8xi8x7 test_vlseg7_8xi8x7_mask(__epi_8xi8x7 arg_0, const signed char*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg7_8xi8x7_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg7_4xi16x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg7.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP12]], <vscale x 4 x i16> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X7]] [[TMP14]]
//
__epi_4xi16x7 test_vlseg7_4xi16x7(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg7_4xi16x7(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg7_4xi16x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg7.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE6:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP12]], <vscale x 4 x i16> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X7]] [[TMP14]]
//
__epi_4xi16x7 test_vlseg7_4xi16x7_mask(__epi_4xi16x7 arg_0, const signed short int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg7_4xi16x7_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg7_2xi32x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg7.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP12]], <vscale x 2 x i32> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X7]] [[TMP14]]
//
__epi_2xi32x7 test_vlseg7_2xi32x7(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg7_2xi32x7(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg7_2xi32x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg7.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE6:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP12]], <vscale x 2 x i32> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X7]] [[TMP14]]
//
__epi_2xi32x7 test_vlseg7_2xi32x7_mask(__epi_2xi32x7 arg_0, const signed int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg7_2xi32x7_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg7_1xi64x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg7.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP12]], <vscale x 1 x i64> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X7]] [[TMP14]]
//
__epi_1xi64x7 test_vlseg7_1xi64x7(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg7_1xi64x7(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg7_1xi64x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg7.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE6:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP12]], <vscale x 1 x i64> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X7]] [[TMP14]]
//
__epi_1xi64x7 test_vlseg7_1xi64x7_mask(__epi_1xi64x7 arg_0, const signed long int*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg7_1xi64x7_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg7_2xf32x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg7.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP12]], <vscale x 2 x float> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X7]] [[TMP14]]
//
__epi_2xf32x7 test_vlseg7_2xf32x7(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg7_2xf32x7(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg7_2xf32x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg7.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], <vscale x 2 x float> [[ARG_0_COERCE4:%.*]], <vscale x 2 x float> [[ARG_0_COERCE5:%.*]], <vscale x 2 x float> [[ARG_0_COERCE6:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP12]], <vscale x 2 x float> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X7]] [[TMP14]]
//
__epi_2xf32x7 test_vlseg7_2xf32x7_mask(__epi_2xf32x7 arg_0, const float*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg7_2xf32x7_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg7_1xf64x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg7.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP12]], <vscale x 1 x double> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X7]] [[TMP14]]
//
__epi_1xf64x7 test_vlseg7_1xf64x7(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg7_1xf64x7(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg7_1xf64x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg7.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], <vscale x 1 x double> [[ARG_0_COERCE4:%.*]], <vscale x 1 x double> [[ARG_0_COERCE5:%.*]], <vscale x 1 x double> [[ARG_0_COERCE6:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP12]], <vscale x 1 x double> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X7]] [[TMP14]]
//
__epi_1xf64x7 test_vlseg7_1xf64x7_mask(__epi_1xf64x7 arg_0, const double*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg7_1xf64x7_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg7_indexed_8xi8x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg7.indexed.nxv8i8.nxv8i8(i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP12]], <vscale x 8 x i8> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X7]] [[TMP14]]
//
__epi_8xi8x7 test_vlseg7_indexed_8xi8x7(const signed char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg7_indexed_8xi8x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg7_indexed_8xi8x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg7.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE6:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP12]], <vscale x 8 x i8> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X7]] [[TMP14]]
//
__epi_8xi8x7 test_vlseg7_indexed_8xi8x7_mask(__epi_8xi8x7 arg_0, const signed char*  arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg7_indexed_8xi8x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg7_indexed_4xi16x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg7.indexed.nxv4i16.nxv4i16(i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP12]], <vscale x 4 x i16> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X7]] [[TMP14]]
//
__epi_4xi16x7 test_vlseg7_indexed_4xi16x7(const signed short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg7_indexed_4xi16x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg7_indexed_4xi16x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg7.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE6:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP12]], <vscale x 4 x i16> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X7]] [[TMP14]]
//
__epi_4xi16x7 test_vlseg7_indexed_4xi16x7_mask(__epi_4xi16x7 arg_0, const signed short int*  arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg7_indexed_4xi16x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg7_indexed_2xi32x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg7.indexed.nxv2i32.nxv2i32(i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP12]], <vscale x 2 x i32> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X7]] [[TMP14]]
//
__epi_2xi32x7 test_vlseg7_indexed_2xi32x7(const signed int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg7_indexed_2xi32x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg7_indexed_2xi32x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg7.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE6:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP12]], <vscale x 2 x i32> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X7]] [[TMP14]]
//
__epi_2xi32x7 test_vlseg7_indexed_2xi32x7_mask(__epi_2xi32x7 arg_0, const signed int*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg7_indexed_2xi32x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg7_indexed_1xi64x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg7.indexed.nxv1i64.nxv1i64(i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP12]], <vscale x 1 x i64> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X7]] [[TMP14]]
//
__epi_1xi64x7 test_vlseg7_indexed_1xi64x7(const signed long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg7_indexed_1xi64x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg7_indexed_1xi64x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg7.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE6:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP12]], <vscale x 1 x i64> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X7]] [[TMP14]]
//
__epi_1xi64x7 test_vlseg7_indexed_1xi64x7_mask(__epi_1xi64x7 arg_0, const signed long int*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg7_indexed_1xi64x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg7_indexed_2xf32x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg7.indexed.nxv2f32.nxv2i32(float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP12]], <vscale x 2 x float> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X7]] [[TMP14]]
//
__epi_2xf32x7 test_vlseg7_indexed_2xf32x7(const float*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg7_indexed_2xf32x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg7_indexed_2xf32x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg7.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], <vscale x 2 x float> [[ARG_0_COERCE4:%.*]], <vscale x 2 x float> [[ARG_0_COERCE5:%.*]], <vscale x 2 x float> [[ARG_0_COERCE6:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP12]], <vscale x 2 x float> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X7]] [[TMP14]]
//
__epi_2xf32x7 test_vlseg7_indexed_2xf32x7_mask(__epi_2xf32x7 arg_0, const float*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg7_indexed_2xf32x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg7_indexed_1xf64x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg7.indexed.nxv1f64.nxv1i64(double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP12]], <vscale x 1 x double> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X7]] [[TMP14]]
//
__epi_1xf64x7 test_vlseg7_indexed_1xf64x7(const double*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg7_indexed_1xf64x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg7_indexed_1xf64x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg7.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], <vscale x 1 x double> [[ARG_0_COERCE4:%.*]], <vscale x 1 x double> [[ARG_0_COERCE5:%.*]], <vscale x 1 x double> [[ARG_0_COERCE6:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP12]], <vscale x 1 x double> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X7]] [[TMP14]]
//
__epi_1xf64x7 test_vlseg7_indexed_1xf64x7_mask(__epi_1xf64x7 arg_0, const double*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg7_indexed_1xf64x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg7_strided_8xi8x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg7.strided.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP12]], <vscale x 8 x i8> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X7]] [[TMP14]]
//
__epi_8xi8x7 test_vlseg7_strided_8xi8x7(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg7_strided_8xi8x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg7_strided_8xi8x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg7.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE6:%.*]], i8* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_8XI8X7]] [[TMP12]], <vscale x 8 x i8> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X7]] [[TMP14]]
//
__epi_8xi8x7 test_vlseg7_strided_8xi8x7_mask(__epi_8xi8x7 arg_0, const signed char*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg7_strided_8xi8x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg7_strided_4xi16x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg7.strided.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP12]], <vscale x 4 x i16> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X7]] [[TMP14]]
//
__epi_4xi16x7 test_vlseg7_strided_4xi16x7(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg7_strided_4xi16x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg7_strided_4xi16x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg7.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE6:%.*]], i16* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_4XI16X7]] [[TMP12]], <vscale x 4 x i16> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X7]] [[TMP14]]
//
__epi_4xi16x7 test_vlseg7_strided_4xi16x7_mask(__epi_4xi16x7 arg_0, const signed short int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg7_strided_4xi16x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg7_strided_2xi32x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg7.strided.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP12]], <vscale x 2 x i32> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X7]] [[TMP14]]
//
__epi_2xi32x7 test_vlseg7_strided_2xi32x7(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg7_strided_2xi32x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg7_strided_2xi32x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg7.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE6:%.*]], i32* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XI32X7]] [[TMP12]], <vscale x 2 x i32> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X7]] [[TMP14]]
//
__epi_2xi32x7 test_vlseg7_strided_2xi32x7_mask(__epi_2xi32x7 arg_0, const signed int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg7_strided_2xi32x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg7_strided_1xi64x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg7.strided.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP12]], <vscale x 1 x i64> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X7]] [[TMP14]]
//
__epi_1xi64x7 test_vlseg7_strided_1xi64x7(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg7_strided_1xi64x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg7_strided_1xi64x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg7.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE6:%.*]], i64* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XI64X7]] [[TMP12]], <vscale x 1 x i64> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X7]] [[TMP14]]
//
__epi_1xi64x7 test_vlseg7_strided_1xi64x7_mask(__epi_1xi64x7 arg_0, const signed long int*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg7_strided_1xi64x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg7_strided_2xf32x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg7.strided.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP12]], <vscale x 2 x float> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X7]] [[TMP14]]
//
__epi_2xf32x7 test_vlseg7_strided_2xf32x7(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg7_strided_2xf32x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg7_strided_2xf32x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg7.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], <vscale x 2 x float> [[ARG_0_COERCE4:%.*]], <vscale x 2 x float> [[ARG_0_COERCE5:%.*]], <vscale x 2 x float> [[ARG_0_COERCE6:%.*]], float* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XF32X7]] [[TMP12]], <vscale x 2 x float> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X7]] [[TMP14]]
//
__epi_2xf32x7 test_vlseg7_strided_2xf32x7_mask(__epi_2xf32x7 arg_0, const float*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg7_strided_2xf32x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg7_strided_1xf64x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg7.strided.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP12]], <vscale x 1 x double> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X7]] [[TMP14]]
//
__epi_1xf64x7 test_vlseg7_strided_1xf64x7(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg7_strided_1xf64x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg7_strided_1xf64x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg7.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], <vscale x 1 x double> [[ARG_0_COERCE4:%.*]], <vscale x 1 x double> [[ARG_0_COERCE5:%.*]], <vscale x 1 x double> [[ARG_0_COERCE6:%.*]], double* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XF64X7]] [[TMP12]], <vscale x 1 x double> [[TMP13]], 6
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X7]] [[TMP14]]
//
__epi_1xf64x7 test_vlseg7_strided_1xf64x7_mask(__epi_1xf64x7 arg_0, const double*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg7_strided_1xf64x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg8_8xi8x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg8.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP12]], <vscale x 8 x i8> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP14]], <vscale x 8 x i8> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X8]] [[TMP16]]
//
__epi_8xi8x8 test_vlseg8_8xi8x8(const signed char*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg8_8xi8x8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg8_8xi8x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg8.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE6:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE7:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP12]], <vscale x 8 x i8> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP14]], <vscale x 8 x i8> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X8]] [[TMP16]]
//
__epi_8xi8x8 test_vlseg8_8xi8x8_mask(__epi_8xi8x8 arg_0, const signed char*  arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg8_8xi8x8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg8_4xi16x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg8.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP12]], <vscale x 4 x i16> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP14]], <vscale x 4 x i16> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X8]] [[TMP16]]
//
__epi_4xi16x8 test_vlseg8_4xi16x8(const signed short int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg8_4xi16x8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg8_4xi16x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg8.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE6:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE7:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP12]], <vscale x 4 x i16> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP14]], <vscale x 4 x i16> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X8]] [[TMP16]]
//
__epi_4xi16x8 test_vlseg8_4xi16x8_mask(__epi_4xi16x8 arg_0, const signed short int*  arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg8_4xi16x8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg8_2xi32x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg8.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP12]], <vscale x 2 x i32> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP14]], <vscale x 2 x i32> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X8]] [[TMP16]]
//
__epi_2xi32x8 test_vlseg8_2xi32x8(const signed int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg8_2xi32x8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg8_2xi32x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg8.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE6:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE7:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP12]], <vscale x 2 x i32> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP14]], <vscale x 2 x i32> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X8]] [[TMP16]]
//
__epi_2xi32x8 test_vlseg8_2xi32x8_mask(__epi_2xi32x8 arg_0, const signed int*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg8_2xi32x8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg8_1xi64x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg8.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP12]], <vscale x 1 x i64> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP14]], <vscale x 1 x i64> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X8]] [[TMP16]]
//
__epi_1xi64x8 test_vlseg8_1xi64x8(const signed long int*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg8_1xi64x8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg8_1xi64x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg8.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE6:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE7:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP12]], <vscale x 1 x i64> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP14]], <vscale x 1 x i64> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X8]] [[TMP16]]
//
__epi_1xi64x8 test_vlseg8_1xi64x8_mask(__epi_1xi64x8 arg_0, const signed long int*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg8_1xi64x8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg8_2xf32x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg8.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP12]], <vscale x 2 x float> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP14]], <vscale x 2 x float> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X8]] [[TMP16]]
//
__epi_2xf32x8 test_vlseg8_2xf32x8(const float*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg8_2xf32x8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg8_2xf32x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg8.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], <vscale x 2 x float> [[ARG_0_COERCE4:%.*]], <vscale x 2 x float> [[ARG_0_COERCE5:%.*]], <vscale x 2 x float> [[ARG_0_COERCE6:%.*]], <vscale x 2 x float> [[ARG_0_COERCE7:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP12]], <vscale x 2 x float> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP14]], <vscale x 2 x float> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X8]] [[TMP16]]
//
__epi_2xf32x8 test_vlseg8_2xf32x8_mask(__epi_2xf32x8 arg_0, const float*  arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg8_2xf32x8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg8_1xf64x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg8.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP12]], <vscale x 1 x double> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP14]], <vscale x 1 x double> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X8]] [[TMP16]]
//
__epi_1xf64x8 test_vlseg8_1xf64x8(const double*  arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vlseg8_1xf64x8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vlseg8_1xf64x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg8.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], <vscale x 1 x double> [[ARG_0_COERCE4:%.*]], <vscale x 1 x double> [[ARG_0_COERCE5:%.*]], <vscale x 1 x double> [[ARG_0_COERCE6:%.*]], <vscale x 1 x double> [[ARG_0_COERCE7:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP12]], <vscale x 1 x double> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP14]], <vscale x 1 x double> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X8]] [[TMP16]]
//
__epi_1xf64x8 test_vlseg8_1xf64x8_mask(__epi_1xf64x8 arg_0, const double*  arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vlseg8_1xf64x8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vlseg8_indexed_8xi8x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg8.indexed.nxv8i8.nxv8i8(i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP12]], <vscale x 8 x i8> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP14]], <vscale x 8 x i8> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X8]] [[TMP16]]
//
__epi_8xi8x8 test_vlseg8_indexed_8xi8x8(const signed char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg8_indexed_8xi8x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg8_indexed_8xi8x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg8.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE6:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE7:%.*]], i8* [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP12]], <vscale x 8 x i8> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP14]], <vscale x 8 x i8> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X8]] [[TMP16]]
//
__epi_8xi8x8 test_vlseg8_indexed_8xi8x8_mask(__epi_8xi8x8 arg_0, const signed char*  arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg8_indexed_8xi8x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg8_indexed_4xi16x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg8.indexed.nxv4i16.nxv4i16(i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP12]], <vscale x 4 x i16> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP14]], <vscale x 4 x i16> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X8]] [[TMP16]]
//
__epi_4xi16x8 test_vlseg8_indexed_4xi16x8(const signed short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg8_indexed_4xi16x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg8_indexed_4xi16x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg8.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE6:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE7:%.*]], i16* [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP12]], <vscale x 4 x i16> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP14]], <vscale x 4 x i16> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X8]] [[TMP16]]
//
__epi_4xi16x8 test_vlseg8_indexed_4xi16x8_mask(__epi_4xi16x8 arg_0, const signed short int*  arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg8_indexed_4xi16x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg8_indexed_2xi32x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg8.indexed.nxv2i32.nxv2i32(i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP12]], <vscale x 2 x i32> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP14]], <vscale x 2 x i32> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X8]] [[TMP16]]
//
__epi_2xi32x8 test_vlseg8_indexed_2xi32x8(const signed int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg8_indexed_2xi32x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg8_indexed_2xi32x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg8.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE6:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE7:%.*]], i32* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP12]], <vscale x 2 x i32> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP14]], <vscale x 2 x i32> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X8]] [[TMP16]]
//
__epi_2xi32x8 test_vlseg8_indexed_2xi32x8_mask(__epi_2xi32x8 arg_0, const signed int*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg8_indexed_2xi32x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg8_indexed_1xi64x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg8.indexed.nxv1i64.nxv1i64(i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP12]], <vscale x 1 x i64> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP14]], <vscale x 1 x i64> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X8]] [[TMP16]]
//
__epi_1xi64x8 test_vlseg8_indexed_1xi64x8(const signed long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg8_indexed_1xi64x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg8_indexed_1xi64x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg8.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE6:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE7:%.*]], i64* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP12]], <vscale x 1 x i64> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP14]], <vscale x 1 x i64> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X8]] [[TMP16]]
//
__epi_1xi64x8 test_vlseg8_indexed_1xi64x8_mask(__epi_1xi64x8 arg_0, const signed long int*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg8_indexed_1xi64x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg8_indexed_2xf32x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg8.indexed.nxv2f32.nxv2i32(float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP12]], <vscale x 2 x float> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP14]], <vscale x 2 x float> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X8]] [[TMP16]]
//
__epi_2xf32x8 test_vlseg8_indexed_2xf32x8(const float*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg8_indexed_2xf32x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg8_indexed_2xf32x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg8.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], <vscale x 2 x float> [[ARG_0_COERCE4:%.*]], <vscale x 2 x float> [[ARG_0_COERCE5:%.*]], <vscale x 2 x float> [[ARG_0_COERCE6:%.*]], <vscale x 2 x float> [[ARG_0_COERCE7:%.*]], float* [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP12]], <vscale x 2 x float> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP14]], <vscale x 2 x float> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X8]] [[TMP16]]
//
__epi_2xf32x8 test_vlseg8_indexed_2xf32x8_mask(__epi_2xf32x8 arg_0, const float*  arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg8_indexed_2xf32x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg8_indexed_1xf64x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg8.indexed.nxv1f64.nxv1i64(double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP12]], <vscale x 1 x double> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP14]], <vscale x 1 x double> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X8]] [[TMP16]]
//
__epi_1xf64x8 test_vlseg8_indexed_1xf64x8(const double*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg8_indexed_1xf64x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg8_indexed_1xf64x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg8.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], <vscale x 1 x double> [[ARG_0_COERCE4:%.*]], <vscale x 1 x double> [[ARG_0_COERCE5:%.*]], <vscale x 1 x double> [[ARG_0_COERCE6:%.*]], <vscale x 1 x double> [[ARG_0_COERCE7:%.*]], double* [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP12]], <vscale x 1 x double> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP14]], <vscale x 1 x double> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X8]] [[TMP16]]
//
__epi_1xf64x8 test_vlseg8_indexed_1xf64x8_mask(__epi_1xf64x8 arg_0, const double*  arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg8_indexed_1xf64x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg8_strided_8xi8x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg8.strided.nxv8i8(i8* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP12]], <vscale x 8 x i8> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP14]], <vscale x 8 x i8> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X8]] [[TMP16]]
//
__epi_8xi8x8 test_vlseg8_strided_8xi8x8(const signed char*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg8_strided_8xi8x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg8_strided_8xi8x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vlseg8.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE6:%.*]], <vscale x 8 x i8> [[ARG_0_COERCE7:%.*]], i8* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP4]], <vscale x 8 x i8> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP6]], <vscale x 8 x i8> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP8]], <vscale x 8 x i8> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP10]], <vscale x 8 x i8> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP12]], <vscale x 8 x i8> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_8XI8X8]] [[TMP14]], <vscale x 8 x i8> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X8]] [[TMP16]]
//
__epi_8xi8x8 test_vlseg8_strided_8xi8x8_mask(__epi_8xi8x8 arg_0, const signed char*  arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg8_strided_8xi8x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg8_strided_4xi16x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg8.strided.nxv4i16(i16* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP12]], <vscale x 4 x i16> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP14]], <vscale x 4 x i16> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X8]] [[TMP16]]
//
__epi_4xi16x8 test_vlseg8_strided_4xi16x8(const signed short int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg8_strided_4xi16x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg8_strided_4xi16x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vlseg8.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE6:%.*]], <vscale x 4 x i16> [[ARG_0_COERCE7:%.*]], i16* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP4]], <vscale x 4 x i16> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP6]], <vscale x 4 x i16> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP8]], <vscale x 4 x i16> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP10]], <vscale x 4 x i16> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP12]], <vscale x 4 x i16> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_4XI16X8]] [[TMP14]], <vscale x 4 x i16> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X8]] [[TMP16]]
//
__epi_4xi16x8 test_vlseg8_strided_4xi16x8_mask(__epi_4xi16x8 arg_0, const signed short int*  arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg8_strided_4xi16x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg8_strided_2xi32x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg8.strided.nxv2i32(i32* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP12]], <vscale x 2 x i32> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP14]], <vscale x 2 x i32> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X8]] [[TMP16]]
//
__epi_2xi32x8 test_vlseg8_strided_2xi32x8(const signed int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg8_strided_2xi32x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg8_strided_2xi32x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vlseg8.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE6:%.*]], <vscale x 2 x i32> [[ARG_0_COERCE7:%.*]], i32* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP4]], <vscale x 2 x i32> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP6]], <vscale x 2 x i32> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP8]], <vscale x 2 x i32> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP10]], <vscale x 2 x i32> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP12]], <vscale x 2 x i32> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_2XI32X8]] [[TMP14]], <vscale x 2 x i32> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X8]] [[TMP16]]
//
__epi_2xi32x8 test_vlseg8_strided_2xi32x8_mask(__epi_2xi32x8 arg_0, const signed int*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg8_strided_2xi32x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg8_strided_1xi64x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg8.strided.nxv1i64(i64* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP12]], <vscale x 1 x i64> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP14]], <vscale x 1 x i64> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X8]] [[TMP16]]
//
__epi_1xi64x8 test_vlseg8_strided_1xi64x8(const signed long int*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg8_strided_1xi64x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg8_strided_1xi64x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vlseg8.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE6:%.*]], <vscale x 1 x i64> [[ARG_0_COERCE7:%.*]], i64* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP4]], <vscale x 1 x i64> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP6]], <vscale x 1 x i64> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP8]], <vscale x 1 x i64> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP10]], <vscale x 1 x i64> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP12]], <vscale x 1 x i64> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_1XI64X8]] [[TMP14]], <vscale x 1 x i64> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X8]] [[TMP16]]
//
__epi_1xi64x8 test_vlseg8_strided_1xi64x8_mask(__epi_1xi64x8 arg_0, const signed long int*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg8_strided_1xi64x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg8_strided_2xf32x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg8.strided.nxv2f32(float* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP12]], <vscale x 2 x float> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP14]], <vscale x 2 x float> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X8]] [[TMP16]]
//
__epi_2xf32x8 test_vlseg8_strided_2xf32x8(const float*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg8_strided_2xf32x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg8_strided_2xf32x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vlseg8.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_0_COERCE0:%.*]], <vscale x 2 x float> [[ARG_0_COERCE1:%.*]], <vscale x 2 x float> [[ARG_0_COERCE2:%.*]], <vscale x 2 x float> [[ARG_0_COERCE3:%.*]], <vscale x 2 x float> [[ARG_0_COERCE4:%.*]], <vscale x 2 x float> [[ARG_0_COERCE5:%.*]], <vscale x 2 x float> [[ARG_0_COERCE6:%.*]], <vscale x 2 x float> [[ARG_0_COERCE7:%.*]], float* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP4]], <vscale x 2 x float> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP6]], <vscale x 2 x float> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP8]], <vscale x 2 x float> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP10]], <vscale x 2 x float> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP12]], <vscale x 2 x float> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_2XF32X8]] [[TMP14]], <vscale x 2 x float> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X8]] [[TMP16]]
//
__epi_2xf32x8 test_vlseg8_strided_2xf32x8_mask(__epi_2xf32x8 arg_0, const float*  arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg8_strided_2xf32x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vlseg8_strided_1xf64x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg8.strided.nxv1f64(double* [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP12]], <vscale x 1 x double> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP14]], <vscale x 1 x double> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X8]] [[TMP16]]
//
__epi_1xf64x8 test_vlseg8_strided_1xf64x8(const double*  arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vlseg8_strided_1xf64x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vlseg8_strided_1xf64x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vlseg8.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_0_COERCE0:%.*]], <vscale x 1 x double> [[ARG_0_COERCE1:%.*]], <vscale x 1 x double> [[ARG_0_COERCE2:%.*]], <vscale x 1 x double> [[ARG_0_COERCE3:%.*]], <vscale x 1 x double> [[ARG_0_COERCE4:%.*]], <vscale x 1 x double> [[ARG_0_COERCE5:%.*]], <vscale x 1 x double> [[ARG_0_COERCE6:%.*]], <vscale x 1 x double> [[ARG_0_COERCE7:%.*]], double* [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    [[TMP5:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 2
// CHECK-O2-NEXT:    [[TMP6:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP4]], <vscale x 1 x double> [[TMP5]], 2
// CHECK-O2-NEXT:    [[TMP7:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 3
// CHECK-O2-NEXT:    [[TMP8:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP6]], <vscale x 1 x double> [[TMP7]], 3
// CHECK-O2-NEXT:    [[TMP9:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 4
// CHECK-O2-NEXT:    [[TMP10:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP8]], <vscale x 1 x double> [[TMP9]], 4
// CHECK-O2-NEXT:    [[TMP11:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 5
// CHECK-O2-NEXT:    [[TMP12:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP10]], <vscale x 1 x double> [[TMP11]], 5
// CHECK-O2-NEXT:    [[TMP13:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 6
// CHECK-O2-NEXT:    [[TMP14:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP12]], <vscale x 1 x double> [[TMP13]], 6
// CHECK-O2-NEXT:    [[TMP15:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 7
// CHECK-O2-NEXT:    [[TMP16:%.*]] = insertvalue [[STRUCT___EPI_1XF64X8]] [[TMP14]], <vscale x 1 x double> [[TMP15]], 7
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X8]] [[TMP16]]
//
__epi_1xf64x8 test_vlseg8_strided_1xf64x8_mask(__epi_1xf64x8 arg_0, const double*  arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vlseg8_strided_1xf64x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmacc.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmacc_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmacc.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmacc_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmacc.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmacc_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmacc.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmacc_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmacc.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmacc_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmacc.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmacc_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmacc.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmacc_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmacc.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmacc_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmacc.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmacc_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmacc.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmacc_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmacc.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmacc_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmacc.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmacc_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmacc.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmacc_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmacc.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmacc_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmacc.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmacc_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmacc.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmacc_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmacc.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmacc_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmacc.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmacc_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmacc.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmacc_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmacc.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmacc_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmacc.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmacc_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmacc.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmacc_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmacc_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmacc.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmacc_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmacc_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmacc_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmacc.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmacc_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmacc_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadc_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmadc.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmadc_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmadc_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmadc_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmadc.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmadc_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmadc_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmadc_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmadc.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmadc_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmadc_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmadc_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmadc.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmadc_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmadc_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmadc_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmadc.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmadc_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmadc_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmadc_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmadc.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmadc_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmadc_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmadc_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmadc.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmadc_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmadc_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmadc_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmadc.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmadc_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmadc_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmadc_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmadc.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmadc_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmadc_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmadc_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmadc.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmadc_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmadc_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmadc_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmadc.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmadc_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmadc_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmadc_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmadc.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmadc_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmadc_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmadc_carry_in_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmadc.carry.in.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmadc_carry_in_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadc_carry_in_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadc_carry_in_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmadc.carry.in.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmadc_carry_in_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadc_carry_in_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadc_carry_in_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmadc.carry.in.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmadc_carry_in_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadc_carry_in_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadc_carry_in_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmadc.carry.in.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmadc_carry_in_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadc_carry_in_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadc_carry_in_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmadc.carry.in.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmadc_carry_in_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadc_carry_in_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadc_carry_in_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmadc.carry.in.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmadc_carry_in_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadc_carry_in_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadc_carry_in_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmadc.carry.in.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmadc_carry_in_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadc_carry_in_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadc_carry_in_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmadc.carry.in.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmadc_carry_in_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadc_carry_in_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadc_carry_in_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmadc.carry.in.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmadc_carry_in_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadc_carry_in_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadc_carry_in_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmadc.carry.in.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmadc_carry_in_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadc_carry_in_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadc_carry_in_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmadc.carry.in.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmadc_carry_in_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadc_carry_in_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadc_carry_in_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmadc.carry.in.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmadc_carry_in_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadc_carry_in_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmadd.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmadd_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmadd.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmadd_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmadd.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmadd_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmadd.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmadd_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmadd.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmadd_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmadd.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmadd_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmadd.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmadd_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmadd.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmadd_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmadd.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmadd_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmadd.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmadd_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmadd.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmadd_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmadd.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmadd_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmadd.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmadd_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmadd.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmadd_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmadd.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmadd_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmadd.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmadd_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmadd.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmadd_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmadd.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmadd_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmadd.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmadd_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmadd.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmadd_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmadd.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmadd_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmadd.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmadd_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmadd_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmadd.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmadd_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmadd_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmadd_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmadd.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmadd_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmadd_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmand_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmand.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmand_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmand_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmand_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmand.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmand_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmand_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmand_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmand.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmand_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmand_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmand_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmand.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmand_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmand_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmand_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmand.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmand_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmand_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmand_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmand.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmand_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmand_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmandnot_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmandnot.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmandnot_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmandnot_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmandnot_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmandnot.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmandnot_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmandnot_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmandnot_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmandnot.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmandnot_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmandnot_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmandnot_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmandnot.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmandnot_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmandnot_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmandnot_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmandnot.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmandnot_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmandnot_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmandnot_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmandnot.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmandnot_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmandnot_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmax.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmax_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmax.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmax_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmax.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmax_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmax.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmax_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmax.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmax_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmax.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmax_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmax.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmax_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmax.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmax_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmax.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmax_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmax.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmax_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmax.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmax_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmax.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmax_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmax.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmax_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmax.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmax_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmax.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmax_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmax.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmax_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmax.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmax_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmax.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmax_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmax.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmax_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmax.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmax_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmax.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmax_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmax.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmax_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmax_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmax.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmax_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmax_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmax_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmax.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmax_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmax_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmaxu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmaxu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmaxu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmaxu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmaxu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmaxu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmaxu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmaxu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmaxu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmaxu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmaxu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmaxu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmaxu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmaxu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmaxu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmaxu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmaxu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmaxu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmaxu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmaxu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmaxu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmaxu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmaxu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmaxu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmaxu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmaxu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmaxu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmaxu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmaxu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmaxu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmaxu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmaxu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmaxu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmaxu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmaxu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmaxu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmaxu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmaxu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmaxu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmaxu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmaxu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmaxu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmaxu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmaxu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmaxu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmaxu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmaxu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmaxu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmaxu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmaxu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmaxu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmaxu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmerge_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmerge.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmerge_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmerge.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmerge_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmerge.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmerge_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmerge.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmerge_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmerge.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmerge_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmerge.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmerge_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmerge.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmerge_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmerge.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmerge_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmerge.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmerge_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmerge.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmerge_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmerge.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmerge_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmerge_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmerge.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmerge_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmerge_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmfeq_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfeq.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfeq_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfeq_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfeq_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfeq.mask.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfeq_2xf32_mask(__epi_2xi1 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfeq_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfeq_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfeq.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfeq_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfeq_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfeq_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfeq.mask.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfeq_1xf64_mask(__epi_1xi1 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfeq_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfeq_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfeq.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfeq_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfeq_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfeq_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfeq.mask.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfeq_4xf32_mask(__epi_4xi1 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfeq_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfeq_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfeq.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfeq_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfeq_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfeq_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfeq.mask.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfeq_2xf64_mask(__epi_2xi1 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfeq_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfeq_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfeq.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfeq_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfeq_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfeq_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfeq.mask.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfeq_8xf32_mask(__epi_8xi1 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfeq_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfeq_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfeq.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfeq_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfeq_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfeq_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfeq.mask.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfeq_4xf64_mask(__epi_4xi1 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfeq_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfge_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfge.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfge_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfge_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfge_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfge.mask.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfge_2xf32_mask(__epi_2xi1 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfge_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfge_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfge.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfge_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfge_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfge_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfge.mask.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfge_1xf64_mask(__epi_1xi1 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfge_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfge_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfge.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfge_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfge_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfge_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfge.mask.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfge_4xf32_mask(__epi_4xi1 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfge_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfge_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfge.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfge_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfge_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfge_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfge.mask.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfge_2xf64_mask(__epi_2xi1 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfge_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfge_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfge.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfge_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfge_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfge_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfge.mask.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfge_8xf32_mask(__epi_8xi1 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfge_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfge_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfge.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfge_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfge_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfge_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfge.mask.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfge_4xf64_mask(__epi_4xi1 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfge_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfgt_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfgt.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfgt_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfgt_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfgt_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfgt.mask.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfgt_2xf32_mask(__epi_2xi1 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfgt_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfgt_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfgt.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfgt_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfgt_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfgt_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfgt.mask.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfgt_1xf64_mask(__epi_1xi1 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfgt_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfgt_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfgt.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfgt_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfgt_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfgt_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfgt.mask.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfgt_4xf32_mask(__epi_4xi1 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfgt_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfgt_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfgt.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfgt_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfgt_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfgt_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfgt.mask.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfgt_2xf64_mask(__epi_2xi1 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfgt_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfgt_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfgt.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfgt_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfgt_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfgt_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfgt.mask.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfgt_8xf32_mask(__epi_8xi1 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfgt_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfgt_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfgt.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfgt_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfgt_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfgt_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfgt.mask.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfgt_4xf64_mask(__epi_4xi1 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfgt_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfle_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfle.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfle_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfle_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfle_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfle.mask.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfle_2xf32_mask(__epi_2xi1 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfle_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfle_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfle.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfle_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfle_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfle_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfle.mask.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfle_1xf64_mask(__epi_1xi1 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfle_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfle_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfle.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfle_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfle_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfle_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfle.mask.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfle_4xf32_mask(__epi_4xi1 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfle_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfle_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfle.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfle_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfle_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfle_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfle.mask.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfle_2xf64_mask(__epi_2xi1 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfle_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfle_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfle.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfle_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfle_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfle_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfle.mask.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfle_8xf32_mask(__epi_8xi1 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfle_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfle_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfle.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfle_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfle_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfle_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfle.mask.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfle_4xf64_mask(__epi_4xi1 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfle_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmflt_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmflt.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmflt_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmflt_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmflt_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmflt.mask.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmflt_2xf32_mask(__epi_2xi1 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmflt_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmflt_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmflt.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmflt_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmflt_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmflt_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmflt.mask.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmflt_1xf64_mask(__epi_1xi1 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmflt_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmflt_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmflt.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmflt_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmflt_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmflt_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmflt.mask.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmflt_4xf32_mask(__epi_4xi1 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmflt_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmflt_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmflt.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmflt_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmflt_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmflt_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmflt.mask.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmflt_2xf64_mask(__epi_2xi1 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmflt_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmflt_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmflt.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmflt_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmflt_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmflt_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmflt.mask.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmflt_8xf32_mask(__epi_8xi1 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmflt_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmflt_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmflt.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmflt_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmflt_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmflt_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmflt.mask.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmflt_4xf64_mask(__epi_4xi1 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmflt_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfne_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfne.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfne_2xf32(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfne_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfne_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfne.mask.nxv2i1.nxv2f32.nxv2f32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfne_2xf32_mask(__epi_2xi1 arg_0, __epi_2xf32 arg_1, __epi_2xf32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfne_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfne_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfne.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfne_1xf64(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfne_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfne_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmfne.mask.nxv1i1.nxv1f64.nxv1f64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmfne_1xf64_mask(__epi_1xi1 arg_0, __epi_1xf64 arg_1, __epi_1xf64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfne_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfne_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfne.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfne_4xf32(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfne_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfne_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfne.mask.nxv4i1.nxv4f32.nxv4f32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfne_4xf32_mask(__epi_4xi1 arg_0, __epi_4xf32 arg_1, __epi_4xf32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfne_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfne_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfne.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfne_2xf64(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfne_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfne_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmfne.mask.nxv2i1.nxv2f64.nxv2f64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmfne_2xf64_mask(__epi_2xi1 arg_0, __epi_2xf64 arg_1, __epi_2xf64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfne_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfne_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfne.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfne_8xf32(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfne_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfne_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmfne.mask.nxv8i1.nxv8f32.nxv8f32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmfne_8xf32_mask(__epi_8xi1 arg_0, __epi_8xf32 arg_1, __epi_8xf32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfne_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmfne_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfne.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfne_4xf64(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmfne_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmfne_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmfne.mask.nxv4i1.nxv4f64.nxv4f64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmfne_4xf64_mask(__epi_4xi1 arg_0, __epi_4xf64 arg_1, __epi_4xf64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmfne_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmin.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmin_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmin.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmin_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmin.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmin_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmin.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmin_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmin.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmin_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmin.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmin_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmin.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmin_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmin.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmin_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmin.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmin_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmin.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmin_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmin.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmin_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmin.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmin_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmin.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmin_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmin.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmin_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmin.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmin_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmin.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmin_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmin.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmin_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmin.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmin_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmin.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmin_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmin.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmin_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmin.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmin_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmin.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmin_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmin_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmin.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmin_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmin_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmin_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmin.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmin_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmin_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vminu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vminu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vminu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vminu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vminu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vminu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vminu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vminu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vminu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vminu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vminu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vminu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vminu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vminu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vminu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vminu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vminu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vminu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vminu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vminu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vminu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vminu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vminu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vminu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vminu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vminu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vminu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vminu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vminu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vminu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vminu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vminu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vminu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vminu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vminu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vminu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vminu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vminu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vminu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vminu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vminu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vminu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vminu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vminu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vminu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vminu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vminu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vminu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vminu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vminu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vminu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vminu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmnand_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmnand.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmnand_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnand_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnand_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmnand.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmnand_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnand_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnand_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmnand.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmnand_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnand_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnand_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmnand.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmnand_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnand_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnand_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmnand.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmnand_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnand_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnand_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmnand.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmnand_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnand_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnor_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmnor.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmnor_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnor_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnor_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmnor.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmnor_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnor_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnor_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmnor.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmnor_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnor_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnor_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmnor.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmnor_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnor_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnor_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmnor.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmnor_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnor_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmnor_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmnor.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmnor_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmnor_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmor_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmor.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmor_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmor_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmor_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmor.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmor_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmor_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmor_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmor.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmor_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmor_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmor_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmor.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmor_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmor_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmor_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmor.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmor_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmor_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmor_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmor.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmor_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmor_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmornot_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmornot.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmornot_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmornot_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmornot_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmornot.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmornot_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmornot_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmornot_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmornot.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmornot_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmornot_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmornot_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmornot.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmornot_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmornot_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmornot_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmornot.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmornot_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmornot_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmornot_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmornot.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmornot_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmornot_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbc_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsbc.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsbc_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbc_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbc_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsbc.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsbc_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbc_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbc_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsbc.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsbc_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbc_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbc_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsbc.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsbc_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbc_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbc_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsbc.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsbc_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbc_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbc_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsbc.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsbc_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbc_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbc_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsbc.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsbc_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbc_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbc_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsbc.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsbc_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbc_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbc_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsbc.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsbc_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbc_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbc_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsbc.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsbc_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbc_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbc_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsbc.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsbc_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbc_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbc_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsbc.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsbc_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbc_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbc_borrow_in_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsbc.borrow.in.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsbc_borrow_in_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsbc_borrow_in_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsbc_borrow_in_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsbc.borrow.in.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsbc_borrow_in_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsbc_borrow_in_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsbc_borrow_in_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsbc.borrow.in.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsbc_borrow_in_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsbc_borrow_in_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsbc_borrow_in_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsbc.borrow.in.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsbc_borrow_in_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsbc_borrow_in_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsbc_borrow_in_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsbc.borrow.in.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsbc_borrow_in_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsbc_borrow_in_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsbc_borrow_in_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsbc.borrow.in.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsbc_borrow_in_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsbc_borrow_in_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsbc_borrow_in_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsbc.borrow.in.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsbc_borrow_in_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsbc_borrow_in_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsbc_borrow_in_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsbc.borrow.in.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsbc_borrow_in_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsbc_borrow_in_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsbc_borrow_in_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsbc.borrow.in.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsbc_borrow_in_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsbc_borrow_in_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsbc_borrow_in_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsbc.borrow.in.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsbc_borrow_in_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsbc_borrow_in_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsbc_borrow_in_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsbc.borrow.in.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsbc_borrow_in_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsbc_borrow_in_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsbc_borrow_in_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsbc.borrow.in.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsbc_borrow_in_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vmsbc_borrow_in_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vmsbf_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsbf.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsbf_8xi1(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsbf_8xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsbf_8xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsbf.mask.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsbf_8xi1_mask(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbf_8xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbf_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsbf.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsbf_4xi1(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsbf_4xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsbf_4xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsbf.mask.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsbf_4xi1_mask(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbf_4xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbf_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsbf.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsbf_2xi1(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsbf_2xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsbf_2xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsbf.mask.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsbf_2xi1_mask(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbf_2xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbf_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsbf.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsbf_1xi1(__epi_1xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsbf_1xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsbf_1xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsbf.mask.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsbf_1xi1_mask(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbf_1xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbf_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsbf.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsbf_16xi1(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsbf_16xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsbf_16xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsbf.mask.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsbf_16xi1_mask(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbf_16xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsbf_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsbf.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsbf_32xi1(__epi_32xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsbf_32xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsbf_32xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsbf.mask.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsbf_32xi1_mask(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsbf_32xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmseq.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmseq_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmseq.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmseq_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmseq.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmseq_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmseq.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmseq_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmseq.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmseq_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmseq.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmseq_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmseq.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmseq_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmseq.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmseq_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmseq.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmseq_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmseq.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmseq_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmseq.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmseq_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmseq.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmseq_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmseq.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmseq_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmseq.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmseq_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmseq.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmseq_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmseq.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmseq_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmseq.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmseq_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmseq.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmseq_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmseq.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmseq_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmseq.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmseq_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmseq.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmseq_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmseq.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmseq_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmseq_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmseq.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmseq_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmseq_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmseq_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmseq.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmseq_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmseq_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgt.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgt_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgt.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgt_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgt.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgt_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgt.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgt_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgt.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgt_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgt.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgt_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsgt.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsgt_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsgt.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsgt_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgt.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgt_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgt.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgt_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgt.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgt_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgt.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgt_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgt.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgt_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgt.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgt_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgt.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgt_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgt.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgt_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsgt.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsgt_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsgt.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsgt_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgt.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgt_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgt.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgt_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgt.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgt_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgt.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgt_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgt_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgt.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgt_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgt_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgt_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgt.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgt_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgt_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgtu.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgtu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgtu.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgtu_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgtu.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgtu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgtu.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgtu_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgtu.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgtu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgtu.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgtu_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsgtu.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsgtu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsgtu.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsgtu_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgtu.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgtu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgtu.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgtu_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgtu.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgtu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgtu.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgtu_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgtu.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgtu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgtu.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgtu_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgtu.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgtu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsgtu.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsgtu_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsgtu.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsgtu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsgtu.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsgtu_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgtu.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgtu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsgtu.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsgtu_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgtu.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgtu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsgtu.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsgtu_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsgtu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgtu.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgtu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsgtu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsgtu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsgtu.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsgtu_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsgtu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsif_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsif.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsif_8xi1(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsif_8xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsif_8xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsif.mask.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsif_8xi1_mask(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsif_8xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsif_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsif.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsif_4xi1(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsif_4xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsif_4xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsif.mask.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsif_4xi1_mask(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsif_4xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsif_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsif.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsif_2xi1(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsif_2xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsif_2xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsif.mask.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsif_2xi1_mask(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsif_2xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsif_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsif.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsif_1xi1(__epi_1xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsif_1xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsif_1xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsif.mask.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsif_1xi1_mask(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsif_1xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsif_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsif.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsif_16xi1(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsif_16xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsif_16xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsif.mask.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsif_16xi1_mask(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsif_16xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsif_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsif.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsif_32xi1(__epi_32xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsif_32xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsif_32xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsif.mask.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsif_32xi1_mask(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsif_32xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsle.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsle_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsle.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsle_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsle.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsle_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsle.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsle_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsle.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsle_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsle.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsle_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsle.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsle_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsle.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsle_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsle.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsle_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsle.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsle_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsle.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsle_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsle.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsle_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsle.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsle_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsle.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsle_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsle.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsle_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsle.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsle_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsle.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsle_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsle.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsle_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsle.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsle_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsle.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsle_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsle.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsle_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsle.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsle_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsle_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsle.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsle_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsle_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsle_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsle.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsle_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsle_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsleu.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsleu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsleu.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsleu_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsleu.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsleu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsleu.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsleu_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsleu.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsleu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsleu.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsleu_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsleu.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsleu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsleu.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsleu_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsleu.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsleu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsleu.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsleu_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsleu.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsleu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsleu.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsleu_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsleu.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsleu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsleu.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsleu_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsleu.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsleu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsleu.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsleu_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsleu.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsleu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsleu.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsleu_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsleu.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsleu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsleu.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsleu_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsleu.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsleu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsleu.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsleu_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsleu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsleu.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsleu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsleu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsleu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsleu.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsleu_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsleu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmslt.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmslt_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmslt.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmslt_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmslt.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmslt_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmslt.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmslt_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmslt.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmslt_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmslt.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmslt_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmslt.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmslt_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmslt.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmslt_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmslt.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmslt_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmslt.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmslt_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmslt.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmslt_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmslt.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmslt_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmslt.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmslt_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmslt.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmslt_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmslt.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmslt_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmslt.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmslt_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmslt.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmslt_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmslt.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmslt_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmslt.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmslt_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmslt.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmslt_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmslt.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmslt_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmslt.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmslt_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmslt_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmslt.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmslt_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmslt_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmslt_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmslt.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmslt_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmslt_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsltu.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsltu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsltu.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsltu_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsltu.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsltu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsltu.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsltu_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsltu.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsltu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsltu.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsltu_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsltu.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsltu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsltu.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsltu_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsltu.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsltu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsltu.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsltu_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsltu.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsltu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsltu.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsltu_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsltu.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsltu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsltu.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsltu_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsltu.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsltu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsltu.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsltu_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsltu.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsltu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsltu.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsltu_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsltu.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsltu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsltu.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsltu_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsltu.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsltu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsltu.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsltu_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsltu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsltu.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsltu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsltu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsltu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsltu.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsltu_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsltu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsne.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsne_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsne.mask.nxv8i1.nxv8i8.nxv8i8(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsne_8xi8_mask(__epi_8xi1 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsne.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsne_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsne.mask.nxv4i1.nxv4i16.nxv4i16(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsne_4xi16_mask(__epi_4xi1 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsne.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsne_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsne.mask.nxv2i1.nxv2i32.nxv2i32(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsne_2xi32_mask(__epi_2xi1 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsne.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsne_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsne.mask.nxv1i1.nxv1i64.nxv1i64(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsne_1xi64_mask(__epi_1xi1 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsne.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsne_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsne.mask.nxv16i1.nxv16i8.nxv16i8(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsne_16xi8_mask(__epi_16xi1 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsne.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsne_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsne.mask.nxv8i1.nxv8i16.nxv8i16(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsne_8xi16_mask(__epi_8xi1 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsne.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsne_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsne.mask.nxv4i1.nxv4i32.nxv4i32(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsne_4xi32_mask(__epi_4xi1 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsne.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsne_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsne.mask.nxv2i1.nxv2i64.nxv2i64(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsne_2xi64_mask(__epi_2xi1 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsne.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsne_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsne.mask.nxv32i1.nxv32i8.nxv32i8(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsne_32xi8_mask(__epi_32xi1 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsne.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsne_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsne.mask.nxv16i1.nxv16i16.nxv16i16(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsne_16xi16_mask(__epi_16xi1 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsne.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsne_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsne.mask.nxv8i1.nxv8i32.nxv8i32(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsne_8xi32_mask(__epi_8xi1 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsne_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsne.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsne_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsne_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsne_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsne.mask.nxv4i1.nxv4i64.nxv4i64(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsne_4xi64_mask(__epi_4xi1 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmsne_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmsof_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsof.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsof_8xi1(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsof_8xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsof_8xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmsof.mask.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmsof_8xi1_mask(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsof_8xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsof_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsof.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsof_4xi1(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsof_4xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsof_4xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmsof.mask.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmsof_4xi1_mask(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsof_4xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsof_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsof.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsof_2xi1(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsof_2xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsof_2xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmsof.mask.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmsof_2xi1_mask(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsof_2xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsof_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsof.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsof_1xi1(__epi_1xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsof_1xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsof_1xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmsof.mask.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmsof_1xi1_mask(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsof_1xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsof_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsof.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsof_16xi1(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsof_16xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsof_16xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmsof.mask.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmsof_16xi1_mask(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsof_16xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmsof_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsof.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsof_32xi1(__epi_32xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmsof_32xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmsof_32xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmsof.mask.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmsof_32xi1_mask(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmsof_32xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmul.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmul_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmul.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmul_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmul.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmul_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmul.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmul_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmul.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmul_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmul.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmul_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmul.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmul_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmul.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmul_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmul.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmul_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmul.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmul_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmul.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmul_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmul.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmul_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmul.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmul_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmul.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmul_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmul.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmul_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmul.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmul_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmul.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmul_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmul.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmul_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmul.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmul_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmul.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmul_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmul.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmul_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmul.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmul_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmul_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmul.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmul_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmul_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmul_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmul.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmul_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmul_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmulh.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmulh_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmulh.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmulh_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmulh.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmulh_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmulh.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmulh_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmulh.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmulh_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmulh.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmulh_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmulh.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmulh_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmulh.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmulh_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmulh.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmulh_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmulh.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmulh_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmulh.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmulh_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmulh.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmulh_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmulh.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmulh_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmulh.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmulh_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmulh.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmulh_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmulh.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmulh_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmulh.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmulh_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmulh.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmulh_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmulh.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmulh_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmulh.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmulh_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmulh.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmulh_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmulh.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmulh_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulh_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmulh.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmulh_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulh_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulh_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmulh.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmulh_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulh_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmulhsu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmulhsu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmulhsu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmulhsu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmulhsu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmulhsu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmulhsu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmulhsu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmulhsu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmulhsu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmulhsu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmulhsu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmulhsu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmulhsu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmulhsu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmulhsu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmulhsu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmulhsu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmulhsu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmulhsu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmulhsu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmulhsu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmulhsu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmulhsu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmulhsu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmulhsu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmulhsu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmulhsu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmulhsu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmulhsu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmulhsu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmulhsu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmulhsu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmulhsu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmulhsu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmulhsu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmulhsu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmulhsu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmulhsu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmulhsu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmulhsu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmulhsu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmulhsu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmulhsu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhsu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmulhsu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmulhsu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhsu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhsu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmulhsu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmulhsu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhsu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmulhu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmulhu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmulhu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmulhu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmulhu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmulhu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmulhu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmulhu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmulhu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmulhu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmulhu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmulhu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmulhu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmulhu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmulhu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmulhu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmulhu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmulhu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmulhu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmulhu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmulhu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmulhu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmulhu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmulhu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmulhu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmulhu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmulhu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmulhu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmulhu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmulhu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmulhu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmulhu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmulhu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmulhu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmulhu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmulhu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmulhu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmulhu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmulhu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmulhu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmulhu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmulhu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmulhu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmulhu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmulhu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmulhu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmulhu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmulhu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmulhu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmulhu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmulhu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vmulhu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vmv_s_x_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmv.s.x.nxv8i8.i8(<vscale x 8 x i8> [[ARG_0:%.*]], i8 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmv_s_x_8xi8(__epi_8xi8 arg_0, signed char arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmv_s_x_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmv_s_x_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmv.s.x.nxv4i16.i16(<vscale x 4 x i16> [[ARG_0:%.*]], i16 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmv_s_x_4xi16(__epi_4xi16 arg_0, signed short int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmv_s_x_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmv_s_x_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmv.s.x.nxv2i32.i32(<vscale x 2 x i32> [[ARG_0:%.*]], i32 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmv_s_x_2xi32(__epi_2xi32 arg_0, signed int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmv_s_x_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmv_s_x_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmv.s.x.nxv1i64.i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmv_s_x_1xi64(__epi_1xi64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmv_s_x_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmv_s_x_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmv.s.x.nxv16i8.i8(<vscale x 16 x i8> [[ARG_0:%.*]], i8 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmv_s_x_16xi8(__epi_16xi8 arg_0, signed char arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmv_s_x_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmv_s_x_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmv.s.x.nxv8i16.i16(<vscale x 8 x i16> [[ARG_0:%.*]], i16 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmv_s_x_8xi16(__epi_8xi16 arg_0, signed short int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmv_s_x_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmv_s_x_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmv.s.x.nxv4i32.i32(<vscale x 4 x i32> [[ARG_0:%.*]], i32 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmv_s_x_4xi32(__epi_4xi32 arg_0, signed int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmv_s_x_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmv_s_x_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmv.s.x.nxv2i64.i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmv_s_x_2xi64(__epi_2xi64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmv_s_x_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmv_s_x_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmv.s.x.nxv32i8.i8(<vscale x 32 x i8> [[ARG_0:%.*]], i8 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmv_s_x_32xi8(__epi_32xi8 arg_0, signed char arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmv_s_x_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmv_s_x_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmv.s.x.nxv16i16.i16(<vscale x 16 x i16> [[ARG_0:%.*]], i16 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmv_s_x_16xi16(__epi_16xi16 arg_0, signed short int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmv_s_x_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmv_s_x_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmv.s.x.nxv8i32.i32(<vscale x 8 x i32> [[ARG_0:%.*]], i32 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmv_s_x_8xi32(__epi_8xi32 arg_0, signed int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmv_s_x_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmv_s_x_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmv.s.x.nxv4i64.i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmv_s_x_4xi64(__epi_4xi64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmv_s_x_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmv_v_x_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vmv.v.x.nxv8i8.i8(i8 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vmv_v_x_8xi8(signed char arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmv_v_x_8xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmv_v_x_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vmv.v.x.nxv4i16.i16(i16 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vmv_v_x_4xi16(signed short int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmv_v_x_4xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmv_v_x_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vmv.v.x.nxv2i32.i32(i32 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vmv_v_x_2xi32(signed int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmv_v_x_2xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmv_v_x_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vmv.v.x.nxv1i64.i64(i64 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vmv_v_x_1xi64(signed long int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmv_v_x_1xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmv_v_x_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vmv.v.x.nxv16i8.i8(i8 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vmv_v_x_16xi8(signed char arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmv_v_x_16xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmv_v_x_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vmv.v.x.nxv8i16.i16(i16 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vmv_v_x_8xi16(signed short int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmv_v_x_8xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmv_v_x_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vmv.v.x.nxv4i32.i32(i32 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vmv_v_x_4xi32(signed int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmv_v_x_4xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmv_v_x_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vmv.v.x.nxv2i64.i64(i64 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vmv_v_x_2xi64(signed long int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmv_v_x_2xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmv_v_x_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vmv.v.x.nxv32i8.i8(i8 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vmv_v_x_32xi8(signed char arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmv_v_x_32xi8(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmv_v_x_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vmv.v.x.nxv16i16.i16(i16 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vmv_v_x_16xi16(signed short int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmv_v_x_16xi16(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmv_v_x_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vmv.v.x.nxv8i32.i32(i32 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vmv_v_x_8xi32(signed int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmv_v_x_8xi32(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmv_v_x_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vmv.v.x.nxv4i64.i64(i64 [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vmv_v_x_4xi64(signed long int arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vmv_v_x_4xi64(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vmv_x_s_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i8 @llvm.epi.vmv.x.s.i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret i8 [[TMP0]]
//
signed char test_vmv_x_s_8xi8(__epi_8xi8 arg_0)
{
    return __builtin_epi_vmv_x_s_8xi8(arg_0);
}

// CHECK-O2-LABEL: @test_vmv_x_s_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i16 @llvm.epi.vmv.x.s.i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret i16 [[TMP0]]
//
signed short int test_vmv_x_s_4xi16(__epi_4xi16 arg_0)
{
    return __builtin_epi_vmv_x_s_4xi16(arg_0);
}

// CHECK-O2-LABEL: @test_vmv_x_s_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.epi.vmv.x.s.i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret i32 [[TMP0]]
//
signed int test_vmv_x_s_2xi32(__epi_2xi32 arg_0)
{
    return __builtin_epi_vmv_x_s_2xi32(arg_0);
}

// CHECK-O2-LABEL: @test_vmv_x_s_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmv.x.s.i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmv_x_s_1xi64(__epi_1xi64 arg_0)
{
    return __builtin_epi_vmv_x_s_1xi64(arg_0);
}

// CHECK-O2-LABEL: @test_vmv_x_s_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i8 @llvm.epi.vmv.x.s.i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret i8 [[TMP0]]
//
signed char test_vmv_x_s_16xi8(__epi_16xi8 arg_0)
{
    return __builtin_epi_vmv_x_s_16xi8(arg_0);
}

// CHECK-O2-LABEL: @test_vmv_x_s_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i16 @llvm.epi.vmv.x.s.i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret i16 [[TMP0]]
//
signed short int test_vmv_x_s_8xi16(__epi_8xi16 arg_0)
{
    return __builtin_epi_vmv_x_s_8xi16(arg_0);
}

// CHECK-O2-LABEL: @test_vmv_x_s_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.epi.vmv.x.s.i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret i32 [[TMP0]]
//
signed int test_vmv_x_s_4xi32(__epi_4xi32 arg_0)
{
    return __builtin_epi_vmv_x_s_4xi32(arg_0);
}

// CHECK-O2-LABEL: @test_vmv_x_s_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmv.x.s.i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmv_x_s_2xi64(__epi_2xi64 arg_0)
{
    return __builtin_epi_vmv_x_s_2xi64(arg_0);
}

// CHECK-O2-LABEL: @test_vmv_x_s_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i8 @llvm.epi.vmv.x.s.i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret i8 [[TMP0]]
//
signed char test_vmv_x_s_32xi8(__epi_32xi8 arg_0)
{
    return __builtin_epi_vmv_x_s_32xi8(arg_0);
}

// CHECK-O2-LABEL: @test_vmv_x_s_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i16 @llvm.epi.vmv.x.s.i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret i16 [[TMP0]]
//
signed short int test_vmv_x_s_16xi16(__epi_16xi16 arg_0)
{
    return __builtin_epi_vmv_x_s_16xi16(arg_0);
}

// CHECK-O2-LABEL: @test_vmv_x_s_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.epi.vmv.x.s.i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret i32 [[TMP0]]
//
signed int test_vmv_x_s_8xi32(__epi_8xi32 arg_0)
{
    return __builtin_epi_vmv_x_s_8xi32(arg_0);
}

// CHECK-O2-LABEL: @test_vmv_x_s_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vmv.x.s.i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vmv_x_s_4xi64(__epi_4xi64 arg_0)
{
    return __builtin_epi_vmv_x_s_4xi64(arg_0);
}

// CHECK-O2-LABEL: @test_vmxnor_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmxnor.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmxnor_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxnor_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxnor_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmxnor.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmxnor_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxnor_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxnor_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmxnor.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmxnor_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxnor_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxnor_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmxnor.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmxnor_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxnor_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxnor_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmxnor.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmxnor_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxnor_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxnor_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmxnor.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmxnor_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxnor_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxor_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i1> @llvm.epi.vmxor.nxv8i1.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i1> [[TMP0]]
//
__epi_8xi1 test_vmxor_8xi1(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxor_8xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxor_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i1> @llvm.epi.vmxor.nxv4i1.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i1> [[TMP0]]
//
__epi_4xi1 test_vmxor_4xi1(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxor_4xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxor_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i1> @llvm.epi.vmxor.nxv2i1.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i1> [[TMP0]]
//
__epi_2xi1 test_vmxor_2xi1(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxor_2xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxor_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i1> @llvm.epi.vmxor.nxv1i1.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i1> [[TMP0]]
//
__epi_1xi1 test_vmxor_1xi1(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxor_1xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxor_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i1> @llvm.epi.vmxor.nxv16i1.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i1> [[TMP0]]
//
__epi_16xi1 test_vmxor_16xi1(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxor_16xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vmxor_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i1> @llvm.epi.vmxor.nxv32i1.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i1> [[TMP0]]
//
__epi_32xi1 test_vmxor_32xi1(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vmxor_32xi1(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnmsac_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vnmsac.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vnmsac_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsac_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsac_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vnmsac.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vnmsac_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsac_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsac_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vnmsac.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vnmsac_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsac_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsac_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vnmsac.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vnmsac_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsac_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsac_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnmsac.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vnmsac_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsac_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsac_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnmsac.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vnmsac_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsac_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsac_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vnmsac.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vnmsac_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsac_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsac_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vnmsac.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vnmsac_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsac_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsac_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vnmsac.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vnmsac_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsac_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsac_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vnmsac.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vnmsac_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsac_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsac_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vnmsac.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vnmsac_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsac_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsac_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vnmsac.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vnmsac_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsac_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsac_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vnmsac.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vnmsac_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsac_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsac_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vnmsac.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vnmsac_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsac_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsac_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vnmsac.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vnmsac_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsac_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsac_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vnmsac.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vnmsac_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsac_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsac_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vnmsac.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vnmsac_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsac_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsac_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vnmsac.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vnmsac_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsac_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsac_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vnmsac.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vnmsac_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsac_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsac_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vnmsac.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vnmsac_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsac_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsac_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vnmsac.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vnmsac_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsac_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsac_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vnmsac.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vnmsac_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsac_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsac_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vnmsac.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vnmsac_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsac_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsac_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vnmsac.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vnmsac_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsac_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsub_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vnmsub.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vnmsub_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsub_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsub_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vnmsub.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vnmsub_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsub_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsub_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vnmsub.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vnmsub_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsub_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsub_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vnmsub.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vnmsub_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsub_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsub_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnmsub.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vnmsub_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsub_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsub_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnmsub.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vnmsub_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsub_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsub_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vnmsub.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vnmsub_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsub_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsub_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vnmsub.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vnmsub_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsub_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsub_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vnmsub.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vnmsub_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsub_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsub_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vnmsub.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vnmsub_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsub_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsub_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vnmsub.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vnmsub_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsub_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsub_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vnmsub.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vnmsub_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsub_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsub_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vnmsub.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vnmsub_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsub_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsub_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vnmsub.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vnmsub_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsub_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsub_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vnmsub.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vnmsub_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsub_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsub_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vnmsub.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vnmsub_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsub_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsub_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vnmsub.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vnmsub_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsub_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsub_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vnmsub.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vnmsub_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsub_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsub_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vnmsub.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vnmsub_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsub_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsub_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vnmsub.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vnmsub_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsub_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsub_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vnmsub.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vnmsub_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsub_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsub_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vnmsub.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vnmsub_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsub_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnmsub_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vnmsub.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vnmsub_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vnmsub_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vnmsub_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vnmsub.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vnmsub_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnmsub_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vnsra.nxv8i8.nxv8i16.nxv8i8(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vnsra_8xi8(__epi_8xi16 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vnsra.mask.nxv8i8.nxv8i16.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vnsra_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi16 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vnsra.nxv4i16.nxv4i32.nxv4i16(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vnsra_4xi16(__epi_4xi32 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vnsra.mask.nxv4i16.nxv4i32.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vnsra_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi32 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnsra.nxv2i32.nxv2i64.nxv2i32(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vnsra_2xi32(__epi_2xi64 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnsra.mask.nxv2i32.nxv2i64.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vnsra_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi64 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vnsra.nxv16i8.nxv16i16.nxv16i8(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vnsra_16xi8(__epi_16xi16 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vnsra.mask.nxv16i8.nxv16i16.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vnsra_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi16 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vnsra.nxv8i16.nxv8i32.nxv8i16(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vnsra_8xi16(__epi_8xi32 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vnsra.mask.nxv8i16.nxv8i32.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vnsra_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi32 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vnsra.nxv4i32.nxv4i64.nxv4i32(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vnsra_4xi32(__epi_4xi64 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vnsra.mask.nxv4i32.nxv4i64.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vnsra_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi64 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vnsra.nxv32i8.nxv32i16.nxv32i8(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vnsra_32xi8(__epi_32xi16 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vnsra.mask.nxv32i8.nxv32i16.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vnsra_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi16 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vnsra.nxv16i16.nxv16i32.nxv16i16(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vnsra_16xi16(__epi_16xi32 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vnsra.mask.nxv16i16.nxv16i32.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vnsra_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi32 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsra_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vnsra.nxv8i32.nxv8i64.nxv8i32(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vnsra_8xi32(__epi_8xi64 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsra_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsra_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vnsra.mask.nxv8i32.nxv8i64.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vnsra_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi64 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsra_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vnsrl.nxv8i8.nxv8i16.nxv8i8(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vnsrl_8xi8(__epi_8xi16 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vnsrl.mask.nxv8i8.nxv8i16.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vnsrl_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi16 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vnsrl.nxv4i16.nxv4i32.nxv4i16(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vnsrl_4xi16(__epi_4xi32 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vnsrl.mask.nxv4i16.nxv4i32.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vnsrl_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi32 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnsrl.nxv2i32.nxv2i64.nxv2i32(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vnsrl_2xi32(__epi_2xi64 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vnsrl.mask.nxv2i32.nxv2i64.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vnsrl_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi64 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vnsrl.nxv16i8.nxv16i16.nxv16i8(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vnsrl_16xi8(__epi_16xi16 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vnsrl.mask.nxv16i8.nxv16i16.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vnsrl_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi16 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vnsrl.nxv8i16.nxv8i32.nxv8i16(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vnsrl_8xi16(__epi_8xi32 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vnsrl.mask.nxv8i16.nxv8i32.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vnsrl_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi32 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vnsrl.nxv4i32.nxv4i64.nxv4i32(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vnsrl_4xi32(__epi_4xi64 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vnsrl.mask.nxv4i32.nxv4i64.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vnsrl_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi64 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vnsrl.nxv32i8.nxv32i16.nxv32i8(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vnsrl_32xi8(__epi_32xi16 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vnsrl.mask.nxv32i8.nxv32i16.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vnsrl_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi16 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vnsrl.nxv16i16.nxv16i32.nxv16i16(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vnsrl_16xi16(__epi_16xi32 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vnsrl.mask.nxv16i16.nxv16i32.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vnsrl_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi32 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vnsrl_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vnsrl.nxv8i32.nxv8i64.nxv8i32(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vnsrl_8xi32(__epi_8xi64 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vnsrl_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vnsrl_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vnsrl.mask.nxv8i32.nxv8i64.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vnsrl_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi64 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vnsrl_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vor.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vor_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vor.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vor_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vor.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vor_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vor.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vor_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vor.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vor_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vor.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vor_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vor.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vor_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vor.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vor_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vor.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vor_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vor.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vor_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vor.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vor_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vor.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vor_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vor.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vor_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vor.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vor_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vor.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vor_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vor.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vor_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vor.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vor_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vor.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vor_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vor.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vor_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vor.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vor_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vor.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vor_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vor.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vor_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vor_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vor.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vor_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vor_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vor_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vor.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vor_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vor_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vpopc_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vpopc.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vpopc_8xi1(__epi_8xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vpopc_8xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vpopc_8xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vpopc.mask.nxv8i1(<vscale x 8 x i1> [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vpopc_8xi1_mask(__epi_8xi1 arg_0, __epi_8xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vpopc_8xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vpopc_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vpopc.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vpopc_4xi1(__epi_4xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vpopc_4xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vpopc_4xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vpopc.mask.nxv4i1(<vscale x 4 x i1> [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vpopc_4xi1_mask(__epi_4xi1 arg_0, __epi_4xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vpopc_4xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vpopc_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vpopc.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vpopc_2xi1(__epi_2xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vpopc_2xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vpopc_2xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vpopc.mask.nxv2i1(<vscale x 2 x i1> [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vpopc_2xi1_mask(__epi_2xi1 arg_0, __epi_2xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vpopc_2xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vpopc_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vpopc.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vpopc_1xi1(__epi_1xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vpopc_1xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vpopc_1xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vpopc.mask.nxv1i1(<vscale x 1 x i1> [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vpopc_1xi1_mask(__epi_1xi1 arg_0, __epi_1xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vpopc_1xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vpopc_16xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vpopc.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vpopc_16xi1(__epi_16xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vpopc_16xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vpopc_16xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vpopc.mask.nxv16i1(<vscale x 16 x i1> [[ARG_0:%.*]], <vscale x 16 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vpopc_16xi1_mask(__epi_16xi1 arg_0, __epi_16xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vpopc_16xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vpopc_32xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vpopc.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], i64 [[ARG_1:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vpopc_32xi1(__epi_32xi1 arg_0, unsigned long int arg_1)
{
    return __builtin_epi_vpopc_32xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vpopc_32xi1_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.epi.vpopc.mask.nxv32i1(<vscale x 32 x i1> [[ARG_0:%.*]], <vscale x 32 x i1> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret i64 [[TMP0]]
//
signed long int test_vpopc_32xi1_mask(__epi_32xi1 arg_0, __epi_32xi1 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vpopc_32xi1_mask(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredand.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredand_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredand.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredand_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredand.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredand_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredand.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredand_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredand.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredand_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredand.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredand_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredand.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredand_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredand.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredand_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredand.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredand_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredand.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredand_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredand.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredand_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredand.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredand_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredand.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredand_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredand.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredand_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredand.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredand_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredand.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredand_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredand.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredand_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredand.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredand_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredand.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredand_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredand.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredand_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredand.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredand_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredand.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredand_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredand_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredand.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredand_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredand_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredand_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredand.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredand_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredand_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredmax.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredmax_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredmax.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredmax_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredmax.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredmax_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredmax.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredmax_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredmax.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredmax_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredmax.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredmax_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredmax.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredmax_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredmax.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredmax_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredmax.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredmax_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredmax.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredmax_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredmax.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredmax_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredmax.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredmax_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredmax.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredmax_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredmax.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredmax_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredmax.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredmax_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredmax.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredmax_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredmax.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredmax_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredmax.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredmax_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredmax.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredmax_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredmax.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredmax_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredmax.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredmax_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredmax.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredmax_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmax_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredmax.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredmax_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmax_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmax_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredmax.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredmax_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmax_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredmaxu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredmaxu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredmaxu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredmaxu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredmaxu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredmaxu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredmaxu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredmaxu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredmaxu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredmaxu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredmaxu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredmaxu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredmaxu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredmaxu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredmaxu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredmaxu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredmaxu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredmaxu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredmaxu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredmaxu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredmaxu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredmaxu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredmaxu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredmaxu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredmaxu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredmaxu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredmaxu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredmaxu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredmaxu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredmaxu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredmaxu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredmaxu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredmaxu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredmaxu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredmaxu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredmaxu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredmaxu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredmaxu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredmaxu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredmaxu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredmaxu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredmaxu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredmaxu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredmaxu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmaxu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredmaxu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredmaxu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmaxu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmaxu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredmaxu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredmaxu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmaxu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredmin.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredmin_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredmin.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredmin_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredmin.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredmin_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredmin.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredmin_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredmin.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredmin_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredmin.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredmin_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredmin.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredmin_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredmin.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredmin_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredmin.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredmin_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredmin.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredmin_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredmin.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredmin_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredmin.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredmin_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredmin.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredmin_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredmin.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredmin_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredmin.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredmin_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredmin.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredmin_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredmin.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredmin_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredmin.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredmin_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredmin.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredmin_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredmin.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredmin_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredmin.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredmin_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredmin.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredmin_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredmin_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredmin.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredmin_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredmin_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredmin_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredmin.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredmin_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredmin_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredminu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredminu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredminu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredminu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredminu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredminu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredminu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredminu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredminu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredminu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredminu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredminu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredminu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredminu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredminu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredminu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredminu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredminu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredminu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredminu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredminu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredminu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredminu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredminu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredminu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredminu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredminu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredminu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredminu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredminu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredminu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredminu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredminu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredminu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredminu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredminu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredminu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredminu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredminu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredminu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredminu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredminu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredminu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredminu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredminu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredminu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredminu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredminu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredminu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredminu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredminu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredminu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredor.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredor_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredor.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredor_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredor.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredor_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredor.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredor_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredor.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredor_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredor.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredor_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredor.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredor_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredor.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredor_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredor.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredor_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredor.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredor_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredor.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredor_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredor.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredor_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredor.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredor_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredor.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredor_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredor.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredor_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredor.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredor_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredor.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredor_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredor.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredor_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredor.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredor_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredor.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredor_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredor.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredor_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredor.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredor_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredor_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredor.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredor_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredor_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredor_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredor.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredor_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredor_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredsum.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredsum_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredsum.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredsum_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredsum.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredsum_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredsum.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredsum_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredsum.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredsum_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredsum.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredsum_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredsum.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredsum_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredsum.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredsum_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredsum.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredsum_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredsum.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredsum_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredsum.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredsum_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredsum.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredsum_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredsum.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredsum_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredsum.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredsum_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredsum.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredsum_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredsum.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredsum_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredsum.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredsum_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredsum.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredsum_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredsum.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredsum_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredsum.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredsum_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredsum.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredsum_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredsum.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredsum_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredsum_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredsum.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredsum_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredsum_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredsum_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredsum.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredsum_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredsum_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredxor.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredxor_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vredxor.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vredxor_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredxor.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredxor_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vredxor.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vredxor_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredxor.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredxor_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vredxor.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vredxor_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredxor.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredxor_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vredxor.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vredxor_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredxor.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredxor_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vredxor.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vredxor_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredxor.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredxor_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vredxor.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vredxor_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredxor.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredxor_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vredxor.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vredxor_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredxor.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredxor_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vredxor.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vredxor_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredxor.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredxor_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vredxor.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vredxor_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredxor.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredxor_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vredxor.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vredxor_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredxor.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredxor_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vredxor.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vredxor_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vredxor_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredxor.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredxor_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vredxor_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vredxor_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vredxor.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vredxor_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vredxor_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrem.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vrem_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrem.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vrem_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrem.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vrem_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrem.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vrem_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrem.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vrem_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrem.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vrem_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrem.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vrem_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrem.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vrem_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrem.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vrem_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrem.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vrem_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrem.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vrem_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrem.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vrem_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrem.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vrem_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrem.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vrem_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrem.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vrem_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrem.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vrem_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrem.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vrem_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrem.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vrem_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrem.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vrem_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrem.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vrem_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrem.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vrem_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrem.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vrem_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrem_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrem.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vrem_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrem_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrem_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrem.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vrem_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrem_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vremu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vremu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vremu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vremu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vremu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vremu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vremu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vremu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vremu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vremu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vremu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vremu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vremu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vremu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vremu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vremu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vremu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vremu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vremu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vremu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vremu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vremu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vremu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vremu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vremu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vremu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vremu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vremu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vremu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vremu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vremu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vremu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vremu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vremu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vremu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vremu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vremu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vremu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vremu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vremu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vremu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vremu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vremu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vremu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vremu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vremu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vremu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vremu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vremu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vremu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vremu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vremu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrgather.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vrgather_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrgather.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vrgather_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrgather.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vrgather_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrgather.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vrgather_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrgather.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vrgather_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrgather.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vrgather_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrgather.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vrgather_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrgather.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vrgather_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vrgather.nxv2f32.nxv2i32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vrgather_2xf32(__epi_2xf32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vrgather.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vrgather_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vrgather.nxv1f64.nxv1i64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vrgather_1xf64(__epi_1xf64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vrgather.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vrgather_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrgather.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vrgather_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrgather.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vrgather_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrgather.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vrgather_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrgather.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vrgather_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrgather.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vrgather_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrgather.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vrgather_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrgather.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vrgather_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrgather.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vrgather_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vrgather.nxv4f32.nxv4i32(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vrgather_4xf32(__epi_4xf32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vrgather.mask.nxv4f32.nxv4i32.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vrgather_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vrgather.nxv2f64.nxv2i64(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vrgather_2xf64(__epi_2xf64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vrgather.mask.nxv2f64.nxv2i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vrgather_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrgather.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vrgather_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrgather.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vrgather_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrgather.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vrgather_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrgather.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vrgather_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrgather.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vrgather_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrgather.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vrgather_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrgather.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vrgather_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrgather.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vrgather_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vrgather.nxv8f32.nxv8i32(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vrgather_8xf32(__epi_8xf32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vrgather.mask.nxv8f32.nxv8i32.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vrgather_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrgather_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vrgather.nxv4f64.nxv4i64(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vrgather_4xf64(__epi_4xf64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrgather_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrgather_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vrgather.mask.nxv4f64.nxv4i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vrgather_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrgather_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrsub.nxv8i8.i8(<vscale x 8 x i8> [[ARG_0:%.*]], i8 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vrsub_8xi8(__epi_8xi8 arg_0, signed char arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrsub.mask.nxv8i8.i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i8 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vrsub_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, signed char arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrsub.nxv4i16.i16(<vscale x 4 x i16> [[ARG_0:%.*]], i16 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vrsub_4xi16(__epi_4xi16 arg_0, signed short int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrsub.mask.nxv4i16.i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i16 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vrsub_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, signed short int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrsub.nxv2i32.i32(<vscale x 2 x i32> [[ARG_0:%.*]], i32 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vrsub_2xi32(__epi_2xi32 arg_0, signed int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrsub.mask.nxv2i32.i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i32 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vrsub_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, signed int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrsub.nxv1i64.i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vrsub_1xi64(__epi_1xi64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrsub.mask.nxv1i64.i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vrsub_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrsub.nxv16i8.i8(<vscale x 16 x i8> [[ARG_0:%.*]], i8 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vrsub_16xi8(__epi_16xi8 arg_0, signed char arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrsub.mask.nxv16i8.i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i8 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vrsub_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, signed char arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrsub.nxv8i16.i16(<vscale x 8 x i16> [[ARG_0:%.*]], i16 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vrsub_8xi16(__epi_8xi16 arg_0, signed short int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrsub.mask.nxv8i16.i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i16 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vrsub_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, signed short int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrsub.nxv4i32.i32(<vscale x 4 x i32> [[ARG_0:%.*]], i32 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vrsub_4xi32(__epi_4xi32 arg_0, signed int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrsub.mask.nxv4i32.i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i32 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vrsub_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, signed int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrsub.nxv2i64.i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vrsub_2xi64(__epi_2xi64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrsub.mask.nxv2i64.i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vrsub_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrsub.nxv32i8.i8(<vscale x 32 x i8> [[ARG_0:%.*]], i8 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vrsub_32xi8(__epi_32xi8 arg_0, signed char arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrsub.mask.nxv32i8.i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i8 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vrsub_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, signed char arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrsub.nxv16i16.i16(<vscale x 16 x i16> [[ARG_0:%.*]], i16 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vrsub_16xi16(__epi_16xi16 arg_0, signed short int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrsub.mask.nxv16i16.i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i16 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vrsub_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, signed short int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrsub.nxv8i32.i32(<vscale x 8 x i32> [[ARG_0:%.*]], i32 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vrsub_8xi32(__epi_8xi32 arg_0, signed int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrsub.mask.nxv8i32.i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i32 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vrsub_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, signed int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vrsub_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrsub.nxv4i64.i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vrsub_4xi64(__epi_4xi64 arg_0, signed long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vrsub_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vrsub_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrsub.mask.nxv4i64.i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vrsub_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vrsub_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsadd.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsadd_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsadd.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsadd_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsadd.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsadd_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsadd.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsadd_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsadd.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsadd_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsadd.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsadd_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsadd.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsadd_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsadd.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsadd_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsadd.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsadd_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsadd.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsadd_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsadd.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsadd_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsadd.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsadd_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsadd.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsadd_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsadd.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsadd_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsadd.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsadd_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsadd.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsadd_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsadd.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsadd_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsadd.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsadd_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsadd.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsadd_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsadd.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsadd_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsadd.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsadd_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsadd.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsadd_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsadd_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsadd.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsadd_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsadd_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsadd_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsadd.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsadd_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsadd_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsaddu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsaddu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsaddu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsaddu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsaddu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsaddu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsaddu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsaddu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsaddu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsaddu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsaddu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsaddu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsaddu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsaddu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsaddu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsaddu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsaddu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsaddu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsaddu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsaddu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsaddu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsaddu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsaddu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsaddu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsaddu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsaddu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsaddu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsaddu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsaddu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsaddu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsaddu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsaddu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsaddu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsaddu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsaddu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsaddu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsaddu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsaddu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsaddu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsaddu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsaddu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsaddu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsaddu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsaddu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsaddu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsaddu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsaddu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsaddu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsaddu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsaddu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsaddu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsaddu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsbc_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsbc.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsbc_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsbc_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsbc_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsbc.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsbc_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsbc_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsbc_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsbc.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsbc_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsbc_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsbc_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsbc.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsbc_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsbc_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsbc_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsbc.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsbc_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsbc_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsbc_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsbc.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsbc_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsbc_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsbc_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsbc.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsbc_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsbc_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsbc_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsbc.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsbc_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsbc_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsbc_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsbc.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsbc_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsbc_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsbc_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsbc.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsbc_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsbc_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsbc_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsbc.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsbc_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsbc_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsbc_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsbc.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsbc_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsbc_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vslide1down_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslide1down.nxv8i8.i64(<vscale x 8 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslide1down_8xi8(__epi_8xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslide1down.mask.nxv8i8.i64.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslide1down_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslide1down.nxv4i16.i64(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslide1down_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslide1down.mask.nxv4i16.i64.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslide1down_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslide1down.nxv2i32.i64(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslide1down_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslide1down.mask.nxv2i32.i64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslide1down_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslide1down.nxv1i64.i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslide1down_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslide1down.mask.nxv1i64.i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslide1down_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslide1down.nxv2f32.i64(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslide1down_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslide1down.mask.nxv2f32.i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslide1down_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslide1down.nxv1f64.i64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslide1down_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslide1down.mask.nxv1f64.i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslide1down_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslide1down.nxv16i8.i64(<vscale x 16 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslide1down_16xi8(__epi_16xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslide1down.mask.nxv16i8.i64.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslide1down_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslide1down.nxv8i16.i64(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslide1down_8xi16(__epi_8xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslide1down.mask.nxv8i16.i64.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslide1down_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslide1down.nxv4i32.i64(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslide1down_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslide1down.mask.nxv4i32.i64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslide1down_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslide1down.nxv2i64.i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslide1down_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslide1down.mask.nxv2i64.i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslide1down_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslide1down.nxv4f32.i64(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslide1down_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslide1down.mask.nxv4f32.i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslide1down_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslide1down.nxv2f64.i64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslide1down_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslide1down.mask.nxv2f64.i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslide1down_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslide1down.nxv32i8.i64(<vscale x 32 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslide1down_32xi8(__epi_32xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslide1down.mask.nxv32i8.i64.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslide1down_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslide1down.nxv16i16.i64(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslide1down_16xi16(__epi_16xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslide1down.mask.nxv16i16.i64.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslide1down_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslide1down.nxv8i32.i64(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslide1down_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslide1down.mask.nxv8i32.i64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslide1down_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslide1down.nxv4i64.i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslide1down_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslide1down.mask.nxv4i64.i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslide1down_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslide1down.nxv8f32.i64(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslide1down_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslide1down.mask.nxv8f32.i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslide1down_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1down_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslide1down.nxv4f64.i64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslide1down_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1down_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1down_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslide1down.mask.nxv4f64.i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslide1down_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1down_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslide1up.nxv8i8.i64(<vscale x 8 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslide1up_8xi8(__epi_8xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslide1up.mask.nxv8i8.i64.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslide1up_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslide1up.nxv4i16.i64(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslide1up_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslide1up.mask.nxv4i16.i64.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslide1up_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslide1up.nxv2i32.i64(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslide1up_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslide1up.mask.nxv2i32.i64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslide1up_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslide1up.nxv1i64.i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslide1up_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslide1up.mask.nxv1i64.i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslide1up_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslide1up.nxv2f32.i64(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslide1up_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslide1up.mask.nxv2f32.i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslide1up_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslide1up.nxv1f64.i64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslide1up_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslide1up.mask.nxv1f64.i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslide1up_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslide1up.nxv16i8.i64(<vscale x 16 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslide1up_16xi8(__epi_16xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslide1up.mask.nxv16i8.i64.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslide1up_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslide1up.nxv8i16.i64(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslide1up_8xi16(__epi_8xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslide1up.mask.nxv8i16.i64.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslide1up_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslide1up.nxv4i32.i64(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslide1up_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslide1up.mask.nxv4i32.i64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslide1up_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslide1up.nxv2i64.i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslide1up_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslide1up.mask.nxv2i64.i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslide1up_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslide1up.nxv4f32.i64(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslide1up_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslide1up.mask.nxv4f32.i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslide1up_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslide1up.nxv2f64.i64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslide1up_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslide1up.mask.nxv2f64.i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslide1up_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslide1up.nxv32i8.i64(<vscale x 32 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslide1up_32xi8(__epi_32xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslide1up.mask.nxv32i8.i64.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslide1up_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslide1up.nxv16i16.i64(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslide1up_16xi16(__epi_16xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslide1up.mask.nxv16i16.i64.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslide1up_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslide1up.nxv8i32.i64(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslide1up_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslide1up.mask.nxv8i32.i64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslide1up_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslide1up.nxv4i64.i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslide1up_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslide1up.mask.nxv4i64.i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslide1up_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslide1up.nxv8f32.i64(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslide1up_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslide1up.mask.nxv8f32.i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslide1up_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslide1up_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslide1up.nxv4f64.i64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslide1up_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslide1up_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslide1up_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslide1up.mask.nxv4f64.i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslide1up_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslide1up_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslidedown.nxv8i8.i64(<vscale x 8 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslidedown_8xi8(__epi_8xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslidedown.mask.nxv8i8.i64.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslidedown_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslidedown.nxv4i16.i64(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslidedown_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslidedown.mask.nxv4i16.i64.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslidedown_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslidedown.nxv2i32.i64(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslidedown_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslidedown.mask.nxv2i32.i64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslidedown_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslidedown.nxv1i64.i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslidedown_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslidedown.mask.nxv1i64.i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslidedown_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslidedown.nxv2f32.i64(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslidedown_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslidedown.mask.nxv2f32.i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslidedown_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslidedown.nxv1f64.i64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslidedown_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslidedown.mask.nxv1f64.i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslidedown_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslidedown.nxv16i8.i64(<vscale x 16 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslidedown_16xi8(__epi_16xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslidedown.mask.nxv16i8.i64.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslidedown_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslidedown.nxv8i16.i64(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslidedown_8xi16(__epi_8xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslidedown.mask.nxv8i16.i64.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslidedown_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslidedown.nxv4i32.i64(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslidedown_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslidedown.mask.nxv4i32.i64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslidedown_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslidedown.nxv2i64.i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslidedown_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslidedown.mask.nxv2i64.i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslidedown_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslidedown.nxv4f32.i64(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslidedown_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslidedown.mask.nxv4f32.i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslidedown_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslidedown.nxv2f64.i64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslidedown_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslidedown.mask.nxv2f64.i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslidedown_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslidedown.nxv32i8.i64(<vscale x 32 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslidedown_32xi8(__epi_32xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslidedown.mask.nxv32i8.i64.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslidedown_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslidedown.nxv16i16.i64(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslidedown_16xi16(__epi_16xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslidedown.mask.nxv16i16.i64.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslidedown_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslidedown.nxv8i32.i64(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslidedown_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslidedown.mask.nxv8i32.i64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslidedown_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslidedown.nxv4i64.i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslidedown_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslidedown.mask.nxv4i64.i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslidedown_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslidedown.nxv8f32.i64(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslidedown_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslidedown.mask.nxv8f32.i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslidedown_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslidedown_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslidedown.nxv4f64.i64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslidedown_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslidedown_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslidedown_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslidedown.mask.nxv4f64.i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslidedown_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslidedown_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslideup.nxv8i8.i64(<vscale x 8 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslideup_8xi8(__epi_8xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vslideup.mask.nxv8i8.i64.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vslideup_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslideup.nxv4i16.i64(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslideup_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vslideup.mask.nxv4i16.i64.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vslideup_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslideup.nxv2i32.i64(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslideup_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vslideup.mask.nxv2i32.i64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vslideup_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslideup.nxv1i64.i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslideup_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vslideup.mask.nxv1i64.i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vslideup_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslideup.nxv2f32.i64(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslideup_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vslideup.mask.nxv2f32.i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vslideup_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslideup.nxv1f64.i64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslideup_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vslideup.mask.nxv1f64.i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vslideup_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslideup.nxv16i8.i64(<vscale x 16 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslideup_16xi8(__epi_16xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vslideup.mask.nxv16i8.i64.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vslideup_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslideup.nxv8i16.i64(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslideup_8xi16(__epi_8xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vslideup.mask.nxv8i16.i64.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vslideup_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslideup.nxv4i32.i64(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslideup_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vslideup.mask.nxv4i32.i64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vslideup_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslideup.nxv2i64.i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslideup_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vslideup.mask.nxv2i64.i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vslideup_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslideup.nxv4f32.i64(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslideup_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vslideup.mask.nxv4f32.i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vslideup_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslideup.nxv2f64.i64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslideup_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vslideup.mask.nxv2f64.i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vslideup_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslideup.nxv32i8.i64(<vscale x 32 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslideup_32xi8(__epi_32xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vslideup.mask.nxv32i8.i64.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vslideup_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslideup.nxv16i16.i64(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslideup_16xi16(__epi_16xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vslideup.mask.nxv16i16.i64.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vslideup_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslideup.nxv8i32.i64(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslideup_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vslideup.mask.nxv8i32.i64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vslideup_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslideup.nxv4i64.i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslideup_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vslideup.mask.nxv4i64.i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vslideup_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslideup.nxv8f32.i64(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslideup_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vslideup.mask.nxv8f32.i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vslideup_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vslideup_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslideup.nxv4f64.i64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslideup_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vslideup_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vslideup_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vslideup.mask.nxv4f64.i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vslideup_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vslideup_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsll.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsll_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsll.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsll_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsll.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsll_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsll.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsll_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsll.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsll_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsll.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsll_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsll.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsll_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsll.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsll_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsll.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsll_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsll.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsll_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsll.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsll_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsll.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsll_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsll.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsll_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsll.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsll_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsll.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsll_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsll.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsll_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsll.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsll_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsll.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsll_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsll.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsll_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsll.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsll_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsll.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsll_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsll.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsll_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsll_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsll.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsll_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsll_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsll_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsll.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsll_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsll_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsmul.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsmul_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsmul.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsmul_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsmul.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsmul_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsmul.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsmul_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsmul.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsmul_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsmul.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsmul_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsmul.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsmul_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsmul.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsmul_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsmul.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsmul_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsmul.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsmul_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsmul.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsmul_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsmul.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsmul_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsmul.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsmul_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsmul.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsmul_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsmul.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsmul_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsmul.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsmul_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsmul.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsmul_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsmul.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsmul_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsmul.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsmul_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsmul.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsmul_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsmul.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsmul_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsmul.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsmul_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsmul_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsmul.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsmul_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsmul_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsmul_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsmul.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsmul_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsmul_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrgather.nxv8i8.i64(<vscale x 8 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsplat_8xi8(__epi_8xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vrgather.mask.nxv8i8.i64.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsplat_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrgather.nxv4i16.i64(<vscale x 4 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsplat_4xi16(__epi_4xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vrgather.mask.nxv4i16.i64.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsplat_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrgather.nxv2i32.i64(<vscale x 2 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsplat_2xi32(__epi_2xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vrgather.mask.nxv2i32.i64.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsplat_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrgather.nxv1i64.i64(<vscale x 1 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsplat_1xi64(__epi_1xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vrgather.mask.nxv1i64.i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsplat_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vrgather.nxv2f32.i64(<vscale x 2 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vsplat_2xf32(__epi_2xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x float> @llvm.epi.vrgather.mask.nxv2f32.i64.nxv2i1(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x float> [[TMP0]]
//
__epi_2xf32 test_vsplat_2xf32_mask(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vrgather.nxv1f64.i64(<vscale x 1 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vsplat_1xf64(__epi_1xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x double> @llvm.epi.vrgather.mask.nxv1f64.i64.nxv1i1(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x double> [[TMP0]]
//
__epi_1xf64 test_vsplat_1xf64_mask(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrgather.nxv16i8.i64(<vscale x 16 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsplat_16xi8(__epi_16xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vrgather.mask.nxv16i8.i64.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsplat_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrgather.nxv8i16.i64(<vscale x 8 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsplat_8xi16(__epi_8xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vrgather.mask.nxv8i16.i64.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsplat_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrgather.nxv4i32.i64(<vscale x 4 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsplat_4xi32(__epi_4xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vrgather.mask.nxv4i32.i64.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsplat_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrgather.nxv2i64.i64(<vscale x 2 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsplat_2xi64(__epi_2xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vrgather.mask.nxv2i64.i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsplat_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vrgather.nxv4f32.i64(<vscale x 4 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vsplat_4xf32(__epi_4xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x float> @llvm.epi.vrgather.mask.nxv4f32.i64.nxv4i1(<vscale x 4 x float> [[ARG_0:%.*]], <vscale x 4 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x float> [[TMP0]]
//
__epi_4xf32 test_vsplat_4xf32_mask(__epi_4xf32 arg_0, __epi_4xf32 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vrgather.nxv2f64.i64(<vscale x 2 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vsplat_2xf64(__epi_2xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x double> @llvm.epi.vrgather.mask.nxv2f64.i64.nxv2i1(<vscale x 2 x double> [[ARG_0:%.*]], <vscale x 2 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x double> [[TMP0]]
//
__epi_2xf64 test_vsplat_2xf64_mask(__epi_2xf64 arg_0, __epi_2xf64 arg_1, unsigned long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrgather.nxv32i8.i64(<vscale x 32 x i8> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsplat_32xi8(__epi_32xi8 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vrgather.mask.nxv32i8.i64.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsplat_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrgather.nxv16i16.i64(<vscale x 16 x i16> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsplat_16xi16(__epi_16xi16 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vrgather.mask.nxv16i16.i64.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsplat_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrgather.nxv8i32.i64(<vscale x 8 x i32> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsplat_8xi32(__epi_8xi32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vrgather.mask.nxv8i32.i64.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsplat_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrgather.nxv4i64.i64(<vscale x 4 x i64> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsplat_4xi64(__epi_4xi64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vrgather.mask.nxv4i64.i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsplat_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vrgather.nxv8f32.i64(<vscale x 8 x float> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vsplat_8xf32(__epi_8xf32 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x float> @llvm.epi.vrgather.mask.nxv8f32.i64.nxv8i1(<vscale x 8 x float> [[ARG_0:%.*]], <vscale x 8 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x float> [[TMP0]]
//
__epi_8xf32 test_vsplat_8xf32_mask(__epi_8xf32 arg_0, __epi_8xf32 arg_1, unsigned long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsplat_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vrgather.nxv4f64.i64(<vscale x 4 x double> [[ARG_0:%.*]], i64 [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vsplat_4xf64(__epi_4xf64 arg_0, unsigned long int arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsplat_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsplat_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x double> @llvm.epi.vrgather.mask.nxv4f64.i64.nxv4i1(<vscale x 4 x double> [[ARG_0:%.*]], <vscale x 4 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x double> [[TMP0]]
//
__epi_4xf64 test_vsplat_4xf64_mask(__epi_4xf64 arg_0, __epi_4xf64 arg_1, unsigned long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsplat_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsra.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsra_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsra.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsra_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsra.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsra_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsra.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsra_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsra.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsra_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsra.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsra_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsra.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsra_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsra.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsra_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsra.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsra_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsra.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsra_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsra.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsra_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsra.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsra_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsra.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsra_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsra.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsra_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsra.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsra_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsra.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsra_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsra.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsra_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsra.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsra_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsra.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsra_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsra.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsra_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsra.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsra_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsra.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsra_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsra_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsra.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsra_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsra_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsra_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsra.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsra_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsra_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsrl.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsrl_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsrl.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsrl_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsrl.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsrl_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsrl.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsrl_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsrl.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsrl_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsrl.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsrl_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsrl.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsrl_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsrl.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsrl_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsrl.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsrl_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsrl.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsrl_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsrl.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsrl_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsrl.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsrl_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsrl.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsrl_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsrl.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsrl_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsrl.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsrl_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsrl.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsrl_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsrl.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsrl_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsrl.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsrl_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsrl.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsrl_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsrl.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsrl_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsrl.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsrl_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsrl.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsrl_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsrl_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsrl.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsrl_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsrl_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsrl_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsrl.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsrl_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsrl_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg2_8xi8x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_8xi8x2(signed char*  arg_0, __epi_8xi8x2 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg2_8xi8x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg2_8xi8x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_8xi8x2_mask(signed char*  arg_0, __epi_8xi8x2 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_8xi8x2_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_4xi16x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_4xi16x2(signed short int*  arg_0, __epi_4xi16x2 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg2_4xi16x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg2_4xi16x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_4xi16x2_mask(signed short int*  arg_0, __epi_4xi16x2 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_4xi16x2_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_2xi32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_2xi32x2(signed int*  arg_0, __epi_2xi32x2 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg2_2xi32x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg2_2xi32x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_2xi32x2_mask(signed int*  arg_0, __epi_2xi32x2 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_2xi32x2_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_1xi64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_1xi64x2(signed long int*  arg_0, __epi_1xi64x2 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg2_1xi64x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg2_1xi64x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_1xi64x2_mask(signed long int*  arg_0, __epi_1xi64x2 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_1xi64x2_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_2xf32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_2xf32x2(float*  arg_0, __epi_2xf32x2 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg2_2xf32x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg2_2xf32x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_2xf32x2_mask(float*  arg_0, __epi_2xf32x2 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_2xf32x2_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_1xf64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_1xf64x2(double*  arg_0, __epi_1xf64x2 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg2_1xf64x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg2_1xf64x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_1xf64x2_mask(double*  arg_0, __epi_1xf64x2 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_1xf64x2_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_indexed_8xi8x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_indexed_8xi8x2(signed char*  arg_0, __epi_8xi8x2 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_indexed_8xi8x2(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_indexed_8xi8x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_indexed_8xi8x2_mask(signed char*  arg_0, __epi_8xi8x2 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg2_indexed_8xi8x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg2_indexed_4xi16x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_indexed_4xi16x2(signed short int*  arg_0, __epi_4xi16x2 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_indexed_4xi16x2(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_indexed_4xi16x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_indexed_4xi16x2_mask(signed short int*  arg_0, __epi_4xi16x2 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg2_indexed_4xi16x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg2_indexed_2xi32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_indexed_2xi32x2(signed int*  arg_0, __epi_2xi32x2 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_indexed_2xi32x2(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_indexed_2xi32x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_indexed_2xi32x2_mask(signed int*  arg_0, __epi_2xi32x2 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg2_indexed_2xi32x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg2_indexed_1xi64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_indexed_1xi64x2(signed long int*  arg_0, __epi_1xi64x2 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_indexed_1xi64x2(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_indexed_1xi64x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_indexed_1xi64x2_mask(signed long int*  arg_0, __epi_1xi64x2 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg2_indexed_1xi64x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg2_indexed_2xf32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.indexed.nxv2f32.nxv2i32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_indexed_2xf32x2(float*  arg_0, __epi_2xf32x2 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_indexed_2xf32x2(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_indexed_2xf32x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_indexed_2xf32x2_mask(float*  arg_0, __epi_2xf32x2 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg2_indexed_2xf32x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg2_indexed_1xf64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.indexed.nxv1f64.nxv1i64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_indexed_1xf64x2(double*  arg_0, __epi_1xf64x2 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_indexed_1xf64x2(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_indexed_1xf64x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_indexed_1xf64x2_mask(double*  arg_0, __epi_1xf64x2 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg2_indexed_1xf64x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg2_strided_8xi8x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.strided.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_strided_8xi8x2(signed char*  arg_0, __epi_8xi8x2 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_strided_8xi8x2(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_strided_8xi8x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_strided_8xi8x2_mask(signed char*  arg_0, __epi_8xi8x2 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg2_strided_8xi8x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg2_strided_4xi16x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.strided.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_strided_4xi16x2(signed short int*  arg_0, __epi_4xi16x2 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_strided_4xi16x2(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_strided_4xi16x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_strided_4xi16x2_mask(signed short int*  arg_0, __epi_4xi16x2 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg2_strided_4xi16x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg2_strided_2xi32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.strided.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_strided_2xi32x2(signed int*  arg_0, __epi_2xi32x2 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_strided_2xi32x2(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_strided_2xi32x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_strided_2xi32x2_mask(signed int*  arg_0, __epi_2xi32x2 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg2_strided_2xi32x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg2_strided_1xi64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.strided.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_strided_1xi64x2(signed long int*  arg_0, __epi_1xi64x2 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_strided_1xi64x2(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_strided_1xi64x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_strided_1xi64x2_mask(signed long int*  arg_0, __epi_1xi64x2 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg2_strided_1xi64x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg2_strided_2xf32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.strided.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_strided_2xf32x2(float*  arg_0, __epi_2xf32x2 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_strided_2xf32x2(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_strided_2xf32x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_strided_2xf32x2_mask(float*  arg_0, __epi_2xf32x2 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg2_strided_2xf32x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg2_strided_1xf64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.strided.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_strided_1xf64x2(double*  arg_0, __epi_1xf64x2 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg2_strided_1xf64x2(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg2_strided_1xf64x2_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg2.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg2_strided_1xf64x2_mask(double*  arg_0, __epi_1xf64x2 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg2_strided_1xf64x2_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg3_8xi8x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_8xi8x3(signed char*  arg_0, __epi_8xi8x3 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg3_8xi8x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg3_8xi8x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_8xi8x3_mask(signed char*  arg_0, __epi_8xi8x3 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_8xi8x3_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_4xi16x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_4xi16x3(signed short int*  arg_0, __epi_4xi16x3 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg3_4xi16x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg3_4xi16x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_4xi16x3_mask(signed short int*  arg_0, __epi_4xi16x3 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_4xi16x3_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_2xi32x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_2xi32x3(signed int*  arg_0, __epi_2xi32x3 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg3_2xi32x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg3_2xi32x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_2xi32x3_mask(signed int*  arg_0, __epi_2xi32x3 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_2xi32x3_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_1xi64x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_1xi64x3(signed long int*  arg_0, __epi_1xi64x3 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg3_1xi64x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg3_1xi64x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_1xi64x3_mask(signed long int*  arg_0, __epi_1xi64x3 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_1xi64x3_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_2xf32x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_2xf32x3(float*  arg_0, __epi_2xf32x3 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg3_2xf32x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg3_2xf32x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_2xf32x3_mask(float*  arg_0, __epi_2xf32x3 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_2xf32x3_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_1xf64x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_1xf64x3(double*  arg_0, __epi_1xf64x3 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg3_1xf64x3(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg3_1xf64x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_1xf64x3_mask(double*  arg_0, __epi_1xf64x3 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_1xf64x3_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_indexed_8xi8x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_indexed_8xi8x3(signed char*  arg_0, __epi_8xi8x3 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_indexed_8xi8x3(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_indexed_8xi8x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_indexed_8xi8x3_mask(signed char*  arg_0, __epi_8xi8x3 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg3_indexed_8xi8x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg3_indexed_4xi16x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_indexed_4xi16x3(signed short int*  arg_0, __epi_4xi16x3 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_indexed_4xi16x3(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_indexed_4xi16x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_indexed_4xi16x3_mask(signed short int*  arg_0, __epi_4xi16x3 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg3_indexed_4xi16x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg3_indexed_2xi32x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_indexed_2xi32x3(signed int*  arg_0, __epi_2xi32x3 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_indexed_2xi32x3(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_indexed_2xi32x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_indexed_2xi32x3_mask(signed int*  arg_0, __epi_2xi32x3 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg3_indexed_2xi32x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg3_indexed_1xi64x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_indexed_1xi64x3(signed long int*  arg_0, __epi_1xi64x3 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_indexed_1xi64x3(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_indexed_1xi64x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_indexed_1xi64x3_mask(signed long int*  arg_0, __epi_1xi64x3 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg3_indexed_1xi64x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg3_indexed_2xf32x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.indexed.nxv2f32.nxv2i32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_indexed_2xf32x3(float*  arg_0, __epi_2xf32x3 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_indexed_2xf32x3(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_indexed_2xf32x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_indexed_2xf32x3_mask(float*  arg_0, __epi_2xf32x3 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg3_indexed_2xf32x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg3_indexed_1xf64x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.indexed.nxv1f64.nxv1i64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_indexed_1xf64x3(double*  arg_0, __epi_1xf64x3 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_indexed_1xf64x3(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_indexed_1xf64x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_indexed_1xf64x3_mask(double*  arg_0, __epi_1xf64x3 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg3_indexed_1xf64x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg3_strided_8xi8x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.strided.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_strided_8xi8x3(signed char*  arg_0, __epi_8xi8x3 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_strided_8xi8x3(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_strided_8xi8x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_strided_8xi8x3_mask(signed char*  arg_0, __epi_8xi8x3 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg3_strided_8xi8x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg3_strided_4xi16x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.strided.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_strided_4xi16x3(signed short int*  arg_0, __epi_4xi16x3 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_strided_4xi16x3(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_strided_4xi16x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_strided_4xi16x3_mask(signed short int*  arg_0, __epi_4xi16x3 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg3_strided_4xi16x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg3_strided_2xi32x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.strided.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_strided_2xi32x3(signed int*  arg_0, __epi_2xi32x3 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_strided_2xi32x3(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_strided_2xi32x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_strided_2xi32x3_mask(signed int*  arg_0, __epi_2xi32x3 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg3_strided_2xi32x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg3_strided_1xi64x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.strided.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_strided_1xi64x3(signed long int*  arg_0, __epi_1xi64x3 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_strided_1xi64x3(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_strided_1xi64x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_strided_1xi64x3_mask(signed long int*  arg_0, __epi_1xi64x3 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg3_strided_1xi64x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg3_strided_2xf32x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.strided.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_strided_2xf32x3(float*  arg_0, __epi_2xf32x3 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_strided_2xf32x3(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_strided_2xf32x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_strided_2xf32x3_mask(float*  arg_0, __epi_2xf32x3 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg3_strided_2xf32x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg3_strided_1xf64x3(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.strided.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_strided_1xf64x3(double*  arg_0, __epi_1xf64x3 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg3_strided_1xf64x3(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg3_strided_1xf64x3_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg3.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg3_strided_1xf64x3_mask(double*  arg_0, __epi_1xf64x3 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg3_strided_1xf64x3_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg4_8xi8x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_8xi8x4(signed char*  arg_0, __epi_8xi8x4 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg4_8xi8x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg4_8xi8x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_8xi8x4_mask(signed char*  arg_0, __epi_8xi8x4 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_8xi8x4_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_4xi16x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_4xi16x4(signed short int*  arg_0, __epi_4xi16x4 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg4_4xi16x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg4_4xi16x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_4xi16x4_mask(signed short int*  arg_0, __epi_4xi16x4 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_4xi16x4_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_2xi32x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_2xi32x4(signed int*  arg_0, __epi_2xi32x4 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg4_2xi32x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg4_2xi32x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_2xi32x4_mask(signed int*  arg_0, __epi_2xi32x4 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_2xi32x4_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_1xi64x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_1xi64x4(signed long int*  arg_0, __epi_1xi64x4 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg4_1xi64x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg4_1xi64x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_1xi64x4_mask(signed long int*  arg_0, __epi_1xi64x4 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_1xi64x4_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_2xf32x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_2xf32x4(float*  arg_0, __epi_2xf32x4 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg4_2xf32x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg4_2xf32x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_2xf32x4_mask(float*  arg_0, __epi_2xf32x4 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_2xf32x4_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_1xf64x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_1xf64x4(double*  arg_0, __epi_1xf64x4 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg4_1xf64x4(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg4_1xf64x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_1xf64x4_mask(double*  arg_0, __epi_1xf64x4 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_1xf64x4_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_indexed_8xi8x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_indexed_8xi8x4(signed char*  arg_0, __epi_8xi8x4 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_indexed_8xi8x4(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_indexed_8xi8x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_indexed_8xi8x4_mask(signed char*  arg_0, __epi_8xi8x4 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg4_indexed_8xi8x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg4_indexed_4xi16x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_indexed_4xi16x4(signed short int*  arg_0, __epi_4xi16x4 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_indexed_4xi16x4(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_indexed_4xi16x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_indexed_4xi16x4_mask(signed short int*  arg_0, __epi_4xi16x4 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg4_indexed_4xi16x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg4_indexed_2xi32x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_indexed_2xi32x4(signed int*  arg_0, __epi_2xi32x4 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_indexed_2xi32x4(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_indexed_2xi32x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_indexed_2xi32x4_mask(signed int*  arg_0, __epi_2xi32x4 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg4_indexed_2xi32x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg4_indexed_1xi64x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_indexed_1xi64x4(signed long int*  arg_0, __epi_1xi64x4 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_indexed_1xi64x4(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_indexed_1xi64x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_indexed_1xi64x4_mask(signed long int*  arg_0, __epi_1xi64x4 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg4_indexed_1xi64x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg4_indexed_2xf32x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.indexed.nxv2f32.nxv2i32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_indexed_2xf32x4(float*  arg_0, __epi_2xf32x4 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_indexed_2xf32x4(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_indexed_2xf32x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_indexed_2xf32x4_mask(float*  arg_0, __epi_2xf32x4 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg4_indexed_2xf32x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg4_indexed_1xf64x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.indexed.nxv1f64.nxv1i64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_indexed_1xf64x4(double*  arg_0, __epi_1xf64x4 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_indexed_1xf64x4(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_indexed_1xf64x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_indexed_1xf64x4_mask(double*  arg_0, __epi_1xf64x4 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg4_indexed_1xf64x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg4_strided_8xi8x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.strided.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_strided_8xi8x4(signed char*  arg_0, __epi_8xi8x4 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_strided_8xi8x4(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_strided_8xi8x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_strided_8xi8x4_mask(signed char*  arg_0, __epi_8xi8x4 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg4_strided_8xi8x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg4_strided_4xi16x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.strided.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_strided_4xi16x4(signed short int*  arg_0, __epi_4xi16x4 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_strided_4xi16x4(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_strided_4xi16x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_strided_4xi16x4_mask(signed short int*  arg_0, __epi_4xi16x4 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg4_strided_4xi16x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg4_strided_2xi32x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.strided.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_strided_2xi32x4(signed int*  arg_0, __epi_2xi32x4 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_strided_2xi32x4(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_strided_2xi32x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_strided_2xi32x4_mask(signed int*  arg_0, __epi_2xi32x4 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg4_strided_2xi32x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg4_strided_1xi64x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.strided.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_strided_1xi64x4(signed long int*  arg_0, __epi_1xi64x4 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_strided_1xi64x4(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_strided_1xi64x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_strided_1xi64x4_mask(signed long int*  arg_0, __epi_1xi64x4 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg4_strided_1xi64x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg4_strided_2xf32x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.strided.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_strided_2xf32x4(float*  arg_0, __epi_2xf32x4 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_strided_2xf32x4(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_strided_2xf32x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_strided_2xf32x4_mask(float*  arg_0, __epi_2xf32x4 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg4_strided_2xf32x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg4_strided_1xf64x4(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.strided.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_strided_1xf64x4(double*  arg_0, __epi_1xf64x4 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg4_strided_1xf64x4(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg4_strided_1xf64x4_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg4.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg4_strided_1xf64x4_mask(double*  arg_0, __epi_1xf64x4 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg4_strided_1xf64x4_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg5_8xi8x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_8xi8x5(signed char*  arg_0, __epi_8xi8x5 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg5_8xi8x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg5_8xi8x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_8xi8x5_mask(signed char*  arg_0, __epi_8xi8x5 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_8xi8x5_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_4xi16x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_4xi16x5(signed short int*  arg_0, __epi_4xi16x5 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg5_4xi16x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg5_4xi16x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_4xi16x5_mask(signed short int*  arg_0, __epi_4xi16x5 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_4xi16x5_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_2xi32x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_2xi32x5(signed int*  arg_0, __epi_2xi32x5 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg5_2xi32x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg5_2xi32x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_2xi32x5_mask(signed int*  arg_0, __epi_2xi32x5 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_2xi32x5_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_1xi64x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_1xi64x5(signed long int*  arg_0, __epi_1xi64x5 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg5_1xi64x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg5_1xi64x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_1xi64x5_mask(signed long int*  arg_0, __epi_1xi64x5 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_1xi64x5_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_2xf32x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_2xf32x5(float*  arg_0, __epi_2xf32x5 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg5_2xf32x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg5_2xf32x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_2xf32x5_mask(float*  arg_0, __epi_2xf32x5 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_2xf32x5_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_1xf64x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_1xf64x5(double*  arg_0, __epi_1xf64x5 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg5_1xf64x5(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg5_1xf64x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_1xf64x5_mask(double*  arg_0, __epi_1xf64x5 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_1xf64x5_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_indexed_8xi8x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_indexed_8xi8x5(signed char*  arg_0, __epi_8xi8x5 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_indexed_8xi8x5(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_indexed_8xi8x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_indexed_8xi8x5_mask(signed char*  arg_0, __epi_8xi8x5 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg5_indexed_8xi8x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg5_indexed_4xi16x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_indexed_4xi16x5(signed short int*  arg_0, __epi_4xi16x5 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_indexed_4xi16x5(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_indexed_4xi16x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_indexed_4xi16x5_mask(signed short int*  arg_0, __epi_4xi16x5 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg5_indexed_4xi16x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg5_indexed_2xi32x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_indexed_2xi32x5(signed int*  arg_0, __epi_2xi32x5 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_indexed_2xi32x5(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_indexed_2xi32x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_indexed_2xi32x5_mask(signed int*  arg_0, __epi_2xi32x5 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg5_indexed_2xi32x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg5_indexed_1xi64x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_indexed_1xi64x5(signed long int*  arg_0, __epi_1xi64x5 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_indexed_1xi64x5(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_indexed_1xi64x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_indexed_1xi64x5_mask(signed long int*  arg_0, __epi_1xi64x5 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg5_indexed_1xi64x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg5_indexed_2xf32x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.indexed.nxv2f32.nxv2i32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_indexed_2xf32x5(float*  arg_0, __epi_2xf32x5 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_indexed_2xf32x5(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_indexed_2xf32x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_indexed_2xf32x5_mask(float*  arg_0, __epi_2xf32x5 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg5_indexed_2xf32x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg5_indexed_1xf64x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.indexed.nxv1f64.nxv1i64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_indexed_1xf64x5(double*  arg_0, __epi_1xf64x5 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_indexed_1xf64x5(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_indexed_1xf64x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_indexed_1xf64x5_mask(double*  arg_0, __epi_1xf64x5 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg5_indexed_1xf64x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg5_strided_8xi8x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.strided.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_strided_8xi8x5(signed char*  arg_0, __epi_8xi8x5 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_strided_8xi8x5(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_strided_8xi8x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_strided_8xi8x5_mask(signed char*  arg_0, __epi_8xi8x5 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg5_strided_8xi8x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg5_strided_4xi16x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.strided.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_strided_4xi16x5(signed short int*  arg_0, __epi_4xi16x5 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_strided_4xi16x5(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_strided_4xi16x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_strided_4xi16x5_mask(signed short int*  arg_0, __epi_4xi16x5 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg5_strided_4xi16x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg5_strided_2xi32x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.strided.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_strided_2xi32x5(signed int*  arg_0, __epi_2xi32x5 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_strided_2xi32x5(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_strided_2xi32x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_strided_2xi32x5_mask(signed int*  arg_0, __epi_2xi32x5 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg5_strided_2xi32x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg5_strided_1xi64x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.strided.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_strided_1xi64x5(signed long int*  arg_0, __epi_1xi64x5 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_strided_1xi64x5(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_strided_1xi64x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_strided_1xi64x5_mask(signed long int*  arg_0, __epi_1xi64x5 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg5_strided_1xi64x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg5_strided_2xf32x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.strided.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_strided_2xf32x5(float*  arg_0, __epi_2xf32x5 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_strided_2xf32x5(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_strided_2xf32x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_strided_2xf32x5_mask(float*  arg_0, __epi_2xf32x5 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg5_strided_2xf32x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg5_strided_1xf64x5(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.strided.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_strided_1xf64x5(double*  arg_0, __epi_1xf64x5 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg5_strided_1xf64x5(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg5_strided_1xf64x5_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg5.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg5_strided_1xf64x5_mask(double*  arg_0, __epi_1xf64x5 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg5_strided_1xf64x5_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg6_8xi8x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_8xi8x6(signed char*  arg_0, __epi_8xi8x6 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg6_8xi8x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg6_8xi8x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_8xi8x6_mask(signed char*  arg_0, __epi_8xi8x6 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_8xi8x6_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_4xi16x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_4xi16x6(signed short int*  arg_0, __epi_4xi16x6 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg6_4xi16x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg6_4xi16x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_4xi16x6_mask(signed short int*  arg_0, __epi_4xi16x6 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_4xi16x6_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_2xi32x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_2xi32x6(signed int*  arg_0, __epi_2xi32x6 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg6_2xi32x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg6_2xi32x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_2xi32x6_mask(signed int*  arg_0, __epi_2xi32x6 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_2xi32x6_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_1xi64x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_1xi64x6(signed long int*  arg_0, __epi_1xi64x6 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg6_1xi64x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg6_1xi64x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_1xi64x6_mask(signed long int*  arg_0, __epi_1xi64x6 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_1xi64x6_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_2xf32x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_2xf32x6(float*  arg_0, __epi_2xf32x6 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg6_2xf32x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg6_2xf32x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_2xf32x6_mask(float*  arg_0, __epi_2xf32x6 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_2xf32x6_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_1xf64x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_1xf64x6(double*  arg_0, __epi_1xf64x6 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg6_1xf64x6(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg6_1xf64x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_1xf64x6_mask(double*  arg_0, __epi_1xf64x6 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_1xf64x6_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_indexed_8xi8x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_indexed_8xi8x6(signed char*  arg_0, __epi_8xi8x6 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_indexed_8xi8x6(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_indexed_8xi8x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_indexed_8xi8x6_mask(signed char*  arg_0, __epi_8xi8x6 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg6_indexed_8xi8x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg6_indexed_4xi16x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_indexed_4xi16x6(signed short int*  arg_0, __epi_4xi16x6 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_indexed_4xi16x6(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_indexed_4xi16x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_indexed_4xi16x6_mask(signed short int*  arg_0, __epi_4xi16x6 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg6_indexed_4xi16x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg6_indexed_2xi32x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_indexed_2xi32x6(signed int*  arg_0, __epi_2xi32x6 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_indexed_2xi32x6(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_indexed_2xi32x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_indexed_2xi32x6_mask(signed int*  arg_0, __epi_2xi32x6 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg6_indexed_2xi32x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg6_indexed_1xi64x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_indexed_1xi64x6(signed long int*  arg_0, __epi_1xi64x6 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_indexed_1xi64x6(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_indexed_1xi64x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_indexed_1xi64x6_mask(signed long int*  arg_0, __epi_1xi64x6 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg6_indexed_1xi64x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg6_indexed_2xf32x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.indexed.nxv2f32.nxv2i32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_indexed_2xf32x6(float*  arg_0, __epi_2xf32x6 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_indexed_2xf32x6(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_indexed_2xf32x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_indexed_2xf32x6_mask(float*  arg_0, __epi_2xf32x6 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg6_indexed_2xf32x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg6_indexed_1xf64x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.indexed.nxv1f64.nxv1i64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_indexed_1xf64x6(double*  arg_0, __epi_1xf64x6 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_indexed_1xf64x6(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_indexed_1xf64x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_indexed_1xf64x6_mask(double*  arg_0, __epi_1xf64x6 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg6_indexed_1xf64x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg6_strided_8xi8x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.strided.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_strided_8xi8x6(signed char*  arg_0, __epi_8xi8x6 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_strided_8xi8x6(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_strided_8xi8x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_strided_8xi8x6_mask(signed char*  arg_0, __epi_8xi8x6 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg6_strided_8xi8x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg6_strided_4xi16x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.strided.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_strided_4xi16x6(signed short int*  arg_0, __epi_4xi16x6 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_strided_4xi16x6(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_strided_4xi16x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_strided_4xi16x6_mask(signed short int*  arg_0, __epi_4xi16x6 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg6_strided_4xi16x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg6_strided_2xi32x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.strided.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_strided_2xi32x6(signed int*  arg_0, __epi_2xi32x6 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_strided_2xi32x6(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_strided_2xi32x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_strided_2xi32x6_mask(signed int*  arg_0, __epi_2xi32x6 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg6_strided_2xi32x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg6_strided_1xi64x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.strided.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_strided_1xi64x6(signed long int*  arg_0, __epi_1xi64x6 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_strided_1xi64x6(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_strided_1xi64x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_strided_1xi64x6_mask(signed long int*  arg_0, __epi_1xi64x6 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg6_strided_1xi64x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg6_strided_2xf32x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.strided.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_strided_2xf32x6(float*  arg_0, __epi_2xf32x6 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_strided_2xf32x6(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_strided_2xf32x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_strided_2xf32x6_mask(float*  arg_0, __epi_2xf32x6 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg6_strided_2xf32x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg6_strided_1xf64x6(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.strided.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_strided_1xf64x6(double*  arg_0, __epi_1xf64x6 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg6_strided_1xf64x6(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg6_strided_1xf64x6_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg6.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg6_strided_1xf64x6_mask(double*  arg_0, __epi_1xf64x6 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg6_strided_1xf64x6_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg7_8xi8x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE6:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_8xi8x7(signed char*  arg_0, __epi_8xi8x7 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg7_8xi8x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg7_8xi8x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE6:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_8xi8x7_mask(signed char*  arg_0, __epi_8xi8x7 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_8xi8x7_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_4xi16x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE6:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_4xi16x7(signed short int*  arg_0, __epi_4xi16x7 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg7_4xi16x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg7_4xi16x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE6:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_4xi16x7_mask(signed short int*  arg_0, __epi_4xi16x7 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_4xi16x7_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_2xi32x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE6:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_2xi32x7(signed int*  arg_0, __epi_2xi32x7 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg7_2xi32x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg7_2xi32x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE6:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_2xi32x7_mask(signed int*  arg_0, __epi_2xi32x7 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_2xi32x7_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_1xi64x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE6:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_1xi64x7(signed long int*  arg_0, __epi_1xi64x7 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg7_1xi64x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg7_1xi64x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE6:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_1xi64x7_mask(signed long int*  arg_0, __epi_1xi64x7 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_1xi64x7_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_2xf32x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], <vscale x 2 x float> [[ARG_1_COERCE6:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_2xf32x7(float*  arg_0, __epi_2xf32x7 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg7_2xf32x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg7_2xf32x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], <vscale x 2 x float> [[ARG_1_COERCE6:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_2xf32x7_mask(float*  arg_0, __epi_2xf32x7 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_2xf32x7_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_1xf64x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], <vscale x 1 x double> [[ARG_1_COERCE6:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_1xf64x7(double*  arg_0, __epi_1xf64x7 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg7_1xf64x7(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg7_1xf64x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], <vscale x 1 x double> [[ARG_1_COERCE6:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_1xf64x7_mask(double*  arg_0, __epi_1xf64x7 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_1xf64x7_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_indexed_8xi8x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE6:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_indexed_8xi8x7(signed char*  arg_0, __epi_8xi8x7 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_indexed_8xi8x7(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_indexed_8xi8x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE6:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_indexed_8xi8x7_mask(signed char*  arg_0, __epi_8xi8x7 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg7_indexed_8xi8x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg7_indexed_4xi16x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE6:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_indexed_4xi16x7(signed short int*  arg_0, __epi_4xi16x7 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_indexed_4xi16x7(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_indexed_4xi16x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE6:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_indexed_4xi16x7_mask(signed short int*  arg_0, __epi_4xi16x7 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg7_indexed_4xi16x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg7_indexed_2xi32x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE6:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_indexed_2xi32x7(signed int*  arg_0, __epi_2xi32x7 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_indexed_2xi32x7(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_indexed_2xi32x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE6:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_indexed_2xi32x7_mask(signed int*  arg_0, __epi_2xi32x7 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg7_indexed_2xi32x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg7_indexed_1xi64x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE6:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_indexed_1xi64x7(signed long int*  arg_0, __epi_1xi64x7 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_indexed_1xi64x7(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_indexed_1xi64x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE6:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_indexed_1xi64x7_mask(signed long int*  arg_0, __epi_1xi64x7 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg7_indexed_1xi64x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg7_indexed_2xf32x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.indexed.nxv2f32.nxv2i32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], <vscale x 2 x float> [[ARG_1_COERCE6:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_indexed_2xf32x7(float*  arg_0, __epi_2xf32x7 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_indexed_2xf32x7(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_indexed_2xf32x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], <vscale x 2 x float> [[ARG_1_COERCE6:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_indexed_2xf32x7_mask(float*  arg_0, __epi_2xf32x7 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg7_indexed_2xf32x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg7_indexed_1xf64x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.indexed.nxv1f64.nxv1i64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], <vscale x 1 x double> [[ARG_1_COERCE6:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_indexed_1xf64x7(double*  arg_0, __epi_1xf64x7 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_indexed_1xf64x7(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_indexed_1xf64x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], <vscale x 1 x double> [[ARG_1_COERCE6:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_indexed_1xf64x7_mask(double*  arg_0, __epi_1xf64x7 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg7_indexed_1xf64x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg7_strided_8xi8x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.strided.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE6:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_strided_8xi8x7(signed char*  arg_0, __epi_8xi8x7 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_strided_8xi8x7(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_strided_8xi8x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE6:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_strided_8xi8x7_mask(signed char*  arg_0, __epi_8xi8x7 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg7_strided_8xi8x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg7_strided_4xi16x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.strided.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE6:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_strided_4xi16x7(signed short int*  arg_0, __epi_4xi16x7 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_strided_4xi16x7(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_strided_4xi16x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE6:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_strided_4xi16x7_mask(signed short int*  arg_0, __epi_4xi16x7 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg7_strided_4xi16x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg7_strided_2xi32x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.strided.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE6:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_strided_2xi32x7(signed int*  arg_0, __epi_2xi32x7 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_strided_2xi32x7(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_strided_2xi32x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE6:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_strided_2xi32x7_mask(signed int*  arg_0, __epi_2xi32x7 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg7_strided_2xi32x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg7_strided_1xi64x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.strided.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE6:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_strided_1xi64x7(signed long int*  arg_0, __epi_1xi64x7 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_strided_1xi64x7(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_strided_1xi64x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE6:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_strided_1xi64x7_mask(signed long int*  arg_0, __epi_1xi64x7 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg7_strided_1xi64x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg7_strided_2xf32x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.strided.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], <vscale x 2 x float> [[ARG_1_COERCE6:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_strided_2xf32x7(float*  arg_0, __epi_2xf32x7 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_strided_2xf32x7(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_strided_2xf32x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], <vscale x 2 x float> [[ARG_1_COERCE6:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_strided_2xf32x7_mask(float*  arg_0, __epi_2xf32x7 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg7_strided_2xf32x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg7_strided_1xf64x7(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.strided.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], <vscale x 1 x double> [[ARG_1_COERCE6:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_strided_1xf64x7(double*  arg_0, __epi_1xf64x7 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg7_strided_1xf64x7(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg7_strided_1xf64x7_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg7.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], <vscale x 1 x double> [[ARG_1_COERCE6:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg7_strided_1xf64x7_mask(double*  arg_0, __epi_1xf64x7 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg7_strided_1xf64x7_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg8_8xi8x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE6:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE7:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_8xi8x8(signed char*  arg_0, __epi_8xi8x8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg8_8xi8x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg8_8xi8x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE6:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE7:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_8xi8x8_mask(signed char*  arg_0, __epi_8xi8x8 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_8xi8x8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_4xi16x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE6:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE7:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_4xi16x8(signed short int*  arg_0, __epi_4xi16x8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg8_4xi16x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg8_4xi16x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE6:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE7:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_4xi16x8_mask(signed short int*  arg_0, __epi_4xi16x8 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_4xi16x8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_2xi32x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE6:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE7:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_2xi32x8(signed int*  arg_0, __epi_2xi32x8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg8_2xi32x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg8_2xi32x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE6:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE7:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_2xi32x8_mask(signed int*  arg_0, __epi_2xi32x8 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_2xi32x8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_1xi64x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE6:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE7:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_1xi64x8(signed long int*  arg_0, __epi_1xi64x8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg8_1xi64x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg8_1xi64x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE6:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE7:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_1xi64x8_mask(signed long int*  arg_0, __epi_1xi64x8 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_1xi64x8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_2xf32x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], <vscale x 2 x float> [[ARG_1_COERCE6:%.*]], <vscale x 2 x float> [[ARG_1_COERCE7:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_2xf32x8(float*  arg_0, __epi_2xf32x8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg8_2xf32x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg8_2xf32x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], <vscale x 2 x float> [[ARG_1_COERCE6:%.*]], <vscale x 2 x float> [[ARG_1_COERCE7:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_2xf32x8_mask(float*  arg_0, __epi_2xf32x8 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_2xf32x8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_1xf64x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], <vscale x 1 x double> [[ARG_1_COERCE6:%.*]], <vscale x 1 x double> [[ARG_1_COERCE7:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_1xf64x8(double*  arg_0, __epi_1xf64x8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsseg8_1xf64x8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsseg8_1xf64x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], <vscale x 1 x double> [[ARG_1_COERCE6:%.*]], <vscale x 1 x double> [[ARG_1_COERCE7:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_1xf64x8_mask(double*  arg_0, __epi_1xf64x8 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_1xf64x8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_indexed_8xi8x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE6:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE7:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_indexed_8xi8x8(signed char*  arg_0, __epi_8xi8x8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_indexed_8xi8x8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_indexed_8xi8x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE6:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE7:%.*]], i8* [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_indexed_8xi8x8_mask(signed char*  arg_0, __epi_8xi8x8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg8_indexed_8xi8x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg8_indexed_4xi16x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE6:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE7:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_indexed_4xi16x8(signed short int*  arg_0, __epi_4xi16x8 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_indexed_4xi16x8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_indexed_4xi16x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE6:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE7:%.*]], i16* [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_indexed_4xi16x8_mask(signed short int*  arg_0, __epi_4xi16x8 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg8_indexed_4xi16x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg8_indexed_2xi32x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE6:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE7:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_indexed_2xi32x8(signed int*  arg_0, __epi_2xi32x8 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_indexed_2xi32x8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_indexed_2xi32x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE6:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE7:%.*]], i32* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_indexed_2xi32x8_mask(signed int*  arg_0, __epi_2xi32x8 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg8_indexed_2xi32x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg8_indexed_1xi64x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE6:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE7:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_indexed_1xi64x8(signed long int*  arg_0, __epi_1xi64x8 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_indexed_1xi64x8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_indexed_1xi64x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE6:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE7:%.*]], i64* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_indexed_1xi64x8_mask(signed long int*  arg_0, __epi_1xi64x8 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg8_indexed_1xi64x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg8_indexed_2xf32x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.indexed.nxv2f32.nxv2i32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], <vscale x 2 x float> [[ARG_1_COERCE6:%.*]], <vscale x 2 x float> [[ARG_1_COERCE7:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_indexed_2xf32x8(float*  arg_0, __epi_2xf32x8 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_indexed_2xf32x8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_indexed_2xf32x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], <vscale x 2 x float> [[ARG_1_COERCE6:%.*]], <vscale x 2 x float> [[ARG_1_COERCE7:%.*]], float* [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_indexed_2xf32x8_mask(float*  arg_0, __epi_2xf32x8 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg8_indexed_2xf32x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg8_indexed_1xf64x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.indexed.nxv1f64.nxv1i64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], <vscale x 1 x double> [[ARG_1_COERCE6:%.*]], <vscale x 1 x double> [[ARG_1_COERCE7:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_indexed_1xf64x8(double*  arg_0, __epi_1xf64x8 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_indexed_1xf64x8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_indexed_1xf64x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], <vscale x 1 x double> [[ARG_1_COERCE6:%.*]], <vscale x 1 x double> [[ARG_1_COERCE7:%.*]], double* [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_indexed_1xf64x8_mask(double*  arg_0, __epi_1xf64x8 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg8_indexed_1xf64x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg8_strided_8xi8x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.strided.nxv8i8(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE6:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE7:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_strided_8xi8x8(signed char*  arg_0, __epi_8xi8x8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_strided_8xi8x8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_strided_8xi8x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1_COERCE0:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE1:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE2:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE3:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE4:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE5:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE6:%.*]], <vscale x 8 x i8> [[ARG_1_COERCE7:%.*]], i8* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_strided_8xi8x8_mask(signed char*  arg_0, __epi_8xi8x8 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg8_strided_8xi8x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg8_strided_4xi16x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.strided.nxv4i16(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE6:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE7:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_strided_4xi16x8(signed short int*  arg_0, __epi_4xi16x8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_strided_4xi16x8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_strided_4xi16x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1_COERCE0:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE1:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE2:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE3:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE4:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE5:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE6:%.*]], <vscale x 4 x i16> [[ARG_1_COERCE7:%.*]], i16* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_strided_4xi16x8_mask(signed short int*  arg_0, __epi_4xi16x8 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg8_strided_4xi16x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg8_strided_2xi32x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.strided.nxv2i32(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE6:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE7:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_strided_2xi32x8(signed int*  arg_0, __epi_2xi32x8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_strided_2xi32x8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_strided_2xi32x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1_COERCE0:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE1:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE2:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE3:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE4:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE5:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE6:%.*]], <vscale x 2 x i32> [[ARG_1_COERCE7:%.*]], i32* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_strided_2xi32x8_mask(signed int*  arg_0, __epi_2xi32x8 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg8_strided_2xi32x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg8_strided_1xi64x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.strided.nxv1i64(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE6:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE7:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_strided_1xi64x8(signed long int*  arg_0, __epi_1xi64x8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_strided_1xi64x8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_strided_1xi64x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1_COERCE0:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE1:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE2:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE3:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE4:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE5:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE6:%.*]], <vscale x 1 x i64> [[ARG_1_COERCE7:%.*]], i64* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_strided_1xi64x8_mask(signed long int*  arg_0, __epi_1xi64x8 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg8_strided_1xi64x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg8_strided_2xf32x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.strided.nxv2f32(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], <vscale x 2 x float> [[ARG_1_COERCE6:%.*]], <vscale x 2 x float> [[ARG_1_COERCE7:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_strided_2xf32x8(float*  arg_0, __epi_2xf32x8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_strided_2xf32x8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_strided_2xf32x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1_COERCE0:%.*]], <vscale x 2 x float> [[ARG_1_COERCE1:%.*]], <vscale x 2 x float> [[ARG_1_COERCE2:%.*]], <vscale x 2 x float> [[ARG_1_COERCE3:%.*]], <vscale x 2 x float> [[ARG_1_COERCE4:%.*]], <vscale x 2 x float> [[ARG_1_COERCE5:%.*]], <vscale x 2 x float> [[ARG_1_COERCE6:%.*]], <vscale x 2 x float> [[ARG_1_COERCE7:%.*]], float* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_strided_2xf32x8_mask(float*  arg_0, __epi_2xf32x8 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg8_strided_2xf32x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsseg8_strided_1xf64x8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.strided.nxv1f64(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], <vscale x 1 x double> [[ARG_1_COERCE6:%.*]], <vscale x 1 x double> [[ARG_1_COERCE7:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_strided_1xf64x8(double*  arg_0, __epi_1xf64x8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vsseg8_strided_1xf64x8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsseg8_strided_1xf64x8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    tail call void @llvm.epi.vsseg8.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1_COERCE0:%.*]], <vscale x 1 x double> [[ARG_1_COERCE1:%.*]], <vscale x 1 x double> [[ARG_1_COERCE2:%.*]], <vscale x 1 x double> [[ARG_1_COERCE3:%.*]], <vscale x 1 x double> [[ARG_1_COERCE4:%.*]], <vscale x 1 x double> [[ARG_1_COERCE5:%.*]], <vscale x 1 x double> [[ARG_1_COERCE6:%.*]], <vscale x 1 x double> [[ARG_1_COERCE7:%.*]], double* [[ARG_0:%.*]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vsseg8_strided_1xf64x8_mask(double*  arg_0, __epi_1xf64x8 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsseg8_strided_1xf64x8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssra.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssra_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssra.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssra_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssra.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssra_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssra.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssra_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssra.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssra_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssra.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssra_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssra.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssra_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssra.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssra_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssra.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssra_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssra.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssra_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssra.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssra_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssra.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssra_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssra.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssra_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssra.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssra_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssra.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssra_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssra.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssra_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssra.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssra_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssra.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssra_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssra.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssra_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssra.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssra_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssra.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssra_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssra.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssra_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssra_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssra.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssra_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssra_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssra_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssra.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssra_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssra_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssrl.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssrl_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssrl.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssrl_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssrl.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssrl_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssrl.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssrl_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssrl.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssrl_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssrl.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssrl_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssrl.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssrl_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssrl.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssrl_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssrl.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssrl_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssrl.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssrl_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssrl.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssrl_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssrl.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssrl_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssrl.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssrl_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssrl.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssrl_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssrl.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssrl_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssrl.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssrl_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssrl.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssrl_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssrl.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssrl_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssrl.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssrl_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssrl.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssrl_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssrl.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssrl_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssrl.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssrl_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssrl_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssrl.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssrl_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssrl_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssrl_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssrl.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssrl_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssrl_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssub.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssub_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssub.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssub_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssub.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssub_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssub.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssub_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssub.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssub_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssub.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssub_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssub.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssub_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssub.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssub_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssub.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssub_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssub.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssub_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssub.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssub_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssub.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssub_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssub.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssub_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssub.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssub_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssub.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssub_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssub.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssub_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssub.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssub_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssub.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssub_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssub.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssub_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssub.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssub_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssub.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssub_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssub.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssub_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssub_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssub.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssub_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssub_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssub_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssub.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssub_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssub_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssubu.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssubu_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vssubu.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vssubu_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssubu.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssubu_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vssubu.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vssubu_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssubu.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssubu_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vssubu.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vssubu_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssubu.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssubu_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vssubu.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vssubu_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssubu.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssubu_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vssubu.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vssubu_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssubu.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssubu_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vssubu.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vssubu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssubu.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssubu_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vssubu.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vssubu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssubu.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssubu_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vssubu.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vssubu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssubu.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssubu_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vssubu.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vssubu_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssubu.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssubu_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vssubu.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vssubu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssubu.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssubu_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vssubu.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vssubu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vssubu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssubu.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssubu_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vssubu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vssubu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vssubu.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vssubu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vssubu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xi8(signed char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xi8_mask(signed char*  arg_0, __epi_8xi8 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_8xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xi16(signed short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xi16_mask(signed short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_4xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xi32(signed int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xi32_mask(signed int*  arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_1xi64(signed long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_1xi64_mask(signed long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_1xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2f32(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xf32(float*  arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xf32_mask(float*  arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1f64(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_1xf64(double*  arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_1xf64_mask(double*  arg_0, __epi_1xf64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_1xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_16xi8(signed char*  arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_16xi8_mask(signed char*  arg_0, __epi_16xi8 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_16xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xi16(signed short int*  arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xi16_mask(signed short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_8xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xi32(signed int*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xi32_mask(signed int*  arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xi64(signed long int*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xi64_mask(signed long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4f32(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xf32(float*  arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xf32_mask(float*  arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2f64(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xf64(double*  arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xf64_mask(double*  arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_32xi8(signed char*  arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_32xi8_mask(signed char*  arg_0, __epi_32xi8 arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_32xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_16xi16(signed short int*  arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_16xi16_mask(signed short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_16xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xi32(signed int*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xi32_mask(signed int*  arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xi64(signed long int*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xi64_mask(signed long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8f32(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xf32(float*  arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xf32_mask(float*  arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4f64(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xf64(double*  arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xf64_mask(double*  arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_8xi8(signed char*  arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_8xi8_mask(signed char*  arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xi16(signed short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xi16_mask(signed short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_2xi32(signed int*  arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_2xi32_mask(signed int*  arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_1xi64(signed long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_1xi64_mask(signed long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv2f32.nxv2i32(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_2xf32(float*  arg_0, __epi_2xf32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_2xf32_mask(float*  arg_0, __epi_2xf32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv1f64.nxv1i64(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_1xf64(double*  arg_0, __epi_1xf64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_1xf64_mask(double*  arg_0, __epi_1xf64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_16xi8(signed char*  arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_16xi8_mask(signed char*  arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_8xi16(signed short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_8xi16_mask(signed short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xi32(signed int*  arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xi32_mask(signed int*  arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_2xi64(signed long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_2xi64_mask(signed long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4f32.nxv4i32(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xf32(float*  arg_0, __epi_4xf32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv4f32.nxv4i32.nxv4i1(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xf32_mask(float*  arg_0, __epi_4xf32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv2f64.nxv2i64(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_2xf64(double*  arg_0, __epi_2xf64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv2f64.nxv2i64.nxv2i1(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_2xf64_mask(double*  arg_0, __epi_2xf64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_32xi8(signed char*  arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_32xi8_mask(signed char*  arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_16xi16(signed short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_16xi16_mask(signed short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_8xi32(signed int*  arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_8xi32_mask(signed int*  arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xi64(signed long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xi64_mask(signed long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8f32.nxv8i32(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_8xf32(float*  arg_0, __epi_8xf32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv8f32.nxv8i32.nxv8i1(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_8xf32_mask(float*  arg_0, __epi_8xf32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4f64.nxv4i64(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xf64(double*  arg_0, __epi_4xf64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv4f64.nxv4i64.nxv4i1(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_4xf64_mask(double*  arg_0, __epi_4xf64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_8xi8(unsigned char*  arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_8xi8_mask(unsigned char*  arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_unsigned_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_4xi16(unsigned short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_4xi16_mask(unsigned short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_unsigned_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_2xi32(unsigned int*  arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_2xi32_mask(unsigned int*  arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_unsigned_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_1xi64(unsigned long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_1xi64_mask(unsigned long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_unsigned_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_16xi8(unsigned char*  arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_16xi8_mask(unsigned char*  arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_unsigned_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_8xi16(unsigned short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_8xi16_mask(unsigned short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_unsigned_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_4xi32(unsigned int*  arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_4xi32_mask(unsigned int*  arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_unsigned_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_2xi64(unsigned long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_2xi64_mask(unsigned long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_unsigned_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_32xi8(unsigned char*  arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_32xi8_mask(unsigned char*  arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_unsigned_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_16xi16(unsigned short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_16xi16_mask(unsigned short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_unsigned_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_8xi32(unsigned int*  arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_8xi32_mask(unsigned int*  arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_unsigned_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_4xi64(unsigned long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_indexed_unsigned_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_indexed_unsigned_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.indexed.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_indexed_unsigned_4xi64_mask(unsigned long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_indexed_unsigned_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_8xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i1>*
// CHECK-O2-NEXT:    store <vscale x 8 x i1> [[ARG_1:%.*]], <vscale x 8 x i1>* [[TMP0]], align 1
// CHECK-O2-NEXT:    ret void
//
void test_vstore_8xi1(unsigned char*  arg_0, __epi_8xi1 arg_1)
{
    return __builtin_epi_vstore_8xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vstore_4xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i1>*
// CHECK-O2-NEXT:    store <vscale x 4 x i1> [[ARG_1:%.*]], <vscale x 4 x i1>* [[TMP0]], align 2
// CHECK-O2-NEXT:    ret void
//
void test_vstore_4xi1(unsigned short int*  arg_0, __epi_4xi1 arg_1)
{
    return __builtin_epi_vstore_4xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vstore_2xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i1>*
// CHECK-O2-NEXT:    store <vscale x 2 x i1> [[ARG_1:%.*]], <vscale x 2 x i1>* [[TMP0]], align 4
// CHECK-O2-NEXT:    ret void
//
void test_vstore_2xi1(unsigned int*  arg_0, __epi_2xi1 arg_1)
{
    return __builtin_epi_vstore_2xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vstore_1xi1(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i1>*
// CHECK-O2-NEXT:    store <vscale x 1 x i1> [[ARG_1:%.*]], <vscale x 1 x i1>* [[TMP0]], align 8
// CHECK-O2-NEXT:    ret void
//
void test_vstore_1xi1(unsigned long int*  arg_0, __epi_1xi1 arg_1)
{
    return __builtin_epi_vstore_1xi1(arg_0, arg_1);
}

// CHECK-O2-LABEL: @test_vstore_nt_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_8xi8(signed char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_8xi8_mask(signed char*  arg_0, __epi_8xi8 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_8xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_4xi16(signed short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_4xi16_mask(signed short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_4xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_2xi32(signed int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_2xi32_mask(signed int*  arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_1xi64(signed long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_1xi64_mask(signed long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_1xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv2f32(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_2xf32(float*  arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_2xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_2xf32_mask(float*  arg_0, __epi_2xf32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_2xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv1f64(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_1xf64(double*  arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_1xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_1xf64_mask(double*  arg_0, __epi_1xf64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_1xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_16xi8(signed char*  arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_16xi8_mask(signed char*  arg_0, __epi_16xi8 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_16xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_8xi16(signed short int*  arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_8xi16_mask(signed short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_8xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_4xi32(signed int*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_4xi32_mask(signed int*  arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_2xi64(signed long int*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_2xi64_mask(signed long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv4f32(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_4xf32(float*  arg_0, __epi_4xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_4xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_4xf32_mask(float*  arg_0, __epi_4xf32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_4xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv2f64(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_2xf64(double*  arg_0, __epi_2xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_2xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_2xf64_mask(double*  arg_0, __epi_2xf64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_2xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_32xi8(signed char*  arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_32xi8_mask(signed char*  arg_0, __epi_32xi8 arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_32xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_16xi16(signed short int*  arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_16xi16_mask(signed short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_16xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_8xi32(signed int*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_8xi32_mask(signed int*  arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_4xi64(signed long int*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_4xi64_mask(signed long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv8f32(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_8xf32(float*  arg_0, __epi_8xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_8xf32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_8xf32_mask(float*  arg_0, __epi_8xf32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_8xf32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv4f64(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_4xf64(double*  arg_0, __epi_4xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_4xf64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_4xf64_mask(double*  arg_0, __epi_4xf64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_4xf64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_8xi8(signed char*  arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_8xi8_mask(signed char*  arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_4xi16(signed short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_4xi16_mask(signed short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_2xi32(signed int*  arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_2xi32_mask(signed int*  arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_1xi64(signed long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_1xi64_mask(signed long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv2f32.nxv2i32(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_2xf32(float*  arg_0, __epi_2xf32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv2f32.nxv2i32.nxv2i1(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_2xf32_mask(float*  arg_0, __epi_2xf32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv1f64.nxv1i64(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_1xf64(double*  arg_0, __epi_1xf64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv1f64.nxv1i64.nxv1i1(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_1xf64_mask(double*  arg_0, __epi_1xf64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_16xi8(signed char*  arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_16xi8_mask(signed char*  arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_8xi16(signed short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_8xi16_mask(signed short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_4xi32(signed int*  arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_4xi32_mask(signed int*  arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_2xi64(signed long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_2xi64_mask(signed long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv4f32.nxv4i32(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_4xf32(float*  arg_0, __epi_4xf32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv4f32.nxv4i32.nxv4i1(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_4xf32_mask(float*  arg_0, __epi_4xf32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv2f64.nxv2i64(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_2xf64(double*  arg_0, __epi_2xf64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv2f64.nxv2i64.nxv2i1(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_2xf64_mask(double*  arg_0, __epi_2xf64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_32xi8(signed char*  arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_32xi8_mask(signed char*  arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_16xi16(signed short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_16xi16_mask(signed short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_8xi32(signed int*  arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_8xi32_mask(signed int*  arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_4xi64(signed long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_4xi64_mask(signed long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv8f32.nxv8i32(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_8xf32(float*  arg_0, __epi_8xf32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv8f32.nxv8i32.nxv8i1(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_8xf32_mask(float*  arg_0, __epi_8xf32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv4f64.nxv4i64(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_4xf64(double*  arg_0, __epi_4xf64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv4f64.nxv4i64.nxv4i1(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_4xf64_mask(double*  arg_0, __epi_4xf64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_8xi8(unsigned char*  arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_8xi8_mask(unsigned char*  arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_4xi16(unsigned short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_4xi16_mask(unsigned short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_2xi32(unsigned int*  arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_2xi32_mask(unsigned int*  arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_1xi64(unsigned long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_1xi64_mask(unsigned long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_16xi8(unsigned char*  arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_16xi8_mask(unsigned char*  arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_8xi16(unsigned short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_8xi16_mask(unsigned short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_4xi32(unsigned int*  arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_4xi32_mask(unsigned int*  arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_2xi64(unsigned long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_2xi64_mask(unsigned long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_32xi8(unsigned char*  arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_32xi8_mask(unsigned char*  arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_16xi16(unsigned short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_16xi16_mask(unsigned short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_8xi32(unsigned int*  arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_8xi32_mask(unsigned int*  arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_4xi64(unsigned long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_indexed_unsigned_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.indexed.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_indexed_unsigned_4xi64_mask(unsigned long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_indexed_unsigned_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_8xi8(signed char*  arg_0, __epi_8xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_8xi8_mask(signed char*  arg_0, __epi_8xi8 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_4xi16(signed short int*  arg_0, __epi_4xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_4xi16_mask(signed short int*  arg_0, __epi_4xi16 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_2xi32(signed int*  arg_0, __epi_2xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_2xi32_mask(signed int*  arg_0, __epi_2xi32 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_1xi64(signed long int*  arg_0, __epi_1xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_1xi64_mask(signed long int*  arg_0, __epi_1xi64 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv2f32(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_2xf32(float*  arg_0, __epi_2xf32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_2xf32_mask(float*  arg_0, __epi_2xf32 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv1f64(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_1xf64(double*  arg_0, __epi_1xf64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_1xf64_mask(double*  arg_0, __epi_1xf64 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_16xi8(signed char*  arg_0, __epi_16xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_16xi8_mask(signed char*  arg_0, __epi_16xi8 arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_8xi16(signed short int*  arg_0, __epi_8xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_8xi16_mask(signed short int*  arg_0, __epi_8xi16 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_4xi32(signed int*  arg_0, __epi_4xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_4xi32_mask(signed int*  arg_0, __epi_4xi32 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_2xi64(signed long int*  arg_0, __epi_2xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_2xi64_mask(signed long int*  arg_0, __epi_2xi64 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv4f32(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_4xf32(float*  arg_0, __epi_4xf32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_4xf32_mask(float*  arg_0, __epi_4xf32 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv2f64(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_2xf64(double*  arg_0, __epi_2xf64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_2xf64_mask(double*  arg_0, __epi_2xf64 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_32xi8(signed char*  arg_0, __epi_32xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_32xi8_mask(signed char*  arg_0, __epi_32xi8 arg_1, signed long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_16xi16(signed short int*  arg_0, __epi_16xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_16xi16_mask(signed short int*  arg_0, __epi_16xi16 arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_8xi32(signed int*  arg_0, __epi_8xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_8xi32_mask(signed int*  arg_0, __epi_8xi32 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_4xi64(signed long int*  arg_0, __epi_4xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_4xi64_mask(signed long int*  arg_0, __epi_4xi64 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv8f32(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_8xf32(float*  arg_0, __epi_8xf32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_8xf32_mask(float*  arg_0, __epi_8xf32 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv4f64(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_4xf64(double*  arg_0, __epi_4xf64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_4xf64_mask(double*  arg_0, __epi_4xf64 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_8xi8(unsigned char*  arg_0, __epi_8xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_unsigned_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_8xi8_mask(unsigned char*  arg_0, __epi_8xi8 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_unsigned_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_4xi16(unsigned short int*  arg_0, __epi_4xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_unsigned_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_4xi16_mask(unsigned short int*  arg_0, __epi_4xi16 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_unsigned_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_2xi32(unsigned int*  arg_0, __epi_2xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_unsigned_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_2xi32_mask(unsigned int*  arg_0, __epi_2xi32 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_unsigned_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_1xi64(unsigned long int*  arg_0, __epi_1xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_unsigned_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_1xi64_mask(unsigned long int*  arg_0, __epi_1xi64 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_unsigned_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_16xi8(unsigned char*  arg_0, __epi_16xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_unsigned_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_16xi8_mask(unsigned char*  arg_0, __epi_16xi8 arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_unsigned_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_8xi16(unsigned short int*  arg_0, __epi_8xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_unsigned_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_8xi16_mask(unsigned short int*  arg_0, __epi_8xi16 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_unsigned_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_4xi32(unsigned int*  arg_0, __epi_4xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_unsigned_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_4xi32_mask(unsigned int*  arg_0, __epi_4xi32 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_unsigned_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_2xi64(unsigned long int*  arg_0, __epi_2xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_unsigned_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_2xi64_mask(unsigned long int*  arg_0, __epi_2xi64 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_unsigned_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_32xi8(unsigned char*  arg_0, __epi_32xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_unsigned_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_32xi8_mask(unsigned char*  arg_0, __epi_32xi8 arg_1, signed long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_unsigned_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_16xi16(unsigned short int*  arg_0, __epi_16xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_unsigned_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_16xi16_mask(unsigned short int*  arg_0, __epi_16xi16 arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_unsigned_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_8xi32(unsigned int*  arg_0, __epi_8xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_unsigned_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_8xi32_mask(unsigned int*  arg_0, __epi_8xi32 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_unsigned_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_4xi64(unsigned long int*  arg_0, __epi_4xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_strided_unsigned_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_strided_unsigned_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.strided.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_strided_unsigned_4xi64_mask(unsigned long int*  arg_0, __epi_4xi64 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_nt_strided_unsigned_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_8xi8(unsigned char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_unsigned_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_8xi8_mask(unsigned char*  arg_0, __epi_8xi8 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_unsigned_8xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_4xi16(unsigned short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_unsigned_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_4xi16_mask(unsigned short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_unsigned_4xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_2xi32(unsigned int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_unsigned_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_2xi32_mask(unsigned int*  arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_unsigned_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_1xi64(unsigned long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_unsigned_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_1xi64_mask(unsigned long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_unsigned_1xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_16xi8(unsigned char*  arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_unsigned_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_16xi8_mask(unsigned char*  arg_0, __epi_16xi8 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_unsigned_16xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_8xi16(unsigned short int*  arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_unsigned_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_8xi16_mask(unsigned short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_unsigned_8xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_4xi32(unsigned int*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_unsigned_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_4xi32_mask(unsigned int*  arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_unsigned_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_2xi64(unsigned long int*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_unsigned_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_2xi64_mask(unsigned long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_unsigned_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_32xi8(unsigned char*  arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_unsigned_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_32xi8_mask(unsigned char*  arg_0, __epi_32xi8 arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_unsigned_32xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_16xi16(unsigned short int*  arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_unsigned_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_16xi16_mask(unsigned short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_unsigned_16xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_8xi32(unsigned int*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_unsigned_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_8xi32_mask(unsigned int*  arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_unsigned_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_4xi64(unsigned long int*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_nt_unsigned_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_nt_unsigned_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nt.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_nt_unsigned_4xi64_mask(unsigned long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_nt_unsigned_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_8xi8(signed char*  arg_0, __epi_8xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_8xi8_mask(signed char*  arg_0, __epi_8xi8 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xi16(signed short int*  arg_0, __epi_4xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xi16_mask(signed short int*  arg_0, __epi_4xi16 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_2xi32(signed int*  arg_0, __epi_2xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_2xi32_mask(signed int*  arg_0, __epi_2xi32 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_1xi64(signed long int*  arg_0, __epi_1xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_1xi64_mask(signed long int*  arg_0, __epi_1xi64 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_2xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv2f32(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_2xf32(float*  arg_0, __epi_2xf32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_2xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_2xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 2 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv2f32.nxv2i1(<vscale x 2 x float> [[ARG_1:%.*]], <vscale x 2 x float>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_2xf32_mask(float*  arg_0, __epi_2xf32 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_2xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_1xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv1f64(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_1xf64(double*  arg_0, __epi_1xf64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_1xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_1xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 1 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv1f64.nxv1i1(<vscale x 1 x double> [[ARG_1:%.*]], <vscale x 1 x double>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_1xf64_mask(double*  arg_0, __epi_1xf64 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_1xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_16xi8(signed char*  arg_0, __epi_16xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_16xi8_mask(signed char*  arg_0, __epi_16xi8 arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_8xi16(signed short int*  arg_0, __epi_8xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_8xi16_mask(signed short int*  arg_0, __epi_8xi16 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xi32(signed int*  arg_0, __epi_4xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xi32_mask(signed int*  arg_0, __epi_4xi32 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_2xi64(signed long int*  arg_0, __epi_2xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_2xi64_mask(signed long int*  arg_0, __epi_2xi64 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4f32(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xf32(float*  arg_0, __epi_4xf32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_4xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 4 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv4f32.nxv4i1(<vscale x 4 x float> [[ARG_1:%.*]], <vscale x 4 x float>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xf32_mask(float*  arg_0, __epi_4xf32 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_4xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_2xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv2f64(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_2xf64(double*  arg_0, __epi_2xf64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_2xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_2xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 2 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv2f64.nxv2i1(<vscale x 2 x double> [[ARG_1:%.*]], <vscale x 2 x double>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_2xf64_mask(double*  arg_0, __epi_2xf64 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_2xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_32xi8(signed char*  arg_0, __epi_32xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_32xi8_mask(signed char*  arg_0, __epi_32xi8 arg_1, signed long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_16xi16(signed short int*  arg_0, __epi_16xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_16xi16_mask(signed short int*  arg_0, __epi_16xi16 arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_8xi32(signed int*  arg_0, __epi_8xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_8xi32_mask(signed int*  arg_0, __epi_8xi32 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xi64(signed long int*  arg_0, __epi_4xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xi64_mask(signed long int*  arg_0, __epi_4xi64 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_8xf32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8f32(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_8xf32(float*  arg_0, __epi_8xf32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_8xf32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_8xf32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast float* [[ARG_0:%.*]] to <vscale x 8 x float>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv8f32.nxv8i1(<vscale x 8 x float> [[ARG_1:%.*]], <vscale x 8 x float>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_8xf32_mask(float*  arg_0, __epi_8xf32 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_8xf32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xf64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4f64(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xf64(double*  arg_0, __epi_4xf64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_4xf64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_4xf64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast double* [[ARG_0:%.*]] to <vscale x 4 x double>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv4f64.nxv4i1(<vscale x 4 x double> [[ARG_1:%.*]], <vscale x 4 x double>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_4xf64_mask(double*  arg_0, __epi_4xf64 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_4xf64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_8xi8(unsigned char*  arg_0, __epi_8xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_8xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_8xi8_mask(unsigned char*  arg_0, __epi_8xi8 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_unsigned_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_4xi16(unsigned short int*  arg_0, __epi_4xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_4xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_4xi16_mask(unsigned short int*  arg_0, __epi_4xi16 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_unsigned_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_2xi32(unsigned int*  arg_0, __epi_2xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_2xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_2xi32_mask(unsigned int*  arg_0, __epi_2xi32 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_unsigned_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_1xi64(unsigned long int*  arg_0, __epi_1xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_1xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_1xi64_mask(unsigned long int*  arg_0, __epi_1xi64 arg_1, signed long int arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_unsigned_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_16xi8(unsigned char*  arg_0, __epi_16xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_16xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_16xi8_mask(unsigned char*  arg_0, __epi_16xi8 arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_unsigned_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_8xi16(unsigned short int*  arg_0, __epi_8xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_8xi16_mask(unsigned short int*  arg_0, __epi_8xi16 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_unsigned_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_4xi32(unsigned int*  arg_0, __epi_4xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_4xi32_mask(unsigned int*  arg_0, __epi_4xi32 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_unsigned_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_2xi64(unsigned long int*  arg_0, __epi_2xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_2xi64_mask(unsigned long int*  arg_0, __epi_2xi64 arg_1, signed long int arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_unsigned_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_32xi8(unsigned char*  arg_0, __epi_32xi8 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_32xi8(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_32xi8_mask(unsigned char*  arg_0, __epi_32xi8 arg_1, signed long int arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_unsigned_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_16xi16(unsigned short int*  arg_0, __epi_16xi16 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_16xi16_mask(unsigned short int*  arg_0, __epi_16xi16 arg_1, signed long int arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_unsigned_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_8xi32(unsigned int*  arg_0, __epi_8xi32 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_8xi32_mask(unsigned int*  arg_0, __epi_8xi32 arg_1, signed long int arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_unsigned_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_4xi64(unsigned long int*  arg_0, __epi_4xi64 arg_1, signed long int arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_strided_unsigned_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_strided_unsigned_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.strided.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_strided_unsigned_4xi64_mask(unsigned long int*  arg_0, __epi_4xi64 arg_1, signed long int arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vstore_strided_unsigned_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8i8(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_8xi8(unsigned char*  arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 8 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_8xi8_mask(unsigned char*  arg_0, __epi_8xi8 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_unsigned_8xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4i16(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_4xi16(unsigned short int*  arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 4 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_4xi16_mask(unsigned short int*  arg_0, __epi_4xi16 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_unsigned_4xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i32(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_2xi32(unsigned int*  arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 2 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_2xi32_mask(unsigned int*  arg_0, __epi_2xi32 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_unsigned_2xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv1i64(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_1xi64(unsigned long int*  arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 1 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64>* [[TMP0]], <vscale x 1 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_1xi64_mask(unsigned long int*  arg_0, __epi_1xi64 arg_1, __epi_1xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_unsigned_1xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv16i8(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_16xi8(unsigned char*  arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 16 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_16xi8_mask(unsigned char*  arg_0, __epi_16xi8 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_unsigned_16xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8i16(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_8xi16(unsigned short int*  arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 8 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_8xi16_mask(unsigned short int*  arg_0, __epi_8xi16 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_unsigned_8xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4i32(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_4xi32(unsigned int*  arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 4 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_4xi32_mask(unsigned int*  arg_0, __epi_4xi32 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_unsigned_4xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv2i64(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_2xi64(unsigned long int*  arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 2 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64>* [[TMP0]], <vscale x 2 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_2xi64_mask(unsigned long int*  arg_0, __epi_2xi64 arg_1, __epi_2xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_unsigned_2xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv32i8(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_32xi8(unsigned char*  arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i8* [[ARG_0:%.*]] to <vscale x 32 x i8>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8>* [[TMP0]], <vscale x 32 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_32xi8_mask(unsigned char*  arg_0, __epi_32xi8 arg_1, __epi_32xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_unsigned_32xi8_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv16i16(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_16xi16(unsigned short int*  arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i16* [[ARG_0:%.*]] to <vscale x 16 x i16>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16>* [[TMP0]], <vscale x 16 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_16xi16_mask(unsigned short int*  arg_0, __epi_16xi16 arg_1, __epi_16xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_unsigned_16xi16_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv8i32(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_8xi32(unsigned int*  arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i32* [[ARG_0:%.*]] to <vscale x 8 x i32>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32>* [[TMP0]], <vscale x 8 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_8xi32_mask(unsigned int*  arg_0, __epi_8xi32 arg_1, __epi_8xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_unsigned_8xi32_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.nxv4i64(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_4xi64(unsigned long int*  arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vstore_unsigned_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vstore_unsigned_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast i64* [[ARG_0:%.*]] to <vscale x 4 x i64>*
// CHECK-O2-NEXT:    tail call void @llvm.epi.vstore.mask.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64>* [[TMP0]], <vscale x 4 x i1> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret void
//
void test_vstore_unsigned_4xi64_mask(unsigned long int*  arg_0, __epi_4xi64 arg_1, __epi_4xi1 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vstore_unsigned_4xi64_mask(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vsub_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsub.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsub_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vsub.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vsub_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsub.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsub_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vsub.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vsub_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsub.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsub_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vsub.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vsub_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsub.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsub_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vsub.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vsub_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsub.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsub_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vsub.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vsub_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsub.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsub_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vsub.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vsub_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsub.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsub_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vsub.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vsub_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsub.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsub_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vsub.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vsub_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsub.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsub_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vsub.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vsub_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsub.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsub_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vsub.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vsub_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsub.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsub_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vsub.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vsub_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vsub_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsub.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsub_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vsub_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vsub_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vsub.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vsub_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vsub_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vtrn_8xi8x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vtrn.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X2]] [[TMP4]]
//
__epi_8xi8x2 test_vtrn_8xi8x2(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vtrn_8xi8x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vtrn_4xi16x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vtrn.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X2]] [[TMP4]]
//
__epi_4xi16x2 test_vtrn_4xi16x2(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vtrn_4xi16x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vtrn_2xi32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vtrn.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X2]] [[TMP4]]
//
__epi_2xi32x2 test_vtrn_2xi32x2(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vtrn_2xi32x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vtrn_1xi64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vtrn.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X2]] [[TMP4]]
//
__epi_1xi64x2 test_vtrn_1xi64x2(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vtrn_1xi64x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vtrn_1xf64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vtrn.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X2]] [[TMP4]]
//
__epi_1xf64x2 test_vtrn_1xf64x2(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vtrn_1xf64x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vtrn_2xf32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vtrn.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X2]] [[TMP4]]
//
__epi_2xf32x2 test_vtrn_2xf32x2(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vtrn_2xf32x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vunzip2_8xi8x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vunzip2.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X2]] [[TMP4]]
//
__epi_8xi8x2 test_vunzip2_8xi8x2(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vunzip2_8xi8x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vunzip2_4xi16x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vunzip2.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X2]] [[TMP4]]
//
__epi_4xi16x2 test_vunzip2_4xi16x2(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vunzip2_4xi16x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vunzip2_2xi32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vunzip2.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X2]] [[TMP4]]
//
__epi_2xi32x2 test_vunzip2_2xi32x2(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vunzip2_2xi32x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vunzip2_1xi64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vunzip2.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X2]] [[TMP4]]
//
__epi_1xi64x2 test_vunzip2_1xi64x2(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vunzip2_1xi64x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vunzip2_1xf64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vunzip2.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X2]] [[TMP4]]
//
__epi_1xf64x2 test_vunzip2_1xf64x2(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vunzip2_1xf64x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vunzip2_2xf32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vunzip2.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X2]] [[TMP4]]
//
__epi_2xf32x2 test_vunzip2_2xf32x2(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vunzip2_2xf32x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwadd.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwadd_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwadd.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwadd_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwadd.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwadd_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwadd.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwadd_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwadd.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwadd_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwadd.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwadd_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwadd.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwadd_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwadd.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwadd_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwadd.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwadd_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwadd.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwadd_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwadd.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwadd_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwadd.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwadd_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwadd.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwadd_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwadd.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwadd_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwadd.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwadd_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwadd.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwadd_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwadd.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwadd_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwadd.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwadd_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwadd.w.nxv8i16.nxv8i8(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwadd_w_8xi16(__epi_8xi16 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwadd.w.mask.nxv8i16.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwadd_w_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwadd.w.nxv4i32.nxv4i16(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwadd_w_4xi32(__epi_4xi32 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwadd.w.mask.nxv4i32.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwadd_w_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwadd.w.nxv2i64.nxv2i32(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwadd_w_2xi64(__epi_2xi64 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwadd.w.mask.nxv2i64.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwadd_w_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwadd.w.nxv16i16.nxv16i8(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwadd_w_16xi16(__epi_16xi16 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwadd.w.mask.nxv16i16.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwadd_w_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwadd.w.nxv8i32.nxv8i16(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwadd_w_8xi32(__epi_8xi32 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwadd.w.mask.nxv8i32.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwadd_w_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwadd.w.nxv4i64.nxv4i32(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwadd_w_4xi64(__epi_4xi64 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwadd.w.mask.nxv4i64.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwadd_w_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwadd.w.nxv32i16.nxv32i8(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwadd_w_32xi16(__epi_32xi16 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwadd.w.mask.nxv32i16.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwadd_w_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi16 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwadd.w.nxv16i32.nxv16i16(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwadd_w_16xi32(__epi_16xi32 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwadd.w.mask.nxv16i32.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwadd_w_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi32 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwadd_w_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwadd.w.nxv8i64.nxv8i32(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwadd_w_8xi64(__epi_8xi64 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwadd_w_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwadd_w_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwadd.w.mask.nxv8i64.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwadd_w_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi64 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwadd_w_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwaddu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwaddu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwaddu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwaddu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwaddu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwaddu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwaddu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwaddu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwaddu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwaddu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwaddu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwaddu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwaddu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwaddu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwaddu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwaddu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwaddu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwaddu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwaddu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwaddu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwaddu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwaddu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwaddu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwaddu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwaddu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwaddu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwaddu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwaddu_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwaddu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwaddu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwaddu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwaddu_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwaddu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwaddu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwaddu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwaddu_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwaddu.w.nxv8i16.nxv8i8(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwaddu_w_8xi16(__epi_8xi16 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwaddu.w.mask.nxv8i16.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwaddu_w_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwaddu.w.nxv4i32.nxv4i16(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwaddu_w_4xi32(__epi_4xi32 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwaddu.w.mask.nxv4i32.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwaddu_w_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwaddu.w.nxv2i64.nxv2i32(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwaddu_w_2xi64(__epi_2xi64 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwaddu.w.mask.nxv2i64.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwaddu_w_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwaddu.w.nxv16i16.nxv16i8(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwaddu_w_16xi16(__epi_16xi16 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwaddu.w.mask.nxv16i16.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwaddu_w_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwaddu.w.nxv8i32.nxv8i16(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwaddu_w_8xi32(__epi_8xi32 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwaddu.w.mask.nxv8i32.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwaddu_w_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwaddu.w.nxv4i64.nxv4i32(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwaddu_w_4xi64(__epi_4xi64 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwaddu.w.mask.nxv4i64.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwaddu_w_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwaddu.w.nxv32i16.nxv32i8(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwaddu_w_32xi16(__epi_32xi16 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwaddu.w.mask.nxv32i16.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwaddu_w_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi16 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwaddu.w.nxv16i32.nxv16i16(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwaddu_w_16xi32(__epi_16xi32 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwaddu.w.mask.nxv16i32.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwaddu_w_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi32 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwaddu_w_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwaddu.w.nxv8i64.nxv8i32(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwaddu_w_8xi64(__epi_8xi64 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwaddu_w_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwaddu_w_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwaddu.w.mask.nxv8i64.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwaddu_w_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi64 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwaddu_w_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmacc.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmacc_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmacc.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmacc_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmacc.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmacc_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmacc.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmacc_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmacc.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmacc_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmacc.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmacc_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmacc.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmacc_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmacc.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmacc_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmacc.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmacc_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmacc.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmacc_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmacc.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmacc_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmacc.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmacc_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmacc.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmacc_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmacc.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmacc_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmacc.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmacc_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmacc.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmacc_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmacc_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmacc.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmacc_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmacc_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmacc_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmacc.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmacc_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmacc_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmaccu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmaccu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmaccu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmaccu_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmaccu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmaccu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmaccu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmaccu_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmaccu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmaccu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmaccu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmaccu_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmaccu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmaccu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmaccu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmaccu_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmaccu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmaccu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmaccu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmaccu_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmaccu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmaccu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmaccu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmaccu_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmaccu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmaccu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmaccu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmaccu_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmaccu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmaccu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmaccu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmaccu_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmaccu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmaccu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmaccu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmaccu_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmaccu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmaccu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmaccu_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmaccu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmsac.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmsac_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmsac.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmsac_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmsac.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmsac_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmsac.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmsac_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmsac.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmsac_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmsac.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmsac_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmsac.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmsac_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmsac.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmsac_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmsac.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmsac_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmsac.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmsac_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmsac.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmsac_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmsac.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmsac_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmsac.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmsac_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmsac.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmsac_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmsac.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmsac_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmsac.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmsac_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsac_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmsac.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmsac_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsac_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsac_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmsac.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmsac_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsac_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmsacu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmsacu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmsacu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmsacu_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmsacu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmsacu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmsacu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmsacu_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmsacu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmsacu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmsacu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmsacu_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmsacu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmsacu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmsacu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmsacu_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmsacu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmsacu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmsacu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmsacu_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmsacu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmsacu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmsacu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmsacu_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmsacu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmsacu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmsacu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmsacu_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmsacu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmsacu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmsacu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmsacu_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmsacu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmsacu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmsacu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwmsacu_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwmsacu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmsacu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmsacu_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmsacu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmul.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmul_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmul.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmul_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmul.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmul_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmul.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmul_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmul.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmul_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmul.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmul_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmul.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmul_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmul.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmul_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmul.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmul_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmul.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmul_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmul.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmul_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmul.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmul_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmul.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmul_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmul.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmul_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmul.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmul_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmul.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmul_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmul_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmul.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmul_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmul_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmul_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmul.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmul_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmul_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmulsu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmulsu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmulsu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmulsu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmulsu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmulsu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmulsu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmulsu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmulsu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmulsu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmulsu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmulsu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmulsu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmulsu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmulsu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmulsu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmulsu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmulsu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmulsu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmulsu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmulsu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmulsu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmulsu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmulsu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmulsu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmulsu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmulsu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmulsu_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmulsu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmulsu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmulsu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmulsu_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulsu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmulsu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmulsu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulsu_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulsu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmulsu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmulsu_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulsu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmulu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmulu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwmulu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwmulu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmulu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmulu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwmulu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwmulu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmulu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmulu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwmulu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwmulu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmulu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmulu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwmulu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwmulu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmulu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmulu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwmulu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwmulu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmulu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmulu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwmulu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwmulu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmulu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmulu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwmulu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwmulu_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmulu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmulu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwmulu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwmulu_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwmulu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmulu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmulu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwmulu_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwmulu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwmulu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwmulu_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwmulu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsum_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwredsum.nxv8i16.nxv8i8.nxv8i16(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwredsum_8xi16(__epi_8xi8 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsum_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsum_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwredsum.mask.nxv8i16.nxv8i8.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwredsum_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsum_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsum_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwredsum.nxv4i32.nxv4i16.nxv4i32(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwredsum_4xi32(__epi_4xi16 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsum_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsum_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwredsum.mask.nxv4i32.nxv4i16.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwredsum_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsum_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsum_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwredsum.nxv2i64.nxv2i32.nxv2i64(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwredsum_2xi64(__epi_2xi32 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsum_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsum_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwredsum.mask.nxv2i64.nxv2i32.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwredsum_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsum_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsum_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwredsum.nxv16i16.nxv16i8.nxv16i16(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwredsum_16xi16(__epi_16xi8 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsum_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsum_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwredsum.mask.nxv16i16.nxv16i8.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwredsum_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsum_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsum_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwredsum.nxv8i32.nxv8i16.nxv8i32(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwredsum_8xi32(__epi_8xi16 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsum_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsum_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwredsum.mask.nxv8i32.nxv8i16.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwredsum_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsum_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsum_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwredsum.nxv4i64.nxv4i32.nxv4i64(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwredsum_4xi64(__epi_4xi32 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsum_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsum_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwredsum.mask.nxv4i64.nxv4i32.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwredsum_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsum_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsum_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwredsum.nxv32i16.nxv32i8.nxv32i16(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwredsum_32xi16(__epi_32xi8 arg_0, __epi_32xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsum_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsum_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwredsum.mask.nxv32i16.nxv32i8.nxv32i16.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwredsum_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsum_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsum_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwredsum.nxv16i32.nxv16i16.nxv16i32(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwredsum_16xi32(__epi_16xi16 arg_0, __epi_16xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsum_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsum_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwredsum.mask.nxv16i32.nxv16i16.nxv16i32.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwredsum_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsum_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsum_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwredsum.nxv8i64.nxv8i32.nxv8i64(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwredsum_8xi64(__epi_8xi32 arg_0, __epi_8xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsum_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsum_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwredsum.mask.nxv8i64.nxv8i32.nxv8i64.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwredsum_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsum_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsumu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwredsumu.nxv8i16.nxv8i8.nxv8i16(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwredsumu_8xi16(__epi_8xi8 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsumu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsumu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwredsumu.mask.nxv8i16.nxv8i8.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwredsumu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsumu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsumu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwredsumu.nxv4i32.nxv4i16.nxv4i32(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwredsumu_4xi32(__epi_4xi16 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsumu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsumu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwredsumu.mask.nxv4i32.nxv4i16.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwredsumu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsumu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsumu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwredsumu.nxv2i64.nxv2i32.nxv2i64(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwredsumu_2xi64(__epi_2xi32 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsumu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsumu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwredsumu.mask.nxv2i64.nxv2i32.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwredsumu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsumu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsumu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwredsumu.nxv16i16.nxv16i8.nxv16i16(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwredsumu_16xi16(__epi_16xi8 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsumu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsumu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwredsumu.mask.nxv16i16.nxv16i8.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwredsumu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsumu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsumu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwredsumu.nxv8i32.nxv8i16.nxv8i32(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwredsumu_8xi32(__epi_8xi16 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsumu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsumu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwredsumu.mask.nxv8i32.nxv8i16.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwredsumu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsumu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsumu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwredsumu.nxv4i64.nxv4i32.nxv4i64(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwredsumu_4xi64(__epi_4xi32 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsumu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsumu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwredsumu.mask.nxv4i64.nxv4i32.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwredsumu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsumu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsumu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwredsumu.nxv32i16.nxv32i8.nxv32i16(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwredsumu_32xi16(__epi_32xi8 arg_0, __epi_32xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsumu_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsumu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwredsumu.mask.nxv32i16.nxv32i8.nxv32i16.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwredsumu_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsumu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsumu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwredsumu.nxv16i32.nxv16i16.nxv16i32(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwredsumu_16xi32(__epi_16xi16 arg_0, __epi_16xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsumu_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsumu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwredsumu.mask.nxv16i32.nxv16i16.nxv16i32.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwredsumu_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsumu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwredsumu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwredsumu.nxv8i64.nxv8i32.nxv8i64(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwredsumu_8xi64(__epi_8xi32 arg_0, __epi_8xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwredsumu_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwredsumu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwredsumu.mask.nxv8i64.nxv8i32.nxv8i64.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwredsumu_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwredsumu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmacc.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmacc_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmacc.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmacc_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmacc.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmacc_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmacc.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmacc_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmacc.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmacc_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmacc.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmacc_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmacc.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmacc_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmacc.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmacc_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmacc.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmacc_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmacc.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmacc_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmacc.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmacc_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmacc.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmacc_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmacc.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmacc_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmacc.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmacc_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmacc.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmacc_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmacc.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmacc_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmacc_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmacc.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmacc_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmacc_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmacc_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmacc.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmacc_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmacc_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmaccu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmaccu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmaccu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmaccu_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmaccu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmaccu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmaccu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmaccu_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmaccu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmaccu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmaccu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmaccu_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmaccu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmaccu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmaccu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmaccu_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmaccu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmaccu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmaccu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmaccu_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmaccu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmaccu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmaccu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmaccu_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmaccu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmaccu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmaccu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmaccu_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmaccu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmaccu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmaccu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmaccu_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmaccu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmaccu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmaccu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmaccu_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmaccu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmaccu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmaccu_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmaccu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmsac.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmsac_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmsac.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmsac_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmsac.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmsac_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmsac.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmsac_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmsac.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmsac_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmsac.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmsac_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmsac.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmsac_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmsac.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmsac_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmsac.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmsac_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmsac.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmsac_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmsac.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmsac_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmsac.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmsac_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmsac.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmsac_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmsac.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmsac_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmsac.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmsac_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmsac.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmsac_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsac_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmsac.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmsac_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsac_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsac_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmsac.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmsac_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsac_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmsacu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmsacu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_8xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsmsacu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsmsacu_8xi16_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmsacu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmsacu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_4xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsmsacu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsmsacu_4xi32_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmsacu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmsacu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_2xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsmsacu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsmsacu_2xi64_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmsacu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmsacu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_16xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsmsacu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsmsacu_16xi16_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmsacu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmsacu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_8xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsmsacu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsmsacu_8xi32_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmsacu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmsacu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_4xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsmsacu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsmsacu_4xi64_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmsacu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmsacu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_32xi16(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsmsacu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i16> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsmsacu_32xi16_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi16 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmsacu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmsacu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_16xi32(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsmsacu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i32> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsmsacu_16xi32_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi32 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsmsacu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmsacu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], i64 [[ARG_3:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmsacu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, unsigned long int arg_3)
{
    return __builtin_epi_vwsmsacu_8xi64(arg_0, arg_1, arg_2, arg_3);
}

// CHECK-O2-LABEL: @test_vwsmsacu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsmsacu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i64> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsmsacu_8xi64_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi64 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsmsacu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsub.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsub_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsub.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsub_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsub.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsub_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsub.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsub_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsub.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsub_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsub.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsub_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsub.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsub_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsub.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsub_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsub.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsub_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsub.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsub_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsub.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsub_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsub.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsub_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsub.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsub_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsub.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsub_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsub.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsub_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsub.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsub_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsub.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsub_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsub.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsub_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsub.w.nxv8i16.nxv8i8(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsub_w_8xi16(__epi_8xi16 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsub.w.mask.nxv8i16.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsub_w_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsub.w.nxv4i32.nxv4i16(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsub_w_4xi32(__epi_4xi32 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsub.w.mask.nxv4i32.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsub_w_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsub.w.nxv2i64.nxv2i32(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsub_w_2xi64(__epi_2xi64 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsub.w.mask.nxv2i64.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsub_w_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsub.w.nxv16i16.nxv16i8(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsub_w_16xi16(__epi_16xi16 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsub.w.mask.nxv16i16.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsub_w_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsub.w.nxv8i32.nxv8i16(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsub_w_8xi32(__epi_8xi32 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsub.w.mask.nxv8i32.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsub_w_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsub.w.nxv4i64.nxv4i32(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsub_w_4xi64(__epi_4xi64 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsub.w.mask.nxv4i64.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsub_w_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsub.w.nxv32i16.nxv32i8(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsub_w_32xi16(__epi_32xi16 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsub.w.mask.nxv32i16.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsub_w_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi16 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsub.w.nxv16i32.nxv16i16(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsub_w_16xi32(__epi_16xi32 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsub.w.mask.nxv16i32.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsub_w_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi32 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsub_w_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsub.w.nxv8i64.nxv8i32(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsub_w_8xi64(__epi_8xi64 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsub_w_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsub_w_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsub.w.mask.nxv8i64.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsub_w_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi64 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsub_w_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsubu.nxv8i16.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsubu_8xi16(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsubu.mask.nxv8i16.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsubu_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsubu.nxv4i32.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsubu_4xi32(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsubu.mask.nxv4i32.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsubu_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsubu.nxv2i64.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsubu_2xi64(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsubu.mask.nxv2i64.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsubu_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsubu.nxv16i16.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsubu_16xi16(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsubu.mask.nxv16i16.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsubu_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsubu.nxv8i32.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsubu_8xi32(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsubu.mask.nxv8i32.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsubu_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsubu.nxv4i64.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsubu_4xi64(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsubu.mask.nxv4i64.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsubu_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsubu.nxv32i16.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsubu_32xi16(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsubu.mask.nxv32i16.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsubu_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsubu.nxv16i32.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsubu_16xi32(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsubu.mask.nxv16i32.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsubu_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsubu.nxv8i64.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsubu_8xi64(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsubu.mask.nxv8i64.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsubu_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsubu.w.nxv8i16.nxv8i8(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsubu_w_8xi16(__epi_8xi16 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vwsubu.w.mask.nxv8i16.nxv8i8.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vwsubu_w_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsubu.w.nxv4i32.nxv4i16(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsubu_w_4xi32(__epi_4xi32 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vwsubu.w.mask.nxv4i32.nxv4i16.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vwsubu_w_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsubu.w.nxv2i64.nxv2i32(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsubu_w_2xi64(__epi_2xi64 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vwsubu.w.mask.nxv2i64.nxv2i32.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vwsubu_w_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsubu.w.nxv16i16.nxv16i8(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsubu_w_16xi16(__epi_16xi16 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vwsubu.w.mask.nxv16i16.nxv16i8.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vwsubu_w_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsubu.w.nxv8i32.nxv8i16(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsubu_w_8xi32(__epi_8xi32 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vwsubu.w.mask.nxv8i32.nxv8i16.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vwsubu_w_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsubu.w.nxv4i64.nxv4i32(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsubu_w_4xi64(__epi_4xi64 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vwsubu.w.mask.nxv4i64.nxv4i32.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vwsubu_w_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_32xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsubu.w.nxv32i16.nxv32i8(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsubu_w_32xi16(__epi_32xi16 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_32xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_32xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i16> @llvm.epi.vwsubu.w.mask.nxv32i16.nxv32i8.nxv32i1(<vscale x 32 x i16> [[ARG_0:%.*]], <vscale x 32 x i16> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
__epi_32xi16 test_vwsubu_w_32xi16_mask(__epi_32xi16 arg_0, __epi_32xi16 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_32xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_16xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsubu.w.nxv16i32.nxv16i16(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsubu_w_16xi32(__epi_16xi32 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_16xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_16xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i32> @llvm.epi.vwsubu.w.mask.nxv16i32.nxv16i16.nxv16i1(<vscale x 16 x i32> [[ARG_0:%.*]], <vscale x 16 x i32> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
__epi_16xi32 test_vwsubu_w_16xi32_mask(__epi_16xi32 arg_0, __epi_16xi32 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_16xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vwsubu_w_8xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsubu.w.nxv8i64.nxv8i32(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsubu_w_8xi64(__epi_8xi64 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vwsubu_w_8xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vwsubu_w_8xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i64> @llvm.epi.vwsubu.w.mask.nxv8i64.nxv8i32.nxv8i1(<vscale x 8 x i64> [[ARG_0:%.*]], <vscale x 8 x i64> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
__epi_8xi64 test_vwsubu_w_8xi64_mask(__epi_8xi64 arg_0, __epi_8xi64 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vwsubu_w_8xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_8xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vxor.nxv8i8.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vxor_8xi8(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_8xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_8xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i8> @llvm.epi.vxor.mask.nxv8i8.nxv8i8.nxv8i1(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], <vscale x 8 x i8> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i8> [[TMP0]]
//
__epi_8xi8 test_vxor_8xi8_mask(__epi_8xi8 arg_0, __epi_8xi8 arg_1, __epi_8xi8 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_8xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_4xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vxor.nxv4i16.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vxor_4xi16(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_4xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_4xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i16> @llvm.epi.vxor.mask.nxv4i16.nxv4i16.nxv4i1(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], <vscale x 4 x i16> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i16> [[TMP0]]
//
__epi_4xi16 test_vxor_4xi16_mask(__epi_4xi16 arg_0, __epi_4xi16 arg_1, __epi_4xi16 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_4xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_2xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vxor.nxv2i32.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vxor_2xi32(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_2xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_2xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i32> @llvm.epi.vxor.mask.nxv2i32.nxv2i32.nxv2i1(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], <vscale x 2 x i32> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i32> [[TMP0]]
//
__epi_2xi32 test_vxor_2xi32_mask(__epi_2xi32 arg_0, __epi_2xi32 arg_1, __epi_2xi32 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_2xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_1xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vxor.nxv1i64.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vxor_1xi64(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_1xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_1xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 1 x i64> @llvm.epi.vxor.mask.nxv1i64.nxv1i64.nxv1i1(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], <vscale x 1 x i64> [[ARG_2:%.*]], <vscale x 1 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 1 x i64> [[TMP0]]
//
__epi_1xi64 test_vxor_1xi64_mask(__epi_1xi64 arg_0, __epi_1xi64 arg_1, __epi_1xi64 arg_2, __epi_1xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_1xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_16xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vxor.nxv16i8.nxv16i8(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vxor_16xi8(__epi_16xi8 arg_0, __epi_16xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_16xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_16xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i8> @llvm.epi.vxor.mask.nxv16i8.nxv16i8.nxv16i1(<vscale x 16 x i8> [[ARG_0:%.*]], <vscale x 16 x i8> [[ARG_1:%.*]], <vscale x 16 x i8> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i8> [[TMP0]]
//
__epi_16xi8 test_vxor_16xi8_mask(__epi_16xi8 arg_0, __epi_16xi8 arg_1, __epi_16xi8 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_16xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_8xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vxor.nxv8i16.nxv8i16(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vxor_8xi16(__epi_8xi16 arg_0, __epi_8xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_8xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_8xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i16> @llvm.epi.vxor.mask.nxv8i16.nxv8i16.nxv8i1(<vscale x 8 x i16> [[ARG_0:%.*]], <vscale x 8 x i16> [[ARG_1:%.*]], <vscale x 8 x i16> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i16> [[TMP0]]
//
__epi_8xi16 test_vxor_8xi16_mask(__epi_8xi16 arg_0, __epi_8xi16 arg_1, __epi_8xi16 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_8xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_4xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vxor.nxv4i32.nxv4i32(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vxor_4xi32(__epi_4xi32 arg_0, __epi_4xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_4xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_4xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i32> @llvm.epi.vxor.mask.nxv4i32.nxv4i32.nxv4i1(<vscale x 4 x i32> [[ARG_0:%.*]], <vscale x 4 x i32> [[ARG_1:%.*]], <vscale x 4 x i32> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i32> [[TMP0]]
//
__epi_4xi32 test_vxor_4xi32_mask(__epi_4xi32 arg_0, __epi_4xi32 arg_1, __epi_4xi32 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_4xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_2xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vxor.nxv2i64.nxv2i64(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vxor_2xi64(__epi_2xi64 arg_0, __epi_2xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_2xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_2xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 2 x i64> @llvm.epi.vxor.mask.nxv2i64.nxv2i64.nxv2i1(<vscale x 2 x i64> [[ARG_0:%.*]], <vscale x 2 x i64> [[ARG_1:%.*]], <vscale x 2 x i64> [[ARG_2:%.*]], <vscale x 2 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 2 x i64> [[TMP0]]
//
__epi_2xi64 test_vxor_2xi64_mask(__epi_2xi64 arg_0, __epi_2xi64 arg_1, __epi_2xi64 arg_2, __epi_2xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_2xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_32xi8(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vxor.nxv32i8.nxv32i8(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vxor_32xi8(__epi_32xi8 arg_0, __epi_32xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_32xi8(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_32xi8_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 32 x i8> @llvm.epi.vxor.mask.nxv32i8.nxv32i8.nxv32i1(<vscale x 32 x i8> [[ARG_0:%.*]], <vscale x 32 x i8> [[ARG_1:%.*]], <vscale x 32 x i8> [[ARG_2:%.*]], <vscale x 32 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 32 x i8> [[TMP0]]
//
__epi_32xi8 test_vxor_32xi8_mask(__epi_32xi8 arg_0, __epi_32xi8 arg_1, __epi_32xi8 arg_2, __epi_32xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_32xi8_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_16xi16(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vxor.nxv16i16.nxv16i16(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vxor_16xi16(__epi_16xi16 arg_0, __epi_16xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_16xi16(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_16xi16_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 16 x i16> @llvm.epi.vxor.mask.nxv16i16.nxv16i16.nxv16i1(<vscale x 16 x i16> [[ARG_0:%.*]], <vscale x 16 x i16> [[ARG_1:%.*]], <vscale x 16 x i16> [[ARG_2:%.*]], <vscale x 16 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 16 x i16> [[TMP0]]
//
__epi_16xi16 test_vxor_16xi16_mask(__epi_16xi16 arg_0, __epi_16xi16 arg_1, __epi_16xi16 arg_2, __epi_16xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_16xi16_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_8xi32(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vxor.nxv8i32.nxv8i32(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vxor_8xi32(__epi_8xi32 arg_0, __epi_8xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_8xi32(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_8xi32_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 8 x i32> @llvm.epi.vxor.mask.nxv8i32.nxv8i32.nxv8i1(<vscale x 8 x i32> [[ARG_0:%.*]], <vscale x 8 x i32> [[ARG_1:%.*]], <vscale x 8 x i32> [[ARG_2:%.*]], <vscale x 8 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 8 x i32> [[TMP0]]
//
__epi_8xi32 test_vxor_8xi32_mask(__epi_8xi32 arg_0, __epi_8xi32 arg_1, __epi_8xi32 arg_2, __epi_8xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_8xi32_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vxor_4xi64(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vxor.nxv4i64.nxv4i64(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vxor_4xi64(__epi_4xi64 arg_0, __epi_4xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vxor_4xi64(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vxor_4xi64_mask(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call <vscale x 4 x i64> @llvm.epi.vxor.mask.nxv4i64.nxv4i64.nxv4i1(<vscale x 4 x i64> [[ARG_0:%.*]], <vscale x 4 x i64> [[ARG_1:%.*]], <vscale x 4 x i64> [[ARG_2:%.*]], <vscale x 4 x i1> [[ARG_3:%.*]], i64 [[ARG_4:%.*]])
// CHECK-O2-NEXT:    ret <vscale x 4 x i64> [[TMP0]]
//
__epi_4xi64 test_vxor_4xi64_mask(__epi_4xi64 arg_0, __epi_4xi64 arg_1, __epi_4xi64 arg_2, __epi_4xi1 arg_3, unsigned long int arg_4)
{
    return __builtin_epi_vxor_4xi64_mask(arg_0, arg_1, arg_2, arg_3, arg_4);
}

// CHECK-O2-LABEL: @test_vzip2_8xi8x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 8 x i8>, <vscale x 8 x i8> } @llvm.epi.vzip2.nxv8i8(<vscale x 8 x i8> [[ARG_0:%.*]], <vscale x 8 x i8> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2:%.*]] undef, <vscale x 8 x i8> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 8 x i8>, <vscale x 8 x i8> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_8XI8X2]] [[TMP2]], <vscale x 8 x i8> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_8XI8X2]] [[TMP4]]
//
__epi_8xi8x2 test_vzip2_8xi8x2(__epi_8xi8 arg_0, __epi_8xi8 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vzip2_8xi8x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vzip2_4xi16x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 4 x i16>, <vscale x 4 x i16> } @llvm.epi.vzip2.nxv4i16(<vscale x 4 x i16> [[ARG_0:%.*]], <vscale x 4 x i16> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2:%.*]] undef, <vscale x 4 x i16> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 4 x i16>, <vscale x 4 x i16> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_4XI16X2]] [[TMP2]], <vscale x 4 x i16> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_4XI16X2]] [[TMP4]]
//
__epi_4xi16x2 test_vzip2_4xi16x2(__epi_4xi16 arg_0, __epi_4xi16 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vzip2_4xi16x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vzip2_2xi32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.epi.vzip2.nxv2i32(<vscale x 2 x i32> [[ARG_0:%.*]], <vscale x 2 x i32> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2:%.*]] undef, <vscale x 2 x i32> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XI32X2]] [[TMP2]], <vscale x 2 x i32> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XI32X2]] [[TMP4]]
//
__epi_2xi32x2 test_vzip2_2xi32x2(__epi_2xi32 arg_0, __epi_2xi32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vzip2_2xi32x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vzip2_1xi64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x i64>, <vscale x 1 x i64> } @llvm.epi.vzip2.nxv1i64(<vscale x 1 x i64> [[ARG_0:%.*]], <vscale x 1 x i64> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2:%.*]] undef, <vscale x 1 x i64> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x i64>, <vscale x 1 x i64> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XI64X2]] [[TMP2]], <vscale x 1 x i64> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XI64X2]] [[TMP4]]
//
__epi_1xi64x2 test_vzip2_1xi64x2(__epi_1xi64 arg_0, __epi_1xi64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vzip2_1xi64x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vzip2_1xf64x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 1 x double>, <vscale x 1 x double> } @llvm.epi.vzip2.nxv1f64(<vscale x 1 x double> [[ARG_0:%.*]], <vscale x 1 x double> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2:%.*]] undef, <vscale x 1 x double> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 1 x double>, <vscale x 1 x double> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_1XF64X2]] [[TMP2]], <vscale x 1 x double> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_1XF64X2]] [[TMP4]]
//
__epi_1xf64x2 test_vzip2_1xf64x2(__epi_1xf64 arg_0, __epi_1xf64 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vzip2_1xf64x2(arg_0, arg_1, arg_2);
}

// CHECK-O2-LABEL: @test_vzip2_2xf32x2(
// CHECK-O2-NEXT:  entry:
// CHECK-O2-NEXT:    [[TMP0:%.*]] = tail call { <vscale x 2 x float>, <vscale x 2 x float> } @llvm.epi.vzip2.nxv2f32(<vscale x 2 x float> [[ARG_0:%.*]], <vscale x 2 x float> [[ARG_1:%.*]], i64 [[ARG_2:%.*]])
// CHECK-O2-NEXT:    [[TMP1:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 0
// CHECK-O2-NEXT:    [[TMP2:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2:%.*]] undef, <vscale x 2 x float> [[TMP1]], 0
// CHECK-O2-NEXT:    [[TMP3:%.*]] = extractvalue { <vscale x 2 x float>, <vscale x 2 x float> } [[TMP0]], 1
// CHECK-O2-NEXT:    [[TMP4:%.*]] = insertvalue [[STRUCT___EPI_2XF32X2]] [[TMP2]], <vscale x 2 x float> [[TMP3]], 1
// CHECK-O2-NEXT:    ret [[STRUCT___EPI_2XF32X2]] [[TMP4]]
//
__epi_2xf32x2 test_vzip2_2xf32x2(__epi_2xf32 arg_0, __epi_2xf32 arg_1, unsigned long int arg_2)
{
    return __builtin_epi_vzip2_2xf32x2(arg_0, arg_1, arg_2);
}

